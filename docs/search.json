[
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Semester\nFall 2024\n\n\nSection\nPSYC 167\n\n\nDay Time\nT/R 1:15-2:30 PM or 2:45-4:00PM (Pacific)\n\n\nLocation\nLocation: Roberts South, 102\n\n\nOffice Hours\nT/R: 12-1pm\n\n\nInstructor\nGabriel I. Cook\n\n\nContact\nDiscord (preferred) or Email: gcook@CMC.edu (please put ’PSYC 167 in subject line)\n\n\nCredit\n3 hours; 1 credits"
  },
  {
    "objectID": "syllabus/syllabus.html#course-details",
    "href": "syllabus/syllabus.html#course-details",
    "title": "Syllabus",
    "section": "",
    "text": "Semester\nFall 2024\n\n\nSection\nPSYC 167\n\n\nDay Time\nT/R 1:15-2:30 PM or 2:45-4:00PM (Pacific)\n\n\nLocation\nLocation: Roberts South, 102\n\n\nOffice Hours\nT/R: 12-1pm\n\n\nInstructor\nGabriel I. Cook\n\n\nContact\nDiscord (preferred) or Email: gcook@CMC.edu (please put ’PSYC 167 in subject line)\n\n\nCredit\n3 hours; 1 credits"
  },
  {
    "objectID": "syllabus/syllabus.html#course-description",
    "href": "syllabus/syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nData visualization is the science and art of creating graphical representations of information and data. Visual representations provide accessible ways to see patterns, trends, and outliers in data. Variables like position, size, and orientation can focus attention and guide perception but can also bias interpretation of data. Students will learn how well-designed visualizations can reduce bias and improve comprehension for data thereby facilitating data-driven decision-making. Students will explore techniques for creating effective visualizations based on principles from cognitive and perceptual psychology, art, and design. Students will gain hands-on experience coding real-world data visualizations for local offices, organizations, and industry participants.\nThe course is targeted toward students with expressed interest in cognition and cognitive biases related to data communication, students interested in using visualization to communicate their own messages, and students interested in creating better visualization tools and systems. Students will engage in discussions of the readings, complete programming and data analysis assignments, and prepare a final project involving storytelling with data visualizations.\nPrerequisite: For data-science sequence or majors (level-A data-science course); recommended a course in Perception, Visual Attention, Cognitive Psychology, or Cognitive Science; or permission of instructor\n\nCourse Specific Learning Goals\n\nUnderstand various uses of visual variables to create data visualizations;\nUnderstand both advantages and disadvantages of using visual variables to create data visualizations;\nAnalyze, critique, and revise data visualizations;\nUnderstand the functionality of the ggplot2 library for creating data visualizations;\nPresent data with visual representations for your target audience, task, and data;\nIdentify appropriate data visualization techniques given particular requirements imposed by the data and/or audience; and\nApply appropriate design principles in the creation of presentations and visualizations\n\nThe following departmental learning goals will also be met: 1. Knowledge of major concepts in cognitive psychology; 2. Understanding of research methods in psychology, including research design, data analysis and interpretation; 3. Development of critical-thinking skills and use of the scientific approach to solve problems related to behavior and mental processes; 4. Oral and written communication skills."
  },
  {
    "objectID": "syllabus/syllabus.html#courses-at-cmc",
    "href": "syllabus/syllabus.html#courses-at-cmc",
    "title": "Syllabus",
    "section": "Courses at CMC",
    "text": "Courses at CMC\n\nFaculty Handbook 5.4.2 Work Load in Classes\n“Courses should involve approximately equal workloads. Generally, students should expect to spend from 6 to 8 hours per week, over and above the time spent in classroom, on each course.” – CMC Faculty Handbook\nIf you do the math, including class time of 2½ hours, you should expect to allocate 8 to 10 hours per week for courses at CMC. “Per week” is a key phrase; courses are not designed for nondistributed cramming."
  },
  {
    "objectID": "syllabus/syllabus.html#course-materials-and-textbook",
    "href": "syllabus/syllabus.html#course-materials-and-textbook",
    "title": "Syllabus",
    "section": "Course Materials and Textbook",
    "text": "Course Materials and Textbook\nAll of the course materials will be available on this course website .\nLink to the course website: https://gabrielcook.xyz/dataviz24/\n\nRequired Equipment:\nComputer: current Mac (macOS) or PC (Windows or Linux) with high-speed internet connection, capable of running R and RStudio; hard-drive space about 5 GB\n\n\nRequired Software:\nR and RStudio: Students will be required to use R and RStudio software. Note: Install Version will be provided. Before installing RStudio, you must also download and install the base R software at https://www.r-project.org/ that is appropriate for your computer’s operating system. RStudio can be downloaded for free at https://www.rstudio.com. You are expected to install R and RStudio on your personal computer by downloading the software from the links above. You will also have to install appropriate libraries throughout the course. Further instructions will be provided.\n\n\nReading Materials/Textbook(s)\nReading materials will be represented in the course modules and will be referenced there in. Some topics will require reading external to the module content, so make sure to check and plan accordingly.\nOther free and open-source materials on the topic that you might find interesting include:\n\nWickham, H., Navarro. D., & Pedersen, T. L. ggplot2: Elegant Graphics for Data Analysis, 3rd ed.*\nClaus O. Wilke (2019). Fundamentals of Data Visualization. O’Reilly Media.\nXie, Y., Allaire, J. J., & Grolemund, G. R Markdown: The Definitive Guide\nKieran Healy (2018). Data Visualization: A Practical Introduction. Princeton University Press.\nNordmann, E. & DeBruine, L. (2023). Applied Data Skills: Processing & Presenting Data (2023) . https://psyteachr.github.io/ads-v2"
  },
  {
    "objectID": "syllabus/syllabus.html#course-structure",
    "href": "syllabus/syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nStudents are expected to participate in all aspects of the class. This class involves developing topic knowledge and computer programming skills for visualizing data. The assumption is that students possess varying levels of skills related to programming. Class time will be spend engaging in a variety of tasks and activities, including lectures, group-work, applied coding activities, presentations, and discussions.\nThese textbooks are free and open-source."
  },
  {
    "objectID": "syllabus/syllabus.html#overview",
    "href": "syllabus/syllabus.html#overview",
    "title": "Syllabus",
    "section": "Overview",
    "text": "Overview\nStudents will read materials covering data-set relevant cognitive functions or abilities and tasks or tools used to measure those abilities. They will also will learn about coding in R, data validation and wrangling, and support their current knowledge of statistical probability and inference.\nCoding for Data Science: Students will be introduced to functional programming using R, application of models, and use of popular data-science libraries, (e.g., dplyr, ggplot, stringr, etc.). Students would learn elements of programming (e.g., assignment, functions, function arguments, operators, objects, passing objects, control flow, etc.).\nData Validation and Wrangling: Students will learn how to wrangle raw data, clean, and manipulate data. The course would involve both data wrangling and data cleaning. Students would learn main concepts of data sanitation of messy data, for example, how to clean, recode, de-dup, fix structural errors and typos, standardize data, etc. in service of applying machine-learning models.\nProject Management: Projects for academics and industry involve collaboration as well as organization of code and materials. Students will learn about and maintain a project with an organized directory structure both locally and remotely with collaborators using Git and GitHub.\nAcademic Integrity. Although you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated.\nMany students are unclear of the definition of plagiarism and for that reason I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\nCourse Modules. This course will be split into modules, allocating various weeks depending on the scope of the module."
  },
  {
    "objectID": "syllabus/syllabus.html#course-structure-1",
    "href": "syllabus/syllabus.html#course-structure-1",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nStudents are expected to participate in all aspects of the class. This class involves developing topic knowledge and computer programming skills for visualizing data. The assumption is that students possess varying levels of skills related to programming. Nevertheless, students are expected to attend class prepared to engage with and practice concepts related to readings and lectures. Prior to class, students should have completed course content (e.g., videos, modules, or readings referenced therein) and watched any associated lectures on the material. Class time will involve answering questions raised by students, a mini lecture, and coding activities that will inform the final project (note, concepts build). Homework assignments will also involved engagement with the project data. Class time will be spent engaging in a variety of tasks and activities, including lectures, group-work, applied coding activities, presentations, and discussions."
  },
  {
    "objectID": "syllabus/syllabus.html#course-schedule",
    "href": "syllabus/syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\n\n\n\nCalendar Date\nWeek Day\nModule Content\nHomework Assignment\nKnowledge Assessment\n\n\n\n\nDue By First Class\n\nInstallation & Setup\n\n\n\n\n27-Aug\nT\nIntroduction\n\n\n\n\n29-Aug\nR\nProject Management (Parts 1 and 2)\n\n\n\n\n03-Sept\nT\nGraphical Perception\n\n\n\n\n05-Sept\nR\nData Frame Manipulation and Wrangling\n\n\n\n\n10-Sept\nT\nData Subsets and Summaries\n\n\n\n\n12-Sept\nR\nConsiderations in Data Visualization\n\n\n\n\n17-Sept\nT\nDesigning Perceptually Efficient Visualizations\nHW 01\nKA 1\n\n\n19-Sept\nR\nThe Grammar of Graphics\n\n\n\n\n24-Sept\nT\nVisualizing Amounts\nHW 02\n\n\n\n26-Sept\nR\nVisualizing Associations\n\n\n\n\n01-Oct\nT\nSpatial Position and Adjustment\nHW 03\nKA 2\n\n\n03-Oct\nR\nColor Scales and Palettes\n\n\n\n\n08-Oct\nT\nHistograms and Density Plots\nHW 04\n\n\n\n10-Oct\nR\nCoordinates, Axes and Position Scales\n\n\n\n\n15-Oct\nT\nFall Break (no class)\n\n\n\n\n17-Oct\nR\nStatistical Transformations (Data as-is Versus Summaries)\n\n\n\n\n22-Oct\nT\nMore Data Wrangling\nHW 05\nKA 3\n\n\n24-Oct\nR\nMid-Term Presentation\n\n\n\n\n29-Oct\nT\nVisualizing More Distributions\nHW 06\n\n\n\n31-Oct\nR\nVisualizing Uncertainty\n\n\n\n\nNLT 31-Oct\n\nMid-Term Presentation to Liaison (By End of Day)\n\n\n\n\n05-Nov\nT\nLegends and Arrangement\nHW 07\nKA 4\n\n\n07-Nov\nR\nVisualizing Trends\n\n\n\n\n12-Nov\nT\nAnnotation and Text\nHW 08\n\n\n\n14-Nov\nR\nMulti-Panel Plots: Faceting and Layers\n\n\n\n\n19-Nov\nT\nAttentional Control and Tradeoffs\nHW 09\nKA 5\n\n\n21-Nov\nR\nTitles Captions & Tables\n\n\n\n\n26-Nov\nT\n[online] Catch-Up, Figure Design (Themes), or Team Project Preparation\nHW 10\n\n\n\n28-Nov\nR\nThanksgiving Break (no class)\n\n\n\n\n03-Dec\nT\nCatch-Up or Team Project Preparation\n\n\n\n\n05-Dec\nR\nIn-Class Presentation (Last day of Class)\n\n\n\n\nNLT13-Dec\nFri\nFinals Week: Final Push to Repo/Written Report (By Noon)\n\nMU\n\n\nNLT13-Dec\nFri\nFinal Presentation to Liaison (By End of Day) - Do Not Schedule your departure prior to presenting to your project’s organization, otherwise expect a grade deduction. The semester schedule and final-exam schedule were available during registration time.\n\n\n\n\nNote(s):\n\nAssessments will take place during the first 10 minutes of class time. If you are late and cannot finish in the time allotted, see below.\n\n\n\n\n\n\nThere will be 1 optional make-up/replacement assessment (MU) offered which can replace a missed assessment or homework or unsatisfactory assessment or homework. The percentage value (not point value) will be applied to items of unequal point value.\n\n\n\n\n\n\nNLT = No Later Than"
  },
  {
    "objectID": "syllabus/syllabus.html#assignments-and-grading",
    "href": "syllabus/syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThis is an engagement and skills-acquisition based course. Students will have opportunities to strengthen skills outside of the classroom in preparation of performing class exercises related to the team project, take computer-free quizzes that involve writing and evaluating code and objects returned from code. Failure to engage in material or rely on ChatGPT or other AI tools will likely result in an inability to perform well on quizzes. The team project involves weekly data manipulation and visualization as well as presentations and a final deliverable.\nStudents are expected to make progress weekly on the team project by completing projects elements that are currently possible to complete (e.g., organizing the repo and its directories, editing the R Markdowns files, ensuring reproducibility, drafting background content, etc.). Procrastination on your part will bring you unnecessary stress and anxiety, a lower quality deliverable, and diffusion of responsibility that I was somehow responsible for your oversight. In turn, your frustration may result in lower course evaluations for me. I am fine with this.\n\nEvaluation and Grading\n\n\n\n\n\nItem\nTotal Points (%)\nPoints\n\n\n\n\nReadings & Videos (by class time)\n5%\n20\n\n\nIn-Class Knowledge Assessments\n20%\n80\n\n\nConceptual and Programming Homework\n20%\n80\n\n\nMidterm Presentation\n20%\n80\n\n\nFinal Project (Pres and Report)\n35%\n140\n\n\n\n\n\nPercentage grades are converted to letter grades according to the following rubric.\n\n\n\n\n\nLetter\n% Range\n\n\n\n\nA\n94 - 100\n\n\nA-\n90 - 93.99\n\n\nB+\n87 - 89.99\n\n\nB\n84 - 86.99\n\n\nB-\n80 - 83.99\n\n\nC+\n77 - 79.99\n\n\nC\n74 - 76.99\n\n\nC-\n70 - 73.99\n\n\nD+\n67 - 69.99\n\n\nD\n64 - 66.99\n\n\nD-\n60 - 63.99\n\n\nF\n0 - 59.99"
  },
  {
    "objectID": "syllabus/syllabus.html#attendance",
    "href": "syllabus/syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\nStudents are expected to attend and participate in each class. If you are unable to attend class, you need not provide any rationale or excuse. You are, however, responsible for submitting homework that is due for that day and for accepting the responsibility for missing assessments on that day. Class time will be used to address coding concerns, work through project-related exercises with your team, and practice coding to build skills. If you elect not to participate, please understand that decision will be reflected in class performance related to quality, professionalism, team contributions, etc."
  },
  {
    "objectID": "syllabus/syllabus.html#course-policies",
    "href": "syllabus/syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nDue dates\nDue dates are suggestions for completing coursework on a weekly basis. There is a lag with homework assignment content so that you are able to complete them early if desired. You may be able to work ahead but you are not encouraged to fall behind. Late homework will be reduced at 50%. \nYou should email me if you have an exceptional circumstance preventing you from taking an assessment during an assessment week.\n\n\nChanges to the syllabus\nThe syllabus may be updated for clarity or to make adjustments for pedagogical purposes. The most current version of the syllabus is always available from the course website.\n\n\nAccessibility\nI have a disability and understand your needs. In order to receive disability-related academic accommodations students should contact me for arrangements as per instruction from disability services.\n\n\nCorrespondence\nI may on occasion need to use e-mail but you should contact me on the Discord channel, which is where I will post announcements, changes, reminders, etc. You are responsible for monitoring Discord and e-mail regularly.\nIf you have questions, please message me on Discord.\nIf you need to e-mail me:\n\nAlways add ’PSYC 167” to the subject line\nemail me at: gcook@cmc.edu"
  },
  {
    "objectID": "syllabus/syllabus.html#college-policy-on-academic-integrity",
    "href": "syllabus/syllabus.html#college-policy-on-academic-integrity",
    "title": "Syllabus",
    "section": "College Policy on Academic Integrity",
    "text": "College Policy on Academic Integrity\nThe faculty and administration of Claremont McKenna College support an environment free from cheating and plagiarism. Each student is responsible for being aware of what constitutes cheating and plagiarism and for avoiding both.\n\nViolations of Academic integrity\nEach student is responsible for understanding and acting in accordance with the College’s policy on Academic Integrity, described below.\n\n\nAcademic Integrity\nAlthough you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty, even those raised by concerned peers, will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated. Many students are unclear of the definition of plagiarism so I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course and would be a violation of integrity. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\n\nStatement of Reasonable Accommodations\nI have an eye disease and visual impairment and understand the need for accommodations. Your experience in this class is important to me. If you have already established accommodations with Disability & Accessibility Services at CMC, please communicate your approved accommodations to me during the first week of the semester so we can discuss your needs in this course ASAP. You can start this conversation by forwarding me your accommodation letter. If you have not yet established accommodations through Accessibility Services but have a temporary health condition or permanent disability (conditions include but are not limited to: mental health, attention-related, learning, vision, hearing, physical or health), you are encouraged to contact Assistant Dean for Disability Services & Academic Success, Kari Rood, at AccessibilityServices@cmc.edu to ask questions and/or begin the process. General information and accommodations request information be found at the CMC DOS Accessibility Service’s website. Please note that arrangements must be made with advance notice in order to access the reasonable accommodations. You are able to request accommodations from CMC Accessibility Services at any point in the semester. Be mindful that this process may take some time to complete and accommodations are not retroactive. I would err on the side of caution and make sure your accommodations are sent to me even if you do not believe you need them as some students only learn they may need time after completing assessment. The Americans With Disabilities Act (ADA) and Section 504 of the Rehabilitation Act do not make accommodations retroactive. If you are approved for extra testing time for example, you must do so before an electronic assessment is posted in order for it to be integrated into the assessment. Claremont McKenna College values creating inclusive and accessible learning environments consistent with federal and state law. If you are not a CMC student, please connect with the Disability & Accessibility Services Coordinator on your campus regarding a similar process.\n\n\n\nFYI on cheating etc.\nRemember, you are responsible for not cheating or violating CMC’s Academic Integrity Policy. You are responsible for understanding that policy, and for conducting yourself in a manner such that you do not violate the policy.\nThe above link lists many examples of cheating and plagiarism that are not allowed. There are many more specific acts that you should NOT do. Here is an additional list of activities that will be sufficient cause for immediate failure in the course.\n\nDo not take pictures of exam or quiz questions and share them with other students\nDo not give other students answers during an exam or quiz, or any other assignment that is an individual assignment\nDo not copy work from another source and submit it as your own\nDo not copy and paste text from the internet and submit it as your own words\nDo not copy and paste text and slightly alter wording to pass the work off as your own\nDo not hire someone else to do the coursework for you\nDo not copy and paste text into a paraphrasing app, and then submit the output of the paraphrasing app as your own work\nDo not copy random words from the internet that have nothing to do with the assignment and submit them as your own work.\nDo not work on individual assignments with other students, share answers or other material, and then all hand in versions of the same thing that are slightly different.\nDo not plagiarize yourself by submitting work that you have previously completed in another class.\n\n\n\nMandate to report violations\nIf a faculty member suspects a violation of academic integrity and, upon investigation, confirms that violation, or if the student admits the violation, the faculty member MUST report the violation. Students should be aware that faculty may use plagiarism detection software.\nThere is no excuse for cheating. Students who are caught cheating may receive a failing grade for the entire course. All students found to have violated the academic integrity will be sanctioned by the Academic Standards Committee."
  },
  {
    "objectID": "syllabus/syllabus.html#faq",
    "href": "syllabus/syllabus.html#faq",
    "title": "Syllabus",
    "section": "FAQ",
    "text": "FAQ\nIf you have questions about the syllabus, let’s talk about it in class, and/or please create a thread to discuss the question on Discord."
  },
  {
    "objectID": "slides/02_git_slides.html#what-is-version-control-for",
    "href": "slides/02_git_slides.html#what-is-version-control-for",
    "title": "Git and GitHub",
    "section": "What is version control for?",
    "text": "What is version control for?\n\n\nProject backup\nGit monitors/controls file versions (empty directories).\nSee specific changes inside files\nUndo changes (time machine)\nVersion Control Summary Video"
  },
  {
    "objectID": "slides/02_git_slides.html#version-control-git-workflow-basics",
    "href": "slides/02_git_slides.html#version-control-git-workflow-basics",
    "title": "Git and GitHub",
    "section": "Version Control: Git Workflow Basics",
    "text": "Version Control: Git Workflow Basics\nThere are 4 main parts to Git Workflow:\n\n\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)\nPush for sending commits to remote repo (on GitHub)\n\n\nOther: Merge for merging branches (i.e., to incorporate your edits into main)\nVideo of Version Control Workflow Basics\n\n\n\n## **Git: Image Version**\n\n@[understanding git through images](https://dev.to/nopenoshishi/understanding-git-through-images-4an1)"
  },
  {
    "objectID": "slides/02_git_slides.html#connecting-git-to-github-the-rstudio-terminal",
    "href": "slides/02_git_slides.html#connecting-git-to-github-the-rstudio-terminal",
    "title": "Git and GitHub",
    "section": "Connecting Git to GitHub: The RStudio Terminal",
    "text": "Connecting Git to GitHub: The RStudio Terminal\n\n\nConfigure Git and GitHub in RStudio Terminal\nCreate token\nSet token\nCan use the RStudio Gui (clunky though)"
  },
  {
    "objectID": "slides/02_git_slides.html#configuring-git-and-github-with-usethis",
    "href": "slides/02_git_slides.html#configuring-git-and-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Configuring Git and GitHub with {usethis}",
    "text": "Configuring Git and GitHub with {usethis}\n\nusethis::use_git_config(user.name = \"janegit\", \n                        user.email = \"jane_git@gitrdone.com\"\n                        )"
  },
  {
    "objectID": "slides/02_git_slides.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "href": "slides/02_git_slides.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Creating a Personal Access Token (PAT) for GitHub with {usethis}",
    "text": "Creating a Personal Access Token (PAT) for GitHub with {usethis}\n\n\nusethis::create_github_token()\nCreate token and copy to your clipboard"
  },
  {
    "objectID": "slides/02_git_slides.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "href": "slides/02_git_slides.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "title": "Git and GitHub",
    "section": "Setting your Git Credentials (using PAT) with {gitcreds}",
    "text": "Setting your Git Credentials (using PAT) with {gitcreds}\n\n\ngitcreds::gitcreds_set()\nChoose option to either set or replace\nAt ? Enter new password or token, paste PAT to set\ngh::gh_whoami() to check if set"
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands",
    "href": "slides/02_git_slides.html#some-basic-commands",
    "title": "Git and GitHub",
    "section": "Some Basic Commands",
    "text": "Some Basic Commands\n\nFork: to make a copy of a repo in your own GitHub account\nClone: make a copy of the your GitHub repo on your local computer. * copies a remote repo to create a local repo with a remote called origin automatically set up."
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands-cont.",
    "href": "slides/02_git_slides.html#some-basic-commands-cont.",
    "title": "Git and GitHub",
    "section": "Some Basic Commands (Cont.)",
    "text": "Some Basic Commands (Cont.)\n\nPull: incorporates changes into your repo from remote\nAdd: adds snapshots of your changes to the “Staging” area.\nCommit: takes the files as they are in your staging area and stores a snap shot of your files (changes) permanently in your Git directory\nPush: uploads your files (changes) to the remote repo\nStatus: checks the status of a repo changes, etc."
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands-cont.-1",
    "href": "slides/02_git_slides.html#some-basic-commands-cont.-1",
    "title": "Git and GitHub",
    "section": "Some Basic Commands (Cont.)",
    "text": "Some Basic Commands (Cont.)\n\nMerge: incorporates changes into the branch you are on.\nPull Request: By “issuing a pull request” to the owner of the upstream repo, you are requesting that your changes be pulled into their repo (accept your changes/work)."
  },
  {
    "objectID": "slides/02_git_slides.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "slides/02_git_slides.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Git and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\n\nMake a change to a file, save to local computer\nCheck status of project for changes\nAdd/Stage change\nCommit change(s)\nPush changes\nPull pulls changes down from repo (downloads and merges changes)"
  },
  {
    "objectID": "slides/02_git_slides.html#checking-the-status-of-local-file-changes",
    "href": "slides/02_git_slides.html#checking-the-status-of-local-file-changes",
    "title": "Git and GitHub",
    "section": "Checking the Status of Local File Changes",
    "text": "Checking the Status of Local File Changes\nAt the Terminal in RStudio\n\n$ git status"
  },
  {
    "objectID": "slides/02_git_slides.html#shared-repository-workflow",
    "href": "slides/02_git_slides.html#shared-repository-workflow",
    "title": "Git and GitHub",
    "section": "Shared Repository Workflow",
    "text": "Shared Repository Workflow\n\n\nPull recent changes from main: git pull\nMake changes to files\nStage your changes: git add\nCommit changes locally: git commit -m \"description of changes\"\nUpload your new the changes to GitHub: git push"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-changes-adding-changes",
    "href": "slides/02_git_slides.html#staging-changes-adding-changes",
    "title": "Git and GitHub",
    "section": "Staging Changes (Adding Changes)",
    "text": "Staging Changes (Adding Changes)\n\n\nStaging and Committing\n\nUntracked vs. tracked files\nTo have tracked by Git, you need to add"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-a-specific-change",
    "href": "slides/02_git_slides.html#staging-a-specific-change",
    "title": "Git and GitHub",
    "section": "Staging a Specific Change",
    "text": "Staging a Specific Change\n\n\n$ git add &lt;file&gt;... such that &lt;file&gt; refers to the file name\nfile might be in a directory, e.g., r/\n$ git add r/yourname.R\nTab to auto-complete, e.g., git add r/you{TAB}"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-all-changes",
    "href": "slides/02_git_slides.html#staging-all-changes",
    "title": "Git and GitHub",
    "section": "Staging All Changes",
    "text": "Staging All Changes\n\n$ git add ."
  },
  {
    "objectID": "slides/02_git_slides.html#committing-the-changes",
    "href": "slides/02_git_slides.html#committing-the-changes",
    "title": "Git and GitHub",
    "section": "Committing the Change(s)",
    "text": "Committing the Change(s)\n\n\ngit commit is used to commit the changes\nadd -m to tell git you want a message (e.g., \"my message here\")\n\n$ git commit -m \"added my first .R file\""
  },
  {
    "objectID": "slides/02_git_slides.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "href": "slides/02_git_slides.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Push (publish) the change(s) from your branch to the remote repository",
    "text": "Push (publish) the change(s) from your branch to the remote repository\n\n\n$ git push\nPushing changes"
  },
  {
    "objectID": "slides/02_git_slides.html#pulls-changes-from-the-remote-repository",
    "href": "slides/02_git_slides.html#pulls-changes-from-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Pulls change(s) from the remote repository",
    "text": "Pulls change(s) from the remote repository\n\n\n$ git pull\nIf you make changes that other will need, let them know to pull"
  },
  {
    "objectID": "slides/02_git_slides.html#git-client-video-tutorials",
    "href": "slides/02_git_slides.html#git-client-video-tutorials",
    "title": "Git and GitHub",
    "section": "Git Client Video Tutorials",
    "text": "Git Client Video Tutorials\n\n\nGitKraken Git Client examples\nfor more, see: this video"
  },
  {
    "objectID": "slides/02_git_slides.html#videos-of-many-things-you-can-do",
    "href": "slides/02_git_slides.html#videos-of-many-things-you-can-do",
    "title": "Git and GitHub",
    "section": "Videos of many things you can do",
    "text": "Videos of many things you can do\nIf interested, see gittower YouTube"
  },
  {
    "objectID": "slides/023_git.html#version-control",
    "href": "slides/023_git.html#version-control",
    "title": "Git and GitHub",
    "section": "Version Control",
    "text": "Version Control\n\n\nWhat is version control?\n\nProject backup\nSee specific changes inside files\nUndo changes (time machine)\n\nVersion Control Summary Video"
  },
  {
    "objectID": "slides/023_git.html#version-control-git-workflow-basics",
    "href": "slides/023_git.html#version-control-git-workflow-basics",
    "title": "Git and GitHub",
    "section": "Version Control: Git Workflow Basics",
    "text": "Version Control: Git Workflow Basics\nThere are three main parts to Git Workflow:\n\n\nVersion control for files (not empty directories)\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)\nVersion Control Workflow Basics"
  },
  {
    "objectID": "slides/023_git.html#connecting-git-to-github-the-rstudio-terminal",
    "href": "slides/023_git.html#connecting-git-to-github-the-rstudio-terminal",
    "title": "Git and GitHub",
    "section": "Connecting Git to GitHub: The RStudio Terminal",
    "text": "Connecting Git to GitHub: The RStudio Terminal\n\n\nConfigure Git and GitHub in RStudio Terminal\nCreate token\nSet token\nCan use the RStudio Gui (clunky though)"
  },
  {
    "objectID": "slides/023_git.html#configuring-git-and-github-with-usethis",
    "href": "slides/023_git.html#configuring-git-and-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Configuring Git and GitHub with {usethis}",
    "text": "Configuring Git and GitHub with {usethis}\n\nusethis::use_git_config(user.name = \"janegit\", \n                        user.email = \"jane_git@gitrdone.com\"\n                        )"
  },
  {
    "objectID": "slides/023_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "href": "slides/023_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Creating a Personal Access Token (PAT) for GitHub with {usethis}",
    "text": "Creating a Personal Access Token (PAT) for GitHub with {usethis}\n\n\nusethis::create_github_token()\nCreate token and copy to your clipboard"
  },
  {
    "objectID": "slides/023_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "href": "slides/023_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "title": "Git and GitHub",
    "section": "Setting your Git Credentials (using PAT) with {gitcreds}",
    "text": "Setting your Git Credentials (using PAT) with {gitcreds}\n\n\ngitcreds::gitcreds_set()\nChoose option to either set or replace\nAt ? Enter new password or token, paste PAT to set\ngh::gh_whoami() to check if set"
  },
  {
    "objectID": "slides/023_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "slides/023_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Git and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\n\nMake a change to a file\nCheck status of project for changes\nStage change\nCommit all changes\nPush changes\nCommit a specific change\nPull changes down from repo (downloads and integrates changes)\nFetch downloads new data (does not change your working copy)"
  },
  {
    "objectID": "slides/023_git.html#checking-the-status-of-local-file-changes",
    "href": "slides/023_git.html#checking-the-status-of-local-file-changes",
    "title": "Git and GitHub",
    "section": "Checking the status of local file changes",
    "text": "Checking the status of local file changes\nAt the Terminal in RStudio\n\n$ git status"
  },
  {
    "objectID": "slides/023_git.html#staging-changes-adding-changes",
    "href": "slides/023_git.html#staging-changes-adding-changes",
    "title": "Git and GitHub",
    "section": "Staging Changes (Adding Changes)",
    "text": "Staging Changes (Adding Changes)\n\n\nStaging and Committing\n\nUntracked vs. tracked files\nTo have tracked by Git, you need to add"
  },
  {
    "objectID": "slides/023_git.html#staging-a-specific-change",
    "href": "slides/023_git.html#staging-a-specific-change",
    "title": "Git and GitHub",
    "section": "Staging a Specific Change",
    "text": "Staging a Specific Change\n\n\n$ git add &lt;file&gt;... such that &lt;file&gt; refers to the file name\nfile might be in a directory, e.g., r/\n$ git add r/yourname.R\nTab to auto-complete, e.g., git add r/you{TAB}"
  },
  {
    "objectID": "slides/023_git.html#staging-all-changes",
    "href": "slides/023_git.html#staging-all-changes",
    "title": "Git and GitHub",
    "section": "Staging All Changes",
    "text": "Staging All Changes\n\n$ git add ."
  },
  {
    "objectID": "slides/023_git.html#committing-the-changes",
    "href": "slides/023_git.html#committing-the-changes",
    "title": "Git and GitHub",
    "section": "Committing the Change(s)",
    "text": "Committing the Change(s)\n\n\ngit commit is used to commit the changes\nadd -m to tell git you want a message (e.g., \"my message here\")\n\n$ git commit -m \"added my first .R file\""
  },
  {
    "objectID": "slides/023_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "href": "slides/023_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Push (publish) the change(s) from your branch to the remote repository",
    "text": "Push (publish) the change(s) from your branch to the remote repository\n\n\n$ git push\nPushing changes"
  },
  {
    "objectID": "slides/023_git.html#pulls-changes-from-the-remote-repository",
    "href": "slides/023_git.html#pulls-changes-from-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Pulls change(s) from the remote repository",
    "text": "Pulls change(s) from the remote repository\n\n\n$ git pull\nIf you make changes that other will need, let them know to pull"
  },
  {
    "objectID": "slides/023_git.html#fetch-changes",
    "href": "slides/023_git.html#fetch-changes",
    "title": "Git and GitHub",
    "section": "Fetch changes",
    "text": "Fetch changes"
  },
  {
    "objectID": "slides/023_git.html#video-tutorials",
    "href": "slides/023_git.html#video-tutorials",
    "title": "Git and GitHub",
    "section": "Video Tutorials",
    "text": "Video Tutorials\n\n\nGitKraken Git Client examples\nfor more, see: this video"
  },
  {
    "objectID": "slides/023_git.html#videos-of-many-things-you-can-do",
    "href": "slides/023_git.html#videos-of-many-things-you-can-do",
    "title": "Git and GitHub",
    "section": "Videos of many things you can do",
    "text": "Videos of many things you can do\nIf interested, see gittower YouTube"
  },
  {
    "objectID": "schedule/index.html",
    "href": "schedule/index.html",
    "title": "Schedule",
    "section": "",
    "text": "Calendar Date\nWeek Day\nModule Content\nHomework Assignment\nKnowledge Assessment\n\n\n\n\nDue By First Class\n\nInstallation & Setup\n\n\n\n\n27-Aug\nT\nIntroduction\n\n\n\n\n29-Aug\nR\nProject Management (Parts 1 and 2)\n\n\n\n\n03-Sept\nT\nGraphical Perception\n\n\n\n\n05-Sept\nR\nData Frame Manipulation and Wrangling\n\n\n\n\n10-Sept\nT\nData Subsets and Summaries\n\n\n\n\n12-Sept\nR\nConsiderations in Data Visualization\n\n\n\n\n17-Sept\nT\nDesigning Perceptually Efficient Visualizations\nHW 01\nKA 1\n\n\n19-Sept\nR\nThe Grammar of Graphics\n\n\n\n\n24-Sept\nT\nVisualizing Amounts\nHW 02\n\n\n\n26-Sept\nR\nVisualizing Associations\n\n\n\n\n01-Oct\nT\nSpatial Position and Adjustment\nHW 03\nKA 2\n\n\n03-Oct\nR\nColor Scales and Palettes\n\n\n\n\n08-Oct\nT\nHistograms and Density Plots\nHW 04\n\n\n\n10-Oct\nR\nCoordinates, Axes and Position Scales\n\n\n\n\n15-Oct\nT\nFall Break (no class)\n\n\n\n\n17-Oct\nR\nStatistical Transformations (Data as-is Versus Summaries)\n\n\n\n\n22-Oct\nT\nMore Data Wrangling\nHW 05\nKA 3\n\n\n24-Oct\nR\nMid-Term Presentation\n\n\n\n\n29-Oct\nT\nVisualizing More Distributions\nHW 06\n\n\n\n31-Oct\nR\nVisualizing Uncertainty\n\n\n\n\nNLT 31-Oct\n\nMid-Term Presentation to Liaison (By End of Day)\n\n\n\n\n05-Nov\nT\nLegends and Arrangement\nHW 07\nKA 4\n\n\n07-Nov\nR\nVisualizing Trends\n\n\n\n\n12-Nov\nT\nAnnotation and Text\nHW 08\n\n\n\n14-Nov\nR\nMulti-Panel Plots: Faceting and Layers\n\n\n\n\n19-Nov\nT\nAttentional Control and Tradeoffs\nHW 09\nKA 5\n\n\n21-Nov\nR\nTitles Captions & Tables\n\n\n\n\n26-Nov\nT\n[online] Catch-Up, Figure Design (Themes), or Team Project Preparation\nHW 10\n\n\n\n28-Nov\nR\nThanksgiving Break (no class)\n\n\n\n\n03-Dec\nT\nCatch-Up or Team Project Preparation\n\n\n\n\n05-Dec\nR\nIn-Class Presentation (Last day of Class)\n\n\n\n\nNLT13-Dec\nFri\nFinals Week: Final Push to Repo/Written Report (By Noon)\n\nMU\n\n\nNLT13-Dec\nFri\nFinal Presentation to Liaison (By End of Day) - Do Not Schedule your departure prior to presenting to your project’s organization, otherwise expect a grade deduction. The semester schedule and final-exam schedule were available during registration time.\n\n\n\n\nNote(s):\n\nAssessments will take place during the first 10 minutes of class time. If you are late and cannot finish in the time allotted, see below.\n\n\n\n\n\n\nThere will be 1 optional make-up/replacement assessment (MU) offered which can replace a missed assessment or homework or unsatisfactory assessment or homework. The percentage value (not point value) will be applied to items of unequal point value.\n\n\n\n\n\n\nNLT = No Later Than"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to prepare, model, and visualize data in order to communicate a story that would address the question(s) proposed by the participating body (viz., liaison). Each project will differ but there will be similarities across projects, for example, cleaning data, managing variables, creating data summaries, creating visualizations, telling a coherent story, etc.\nEach project has a primary goal which is necessary to include for the final deliverable. If the team can adequately deliver the primary goal, additional goals can be worked on by eager teams. There may be exploratory components, which would allow for a healthy dose of flexibility in team creativity. Exploratory elements, however, should be discussed carefully with project liaisons."
  },
  {
    "objectID": "project/index.html#project-description",
    "href": "project/index.html#project-description",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to prepare, model, and visualize data in order to communicate a story that would address the question(s) proposed by the participating body (viz., liaison). Each project will differ but there will be similarities across projects, for example, cleaning data, managing variables, creating data summaries, creating visualizations, telling a coherent story, etc.\nEach project has a primary goal which is necessary to include for the final deliverable. If the team can adequately deliver the primary goal, additional goals can be worked on by eager teams. There may be exploratory components, which would allow for a healthy dose of flexibility in team creativity. Exploratory elements, however, should be discussed carefully with project liaisons."
  },
  {
    "objectID": "project/index.html#team-membership-and-roles",
    "href": "project/index.html#team-membership-and-roles",
    "title": "Project",
    "section": "Team Membership and Roles",
    "text": "Team Membership and Roles\nA team of students will work with a project liaison to develop the project and work together to produce the midterm and final deliverables. Rather than having all students in charge of all duties, team members should consider delegating tasks and various types of workloads to students who are best equipped to handle them either because of ability or because of interest and desire. Teams are to meet weekly and members are to complete individual work log reports, which are used for final grading."
  },
  {
    "objectID": "project/index.html#team-meetings",
    "href": "project/index.html#team-meetings",
    "title": "Project",
    "section": "Team Meetings",
    "text": "Team Meetings\nTeam meetings will be weekly and in-person. The team will determine when all members can meet at the same time each week to discuss their weekly accomplishments, upcoming goals, setbacks, etc. The PM will share with me the time and the location of the meeting."
  },
  {
    "objectID": "project/index.html#deliverables",
    "href": "project/index.html#deliverables",
    "title": "Project",
    "section": "Deliverables",
    "text": "Deliverables\n\nMidterm Presentation\nFinal Presentation\nFinal R Markdown Report and pdf\nWork logs/GitHub commits"
  },
  {
    "objectID": "project/index.html#project-evaluation",
    "href": "project/index.html#project-evaluation",
    "title": "Project",
    "section": "Project Evaluation",
    "text": "Project Evaluation\nThe project has different components representing it at various stages (e.g., midterm presentation, final presentation and report). See those sections specifically but the following general items will be important to consider.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly work logs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\nPresentation Characteristics\nSee the midterm and final presentation guidelines for more detail and rubric but in general, the following characteristics will be evaluated.\n\nClarity: well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization: structured logically; ability to walk audience through the data journey and communicate a story interpretation about data\nThoroughness: all relevant issues discussed thoroughly\nPresentation Style: degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/index.html#weekly-work-logreport",
    "href": "project/index.html#weekly-work-logreport",
    "title": "Project",
    "section": "Weekly Work log/Report",
    "text": "Weekly Work log/Report\nTracking individual and team goals weekly ensures progress toward the goal, commitment to the project, accountability for oneself, and a record of accomplishments.\nThe Project Manager should inquire with the team about the best way to submit work logs or transparency and review. This could be a Google Doc File, a spreadsheet, or even a Google From that contains questions to answer, which then get dumped into a Google Spreadsheet for all to review.\n\nFrequency of Work log\nWork logs are to be completed by end-of-day following the team meeting, after communicating future goals (distributed equally) to other team members. Please make public for me to review. Meetings should be physical to facilitate team cohesion and conversation, and limit silly technical issues that just waste meeting time.\n\n\nContents of Work log\nWork logs should contain information about the reporting date (or be interactive as needed daily as with a Kanban), the team member reporting, that member’s previous week accomplishments, and that member’s future week goals. A recurring week Kanban spreadsheet would take care of this for each week of the project.\nA Kanban template for projects is located here. You are not required to use this form of work log but some teams have found it useful in the past so I have created one based on the nature of the class project. I have added fields that are relevant to your project so that team members can log work by week. You can certainly modify or add more fields on the Key sheet.\nAnother recommended work log is accessible here. This is a work log file distributed to DS180 Capstone Faculty to share with their teams but I find it a little more clunky than than Kanban."
  },
  {
    "objectID": "project/04_project_report.html",
    "href": "project/04_project_report.html",
    "title": "Final Report",
    "section": "",
    "text": "The final written report for the project will be delivered to me and to your liaison. I can provide a color-printed copy for you to distribute to the liaison and for their offices. The final report is to be created in R Markdown and knit as a Pdf or Word document. An example starter file can be found here. You are not to write the document in GoogleDocs, or other sharing platforms. The course is designed for you to acquire new skills and build confidence in those skills. Investing in yourself is what will get you internships, jobs, and leadership roles in labs and lab manager roles in graduate school. Thus, the report is to be created in R Markdown and maintained in the remote repository. Because RStudio does not have grammar check capability, you are free to create your own personal content in a Word Processing software like MS Word before you add the content to R Markdown. However, I advise you change the font in that working file to sans serif font because R Markdown may get confused with certain characters (e.g., serif font apostrophes, etc.) and you may need to fix these issues later. After running your grammar and spelling check, then add the content to the .Rmd file. If you do work in a separate file, you will need to make sure to save this file to the project /report directory and ensure you push that file to the remote repository. Also, make sure you use your initials in the file name so that team members don’t all have the same file names.\nA code lead should take on the responsibility to save the file to /report in the team project, add, commit, and push the file to the remote repo on GitHub. Some team members will not be familiar with using Git and the code lead is responsible for ensuring the report file is in the final project repo. Therefore, when team members work on their respective report content, I recommend an easy approach:\n\nThe team decides to work independently in their own RStudio project (e.g., \"dataviz-exercises\") and perhaps make a copy of the main .Rmd document that include team member’s initials as a suffix to the filename). The team delegates the sections to be written by specific team members. Each member edits their file, saves it, and ensures they can knit an HTML (or Word) version of the file. If successful without error, then send the the sections to the team member responsible for integrating the work into a team report. That team member integrates the content and ensures they can can knit it. That file is then sent to all team members for review before is it sent to the code lead for adding to the team’s official RStudio project (and remote repo). There are certainly limitations with this approach if executed in haste. As long as the team plans accordingly, this approach should be fine.\nThe team work collaboratively using Box Edit, Docs in Proton Drive which is free and private, or GoogleDocs. However, due to Google Privacy Issues, you cannot use GoogleDocs without a written approval from your team’s liaison. All team members can see the written content and make edits. A limitation is that R code blocks, R in-line code, and plots would not be visible unless added to the document.\n\nNote: Remember that with a version control system like Git, you always have access to all versions of the files pushed to GitHub. You can always revert to a prior version. I can help you with this if you get to this point. Good messages in your commits will be helpful here."
  },
  {
    "objectID": "project/04_project_report.html#abstract",
    "href": "project/04_project_report.html#abstract",
    "title": "Final Report",
    "section": "Abstract",
    "text": "Abstract\nThe abstract provides a main summary of data, problem, methods, and key findings."
  },
  {
    "objectID": "project/04_project_report.html#contents",
    "href": "project/04_project_report.html#contents",
    "title": "Final Report",
    "section": "Contents",
    "text": "Contents\nA contents pages, or table of contents, provides a listing of the document sections and subsections as we as a page for location.\n\nTitle Page\nAbstract\nTable of Contents\nAcknowledgments\n\nChapters:\n\nIntroduction\nData\nResults/Findings\nDiscussion\nConclusion\nReferences"
  },
  {
    "objectID": "project/04_project_report.html#sources-of-data",
    "href": "project/04_project_report.html#sources-of-data",
    "title": "Final Report",
    "section": "Sources of Data",
    "text": "Sources of Data\nWhat was the data source/where did you obtain it from? Include the source URL of the website from which you accessed the data. Include information about where and how the data were collected or obtained. Specify whether the data were obtained from internal databases, external sources, or gathered through specific methods (surveys, sensors, web scraping, etc.)."
  },
  {
    "objectID": "project/04_project_report.html#data-characteristics",
    "href": "project/04_project_report.html#data-characteristics",
    "title": "Final Report",
    "section": "Data Characteristics",
    "text": "Data Characteristics\nDiscuss the data in detail. In which format was the data stored? How many cases were there in total? How many variables were contained? What variables were contained? What were the key variables you used?\nDescribe the types of variables present in the data set (numerical, categorical, text, etc.). When discussing variables of the visualization in the results chapter, make sure to provide clarity about the variable, its metric, and reason for using that variable (e.g., mean, max, median, mean of max values, median of max values, dispersion measures, etc.).\nList and briefly describe each attribute, feature, or variable in the data set, paying special attention to those used for the project."
  },
  {
    "objectID": "project/04_project_report.html#data-quality-and-data-preprocessing",
    "href": "project/04_project_report.html#data-quality-and-data-preprocessing",
    "title": "Final Report",
    "section": "Data Quality and Data Preprocessing",
    "text": "Data Quality and Data Preprocessing\nDescribe the steps taken to clean and prepare the data for investigation. This description may include removing duplicates, standardizing formats, trimming, correcting inconsistencies, etc. Explain any criteria used to select variables or features for visualization, focusing on those with the greatest impact or insight for the organization’s understanding.\nSome key details to address include:\n\nMissing Values: Explain the presence and treatment of any missing data. Explain how missing values were handled during analysis (removal, replacement, etc.).\nOutliers and Anomalies: Mention any identified outliers or anomalies and how they were addressed (treatment or exclusion).\nVariables Created: Describe the variables created, their units of measurement, etc. Explain if any normalization or scaling procedures applied to create the variables and to ensure data consistency and comparability across measures.\n\nAlso, specify where the cleaned data may be obtained."
  },
  {
    "objectID": "project/04_project_report.html#data-limitations",
    "href": "project/04_project_report.html#data-limitations",
    "title": "Final Report",
    "section": "Data Limitations",
    "text": "Data Limitations\nHighlight any limitations or constraints of the data set that affected the team’s ability to address the initial problem. Similarly, describe how any limitations might affect the interpretation of the findings."
  },
  {
    "objectID": "project/02_project_midterm.html",
    "href": "project/02_project_midterm.html",
    "title": "Midterm presentation",
    "section": "",
    "text": "After having several weeks to investigate and examine your data, brainstorm potential key items to address, identify potential story lines, and create some data visualizations, the next step is to present to the class. You goal for the midterm presentation will be to present and discuss data visualizations, or variants thereof, that could find their way into the end-of-semester final presentation and report deliverable.\nYou will be evaluated on you and your team’s ability to convey the steps taken to clean up the data in service of creating some plots as well as share a decision-making journey of plot creation. Any variables that needed to be fixed or modified, factorized, computed anew, or summarized in some way can resulted in one single starting data frame/tibble and likely some smaller data summaries. Teams taking different approaches, or who are guided by liaisons who have different interests, will end up with different data, different data visualizations, and different stories. Include code where appropriate to communicate how you achieved your goals.\nAt this stage in the project, the important point is that all team members should be working with data, challenge themselves to think about data, and practice using {ggplot} for creating data visualizations. Thus, all team members must have two plots, even if those plots communicate detailed variants of the same performance metric. By plot variants, mean Same Data, Different Stories. Variant plots use the same data but are visualized differently in order to facilitate different comparisons, use additional date to provide a more nuanced or detailed interpretation, use different levels/grouping of exiting variables, or use a different scaling structures, etc. Alternatively, the two plots could visualize different metrics obtained from the data, different calculations of a metric, compare different calculations, etc. to represent depths to data inquiry.\nAn example of looking at the data in different ways is illustrated in Nathan Yau’s post One Dataset, Visualized 25 Ways. If you struggle to think about data, you can also check out his post on how to think like a statistician without the math. I believe that the most valuable comment is this post to in the Ask Why section. He explains that “…the most important thing I’ve learned, [is to] always ask why. When you see a blip in a graph, you should wonder why it’s there. If you find some correlation, you should think about whether or not it makes any sense. If it does make sense, then cool, but if not, dig deeper. Numbers are great, but you have to remember that when humans are involved, errors are always a possibility.” Asking why data are they way they are is important because patterns in data can happen by chance or for some systematic reason. Any systematic influence has to have a reason, an explanation for its presence. Although you may be able to describe a pattern or influence, if you cannot provide an explanation for it, there is no useful way to make that information actionable."
  },
  {
    "objectID": "project/02_project_midterm.html#data-cleaning-and-variable-creation",
    "href": "project/02_project_midterm.html#data-cleaning-and-variable-creation",
    "title": "Midterm presentation",
    "section": "Data Cleaning and Variable Creation",
    "text": "Data Cleaning and Variable Creation\nYou should communicate steps taken to clean data to fulfill sub-goals for different plots. I recommend sharing your code. The audience should understand the code and may have the capacity to identify errors.\n\nGeneral Data Cleaning\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of {dplyr} functions like group_by(), mutate(), filter(), ungroup(), or other functions from {stringr}, {tidyr} or otherwise for merging/joining, adding new variables, etc.\n\n\n\nData Summaries for Plots\n\nCommunicate how you calculated and/or obtained summary metrics\nCommunicate any usage of functions like group_by(), summarize(), filter(), or ungroup() to ensure your data are computed correctly"
  },
  {
    "objectID": "project/02_project_midterm.html#data-visualizations-story-telling-with-pictures",
    "href": "project/02_project_midterm.html#data-visualizations-story-telling-with-pictures",
    "title": "Midterm presentation",
    "section": "Data Visualizations: Story Telling with Pictures",
    "text": "Data Visualizations: Story Telling with Pictures\n\nConvey performance metrics using data visualizations\nWalk audience through an explanation of the visualizations\nConvey why you chose the data to plot and why you chose the plot to convey the data\nCommunicate plot limitations and intended amendments along with reasons why\n\nA plot is chosen as a visual aid for a talk, paper, news article, etc. for various reasons:\n\nwas the only plot created\nwas the only plot known how to create\nwas the best of several plots created\n\nEach data visualization must serve a goal for your audience. You should consider how you intend to talk about the visualization to your audience when you create it. If there are different ways to talk about the same data and more than one variant facilitates that communications, you may consider creating more than one.\nYou should stumble upon neither that goal nor the the geom type used to communicate that goal. Are you trying to communicate comparisons of some sort? If so, does the plot make that particular comparison easy?\n\nPlot Introduction\nBefore revealing your plot, set the stage for its intent. Use words. In your final report, you will be telling a story about the data. You will not just present plots and talk about them. For example, you make introduce a research question that the plot will either help answer or provide information about examining further. After walking the reader through the problem, you will reference a figure containing the plot. For the midterm presentation, you will similarly introduce a question that the plot will help address. Mention the data that the plot visualizes. Are these data minimums, maximums, means, medians, measures of variability, etc. Do the data represent groups of people? Do they include dates? Think of this step as a topic slide before presenting the plot. Your topic title should be brief and clear and you should fill in any more detail with words. This step will set the stage for the audience to understand what data you would be presenting before you throw a plot in their face.\n\n\nPlot Reveal and Explanation\nYou should make sure that you walk the reader through the data visualization. Be explicit about what the axes represent and what any aesthetics represent so that the audience does not have to figure this out. In other words, do not just present the plot and say “we can see there are differences in metric X across time”. Instead, say something more clear like: “This plot visualizes data about Event X for Group/Person/year Y. Along the horizontal axis is… a long the y axis is…. You can see that the average range of times/distances for Event X decreases as athletes’ move through class ranks (e.g, FR to SR). This pattern in the data suggests that…”. You get the point.\n\n\nPlot Discussion\nFor each plot you should:\n\nexplain why you selected this plot as the data visualization of choice to communicate the element of data being communicated\nincorporate information from readings about why you have chosen this plot type\nexplain what modifications you made to the plot (feel free to share code)\nexplain limitations that the plot contains\nshare your future goals to:\n\nreplace the plot with a completely new plot for reason X\nmodify it in one or various ways to solve limitation X, Y, and X\nleave plot as is/explain why the plot needs no work"
  },
  {
    "objectID": "project/02_project_midterm.html#data-cleaning-and-variable-creation-30-pts",
    "href": "project/02_project_midterm.html#data-cleaning-and-variable-creation-30-pts",
    "title": "Midterm presentation",
    "section": "Data Cleaning and Variable Creation (30 pts)",
    "text": "Data Cleaning and Variable Creation (30 pts)\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of functions to ensure your data are computed correctly\nCommunicate any aggregation methods and summary data frames per plot"
  },
  {
    "objectID": "project/02_project_midterm.html#data-visualizations-story-telling-with-pictures-40-pts",
    "href": "project/02_project_midterm.html#data-visualizations-story-telling-with-pictures-40-pts",
    "title": "Midterm presentation",
    "section": "Data Visualizations: Story Telling with Pictures (40 pts)",
    "text": "Data Visualizations: Story Telling with Pictures (40 pts)\n\nPlot Introduction (5 pts)\nPlot Reveal and Explanation (20 pts)\nPlot Discussion (15 pts)"
  },
  {
    "objectID": "project/02_project_midterm.html#presentation-characteristics-20-pts",
    "href": "project/02_project_midterm.html#presentation-characteristics-20-pts",
    "title": "Midterm presentation",
    "section": "Presentation Characteristics (20 pts)",
    "text": "Presentation Characteristics (20 pts)\n\nClarity (5pts): well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization (5pts): structured logically; ability to walk audience through some story line or the a story about plot decision processes\nThoroughness (5pts): all relevant issues discussed thoroughly\nPresentation Style (5pts): degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/02_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "href": "project/02_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Team and Team Member Evaluation (5 pts)",
    "text": "Team and Team Member Evaluation (5 pts)\n\nEvaluation of personal contributions toward the project as evaluated by other team members (claims partially validated using on-time weekly report submissions).\nThe audience (your client) will also provide an overall review for the team and individual team members."
  },
  {
    "objectID": "project/02_project_midterm.html#self-evaluation-5-pts",
    "href": "project/02_project_midterm.html#self-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Self Evaluation (5 pts)",
    "text": "Self Evaluation (5 pts)\nEvaluation of your personal contributions toward the project as evaluated by yourself (claims partially validated using on-time weekly report submissions)."
  },
  {
    "objectID": "modules_setup/index.html",
    "href": "modules_setup/index.html",
    "title": "Installation, Setup, & R Basics",
    "section": "",
    "text": "For this course, we will use the R programming language to create all data visualizations. Although you may have a preferred IDE other than RStudio, my recommendation is to use RStudio. All instructions will assume you are using RStudio. For report documents, we will use the R Markdown language. RStudio projects will be used for managing your work space in order to simplify your working directory and file paths, manage history, and your R Markdown files (e.g., .Rmd) and code script files (.R). These RStudio projects will be version-control projects maintained at a remote repository on GitHub.com. Finally, the Git program will be used to communicate with that remote repository."
  },
  {
    "objectID": "modules_setup/index.html#overview",
    "href": "modules_setup/index.html#overview",
    "title": "Installation, Setup, & R Basics",
    "section": "",
    "text": "For this course, we will use the R programming language to create all data visualizations. Although you may have a preferred IDE other than RStudio, my recommendation is to use RStudio. All instructions will assume you are using RStudio. For report documents, we will use the R Markdown language. RStudio projects will be used for managing your work space in order to simplify your working directory and file paths, manage history, and your R Markdown files (e.g., .Rmd) and code script files (.R). These RStudio projects will be version-control projects maintained at a remote repository on GitHub.com. Finally, the Git program will be used to communicate with that remote repository."
  },
  {
    "objectID": "modules_setup/index.html#setup-structure",
    "href": "modules_setup/index.html#setup-structure",
    "title": "Installation, Setup, & R Basics",
    "section": "Setup Structure",
    "text": "Setup Structure\n\nInstall R and RStudio\nCreate a GitHub account if you do not have one\nInstall Git if your computer system needs it (e.g., not installed)"
  },
  {
    "objectID": "modules_setup/index.html#other-setup-topics",
    "href": "modules_setup/index.html#other-setup-topics",
    "title": "Installation, Setup, & R Basics",
    "section": "Other Setup Topics",
    "text": "Other Setup Topics\nFor those requiring refreshers about R Markdown, functions, and scripts are in this section."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html",
    "href": "modules_setup/R Basics/reading_data_files.html",
    "title": "Reading data files",
    "section": "",
    "text": "In this module, you will learn how to read and write data files in different formats. Depending how you access data, the process may change so this topic is discussed in a general way with different approaches described. If you find yourself in a bind with reading data, one of these approaches will likely work. In many instances, however, readr::read_csv() will be your friend when reading files and readr::write_csv() will be for writing files.\nIn addition, concepts related to reading files and managing workflow are discussed. By doing so, my goal is to make you aware of some key issues that could cause some problems with data science projects. When reading files,"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#readings",
    "href": "modules_setup/R Basics/reading_data_files.html#readings",
    "title": "Reading data files",
    "section": "Readings",
    "text": "Readings\n\nR Workflow Basics\nGeneral Wrangling: Sections 5.1 up through 5.5"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#task",
    "href": "modules_setup/R Basics/reading_data_files.html#task",
    "title": "Reading data files",
    "section": "Task",
    "text": "Task\n\nCreate a GitHub account if you don’t have one (this may come in handy for projects and a blog if you want)"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#libraries",
    "href": "modules_setup/R Basics/reading_data_files.html#libraries",
    "title": "Reading data files",
    "section": "Libraries",
    "text": "Libraries\n\n{openxlsx} 4.2.5.2: for reading Excel spreadsheets from a URL\n{readxl} 1.4.3: for reading Excel spreadsheets\n{readr} 2.1.5: for reading .csv, .tsv, and .fwf files\n\nFirst, we need an .xlsx data file. You can obtain one locally or online from a URL."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#excel-files-from-a-url",
    "href": "modules_setup/R Basics/reading_data_files.html#excel-files-from-a-url",
    "title": "Reading data files",
    "section": "Excel files from a URL",
    "text": "Excel files from a URL\n{readxl} 1.4.3 lacks the ability to read the file from online. We can, however, read it using {openxlsx}. The problem is that you will only be able to read a the first sheet. If the first sheet is all you need, this can work. Pass the URL to openxlsx::read.xlsx() and assign it’s contents to an object named DAT using the assignment operator &lt;-.\n\nURL &lt;- \"https://github.com/slicesofdata/dataviz24/raw/main/data/cms-top-all-time-2023-swim.xlsx\"\n\nDAT &lt;- openxlsx::read.xlsx(URL, sheet = 1)\n\nWhat does the head of the data file look like?\n\nhead(DAT)\n\n   score              name year          event   team\n1 525.35       Maia Presti 2015 1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023 1-Meter Diving Athena\n3 512.05      Emma Ng Pack 2023 1-Meter Diving Athena\n4 494.95         Izzy Doud 2023 1-Meter Diving Athena\n5 462.15     Carli Lessard 2015 1-Meter Diving Athena\n6 447.70     Alexis Romero 2023 1-Meter Diving Athena\n\n\nJust an FYI, when you want a different worksheet you will need to pass a sheet name to the sheet argument. In this case, we saved it as part of the download process. Let’s pass sheet = \"swim\".\n\nhead(\n  openxlsx::read.xlsx(URL, sheet = \"swim\")\n)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "href": "modules_setup/R Basics/reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "title": "Reading data files",
    "section": "Reading Excel Spreadsheets with {readxl}",
    "text": "Reading Excel Spreadsheets with {readxl}\nWe will use the {readxl} library to handing reading of Excel files. Because Excel files can contain multiple sheets, one goal would be to find out the sheet names using readxl::excel_sheets (see ?readxl::excel_sheets). This function takes one argument, which is the path to the file. Passing the path will return the sheet names in that file. We can pass the path string directly into the function or if the file path is already saved as a object, pass that.\nIn order to read an Excel spreadsheet file, you will need to specify at very least file and if you want to read a specific sheet other than the first one, then you will need to specify sheet.\n\nfile: a path to the file, including the file name\nsheet: the sheet name to read\n\n\nGetting Sheet Names\nFirst, let’s assign the file path to an object because we will use this path a few times and we don’t want to keep typing it lest we make an error.\n\nfile_name &lt;- \"cms-top-all-time-2023-swim.xlsx\"\n\nWe can examine the worksheet names:\n\nreadxl::excel_sheets(path = here::here(\"data\", file_name))\n\n[1] \"diving\" \"swim\"   \"relay\" \n\n\nGreat, we know know the sheet names. The benefit of passing an object is that you you may wish to pass the path to another function, for example, to read a sheet from the file.\n\n\nReading a Sheet\nIn order to read a sheet, we will use readxl::read_excel(), which takes the file path as the first argument and the name of the desired sheet as the second argument. You might get away with passing only the path as long as your goal is to read the first sheet because this is the default action. Let’s wrap the function in head() to see the top.\n\nhead(\n  readxl::read_excel(here::here(\"data\", file_name))\n)\n\n# A tibble: 6 × 5\n  score  name              year  event          team  \n  &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt; \n1 525.35 Maia Presti       2015  1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023  1-Meter Diving Athena\n3 512.05 Emma Ng Pack      2023  1-Meter Diving Athena\n4 494.95 Izzy Doud         2023  1-Meter Diving Athena\n5 462.15 Carli Lessard     2015  1-Meter Diving Athena\n6 447.70 Alexis Romero     2023  1-Meter Diving Athena\n\n\nThe function also turns the file content into special object type knows as a data frame. A data frame is composed of row and column data. Sometimes data frames are messy but luckily we have a fairly clean file. You can verify using R’s built-in function is.data.frame(), which will return TRUE if it’s a data frame or FALSE if not. We will assign this to an object\n\nis.data.frame(readxl::read_excel(here::here(\"data\", file_name)))\n\n[1] TRUE\n\n\nBut we don’t want the first sheet. Pass sheet = \"swim\" to read that sheet. Also, let’s read in the data and assign it to an object called DAT which will hold the data frame.\n\nDAT &lt;- readxl::read_excel(here::here(\"data\", file_name), sheet = \"swim\")\n\nViewing the head of the data frame, we can see that it is composed of 5 column vectors representing variables with names: time, name, year, event, team.\n\nhead(DAT)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nOK, that was fun. In order to demonstrate reading local .csv files, we will take a detour into saving files."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#managing-file-paths-with-here",
    "href": "modules_setup/R Basics/reading_data_files.html#managing-file-paths-with-here",
    "title": "Reading data files",
    "section": "Managing file paths with {here}",
    "text": "Managing file paths with {here}\nWhen downloading the file, you may have noticed using the {here} library. A discussion of the library was delayed at the time. We will now look a little deeper into how the library simplifies working with file paths within the context of the {readr}.\nWhat’s the best way to handle directories and file paths? Undoutedly, that is the {here} library, assuming of course you are smart enough to be using projects in RStudio. When you open a file from within a project, {here} will make the project directory the working directory. And if you are organized, your data files will be in a /data directory inside the project directory. When passing \"data\" as the first argument to here::here() ( e.g., here::here(\"data\"), you will see that the function returns a string containing the full path to the project directory plus the data subdirectory.\n\nhere::here(\"data\")\n\n[1] \"C:/Users/gcook/Sync/git/dataviz/dataviz24/data\""
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#a-workflow-side-note-on-strings",
    "href": "modules_setup/R Basics/reading_data_files.html#a-workflow-side-note-on-strings",
    "title": "Reading data files",
    "section": "A Workflow Side Note on Strings",
    "text": "A Workflow Side Note on Strings\nYou could avoid hard coding the change of the file extension in order to streamline you workflow. Every time to pass the path and the path changes you will need to change this by hand and doing so could be extremely annoying. For example, if you change the save location or the file name, you’ll need to make updates for all code referencing the path. To avoid potential headaches, we can instead use gsub() to examine a string, look for a pattern, and replace that pattern with another pattern. All we want to do is to change \".xlsx\" or \".xls\" in the string to \".csv\". And because we will next want to use this new name for reading later, let’s assign the change to a new string object, file_csv.\nFirst, let’s see what gsub() is doing.\n\ngsub(pattern = \".xlsx|.xls\",  \n     replacement = \".csv\", \n     x = file_name\n     )\n\n[1] \"cms-top-all-time-2023-swim.csv\"\n\n\nAssign to an object:\n\nfile_csv &lt;- gsub(\".xlsx|.xls\", \".csv\", file_name)\n\nNote: Code was simplified because the arguments were passed in the order expected by the gsub() function.\nSecond, pass the path object to write_csv():\n\nreadr::write_csv(x = DAT, \n                 file = here::here(\"data\", file_csv)\n                 )\n\nDid it save? Use file.exists().\n\nfile.exists(here::here(\"data\", file_csv))\n\n[1] TRUE\n\n\nRemember, all we have done is save the data frame. This new file will contain only the data from the spreadsheet that we read earlier. Before opening this new file, we need to take a detour on general handling of reading files with {readr}."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "href": "modules_setup/R Basics/reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored on a Website",
    "text": "Reading a .csv File Stored on a Website\nFor example, although the mtcars data is also a built-in data set in R, if it were a read actual .csv file save on some website, you can pass the URL path as the file. This file does exist on the {tidyverse} github for {readr}.\n\nreadr::read_csv(file = \"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBecause file if the first argument of the function, you do not need to reference it specifically. Doing so just eliminates ambiguity for more complicated function calls. You will come across a lot of examples of code that do NOT reference the arguments by name.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBy default, readr::read_csv() tries to guess whether column/variable names are present. If you know they exist, you can set col_names = TRUE.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nIf the names are present and you set col_names = FALSE, you will get a mess because {readr} will assume the header row is data just as the rest of the file.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = F)\n\nRows: 33 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 33 × 11\n   X1    X2    X3    X4    X5    X6    X7    X8    X9    X10   X11  \n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 mpg   cyl   disp  hp    drat  wt    qsec  vs    am    gear  carb \n 2 21    6     160   110   3.9   2.62  16.46 0     1     4     4    \n 3 21    6     160   110   3.9   2.875 17.02 0     1     4     4    \n 4 22.8  4     108   93    3.85  2.32  18.61 1     1     4     1    \n 5 21.4  6     258   110   3.08  3.215 19.44 1     0     3     1    \n 6 18.7  8     360   175   3.15  3.44  17.02 0     0     3     2    \n 7 18.1  6     225   105   2.76  3.46  20.22 1     0     3     1    \n 8 14.3  8     360   245   3.21  3.57  15.84 0     0     3     4    \n 9 24.4  4     146.7 62    3.69  3.19  20    1     0     4     2    \n10 22.8  4     140.8 95    3.92  3.15  22.9  1     0     4     2    \n# ℹ 23 more rows\n\n\nAs you can see, the column names are all prefixed with “X” and the first row is now the name of the headers. names() or colnames() will return the column names, so we can apply it and see what happens. We will wrap readr::read_csv() in names(). See how this is a problem. You can use colnames() to test this too.\n\nnames(\n  readr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n  )\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "href": "modules_setup/R Basics/reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored Locally on your Computer",
    "text": "Reading a .csv File Stored Locally on your Computer\nIf a file actually existed on your computer, the file would not be a URL but rather the path location to where the file is stored.\nAnd now we can read the locale file as before except we are not passing the string name but rather an object (e.g., file_csv) holding the file path and file name. Voilà.\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "href": "modules_setup/R Basics/reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "title": "Reading data files",
    "section": "Reading Raw Data that is Comma-Separated (e.g., .csv)",
    "text": "Reading Raw Data that is Comma-Separated (e.g., .csv)\nWe will file use readr::read_csv() to read our data file (viz., cms-top-all-time-2023-swim.csv).\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf there were only data in the file and no names representing variables on the first row, the file might look like that below. We can imitate this by skipping the first row (containing names) using skip =.\n\nreadr::read_csv(here::here(\"data\", file_csv), skip = 1)\n\nRows: 439 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): 23.29, Jocelyn Crawford, 2019, 50 FREE, Athena\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 439 × 5\n   `23.29` `Jocelyn Crawford` `2019` `50 FREE` Athena\n   &lt;chr&gt;   &lt;chr&gt;              &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt; \n 1 23.31   Ava Sealander      2022   50 FREE   Athena\n 2 23.49   Kelly Ngo          2016   50 FREE   Athena\n 3 23.71   Helen Liu          2014   50 FREE   Athena\n 4 23.76   Michele Kee        2014   50 FREE   Athena\n 5 23.77   Natalia Orbach-M   2020   50 FREE   Athena\n 6 23.77   Suzia Starzyk      2020   50 FREE   Athena\n 7 23.87   Katie Bilotti      2010   50 FREE   Athena\n 8 23.93   Jenni Rinker       2011   50 FREE   Athena\n 9 24.02   Annika Sharma      2023   50 FREE   Athena\n10 51.05   Kelly Ngo          2016   100 FREE  Athena\n# ℹ 429 more rows\n\n\nSee how the first row is assumed to be names? Setting col_names = F will fix the problem. Putting the arguments on separate rows of R code might improve code legibility.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = F\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): X1, X2, X3, X4, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   X1    X2               X3    X4      X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nBut we have no column names now. Setting col_names = will fix that. Use c() to combine 4 names, e.g., col_names = c(\"name1\", \"name2\", \"name3\", \"name4\").\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = c(\"time\", \"name\", \"year\", \"event\")\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf you have column names that are on row 1 of the data frame, don’t skip that row and instead set col_names = TRUE to put them in place.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                col_names = T\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nLuckily, we have both names and data in the file and by default readr::read_csv() does what we intend."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#reading-data-from-a-librarypackage",
    "href": "modules_setup/R Basics/reading_data_files.html#reading-data-from-a-librarypackage",
    "title": "Reading data files",
    "section": "Reading Data from a Library/Package",
    "text": "Reading Data from a Library/Package\nAs mentioned earlier, mtcars is a data set on cars which is also part of base R, meaning you do not need to read it from anyplace. R does this automatically.\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# or \nprint(mtcars)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nUse names() to read the column names:\n\nnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#object-assignment-using--",
    "href": "modules_setup/R Basics/reading_data_files.html#object-assignment-using--",
    "title": "Reading data files",
    "section": "Object Assignment using <-",
    "text": "Object Assignment using &lt;-\nYou will want to take the data frame object that is returned by the read.csv() function and assign it to an object of some name using the assignment operator &lt;- . Although the concept of assignment will be covered later, for now just understand that we need to make the data more accessible to work with. You could name the object anything you want. Let’s assign it to DAT standing for data frame and let’s make it ALL CAPS.\nA note about case: R is a case-sensitive language so object names like DAT, dat, DaT, etc. are possible and can refer to different objects depending on how you assign them. We will use capital letters only because I like to flag objects that are data frame as special and this approach makes them visually identifiable. You could choose your own convention for naming data frames, other objects, variables in data frames, etc. but I don’t recommend being random about it."
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#using-read.table",
    "href": "modules_setup/R Basics/reading_data_files.html#using-read.table",
    "title": "Reading data files",
    "section": "Using read.table():",
    "text": "Using read.table():\nread.table() is a flexible function for reading files because you can specify how the data are separated in rows by setting the sep argument. A common separation is a comma but you might also have tabs or other special characters.\n\nDAT &lt;- read.table(file = here::here(\"data\", file_csv),\n                  sep = \",\",\n                  header = T\n                  )\n\nread.csv() is a specific case of read.table() that sets sep = \",\" for you so there is no need to pass the argument. read.csv() is the more common function you will come across for reading .csv files but read.table() works the same as long as you set the argument.\n\nDAT &lt;- read.csv(here::here(\"data\", file_csv))"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#using-read_csv-from-readr",
    "href": "modules_setup/R Basics/reading_data_files.html#using-read_csv-from-readr",
    "title": "Reading data files",
    "section": "Using read_csv() from {readr}:",
    "text": "Using read_csv() from {readr}:\nThere are advantages to using readr::read_csv() over read.csv(), which is why we will prefer it. We will assign it to an object named DAT2.\n\nDAT2 &lt;- readr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(DAT2)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nWe can test whether DAT and DAT2 are the same using a logical test ==. Notice the two =. If we use one =, we will actually assign the contents of DAT2 to DAT because a single = in this context (scope) will do the same as &lt;-. A discussion of the differences is beyond the scope here but suffice it so say &lt;- is the common practice except when you are writing custom functions. In most cases, assignment inside functions are done with = because objects created inside a function are not typically needed outside that scope.\nAnyway, you can see that the contents are the same even when files are read by different functions. This is wrapped in the all() function, which will return TRUE if everything is TRUE. This is good that the contents are identical.\n\nall(DAT == DAT2)\n\n[1] TRUE"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#data-as-a-data-frame",
    "href": "modules_setup/R Basics/reading_data_files.html#data-as-a-data-frame",
    "title": "Reading data files",
    "section": "Data as a Data Frame",
    "text": "Data as a Data Frame\nYou should see an object named DAT that contains the data frame with some swim data. If you want to verify this is actually a data frame object, you can pass the DAT object into the is.data.frame() function. The function will return TRUE if it is and FALSE if it is not.\n\nis.data.frame(DAT)\n\n[1] TRUE\n\nis.data.frame(DAT2)  # tibbles are also data frames\n\n[1] TRUE"
  },
  {
    "objectID": "modules_setup/R Basics/reading_data_files.html#are-they-both-tibbles",
    "href": "modules_setup/R Basics/reading_data_files.html#are-they-both-tibbles",
    "title": "Reading data files",
    "section": "Are they both tibbles?",
    "text": "Are they both tibbles?\nTibbles are different from data frames, see the {tibble} library.\n\ntibble::is_tibble(DAT)\n\n[1] FALSE\n\ntibble::is_tibble(DAT2)\n\n[1] TRUE\n\n\nNow the you have the data frame, you can examine some of its contents, for example, the first 6 rows using the head() function.\n\nhead(DAT)    # hmm, something seems off.\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nBecause header rows do exist atop the .csv file, specify that they exist by passing TRUE to the header argument of the function (e.g., header = TRUE or header = T).\n\nDAT &lt;- read.table(here::here(\"data\", file_csv),\n                  sep = \",\", \n                  header = TRUE\n                  )\n\nhead(DAT)    # Perfect!\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules_setup/R Basics/index.html",
    "href": "modules_setup/R Basics/index.html",
    "title": "R Basics and Refreshers",
    "section": "",
    "text": "For this course, we use the R programming language. Although you may have a preferred IDE, my recommendation is to use RStudio. All instructions will assume you are using RStudio. We will also use the R Markdown language for report documents. Projects will be managed at GitHub and will interface with RStudio using the Git program."
  },
  {
    "objectID": "modules_setup/R Basics/index.html#setup-structure",
    "href": "modules_setup/R Basics/index.html#setup-structure",
    "title": "R Basics and Refreshers",
    "section": "Setup Structure",
    "text": "Setup Structure\n\nInstall R and RStudio\nCreate a GitHub account if you do not have one\nInstall Git if your computer system needs it (e.g., not installed)"
  },
  {
    "objectID": "modules_setup/R Basics/index.html#other-setup-topics",
    "href": "modules_setup/R Basics/index.html#other-setup-topics",
    "title": "R Basics and Refreshers",
    "section": "Other Setup Topics",
    "text": "Other Setup Topics\nFor those requiring refreshers about R Markdown, functions, and scripts are in this section."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html",
    "title": "Installing R & RStudio",
    "section": "",
    "text": "For this course, we will use the R programming language and the RStudio IDE for manipulating data and creating data visualizations."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#tasks",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#tasks",
    "title": "Installing R & RStudio",
    "section": "Tasks",
    "text": "Tasks\nThe first step for this course is to install and configure some software. If you have these installed on your computer, you will need to ensure you have the correct versions of software and libraries installed.\n\nDownload and Install R\nDownload and Install RStudio\nConfigure RStudio\nInstall R libraries/packages needed"
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#optional-readings",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#optional-readings",
    "title": "Installing R & RStudio",
    "section": "Optional Readings",
    "text": "Optional Readings\nIf you need a refresher on the RStudio IDE, consider this intro to R.\nIf you need a refresher on R Markdown, consider this link on working with RMarkdown."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#determining-the-version-of-your-computers-operating-system",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#determining-the-version-of-your-computers-operating-system",
    "title": "Installing R & RStudio",
    "section": "Determining the version of your computer’s operating system",
    "text": "Determining the version of your computer’s operating system\nYour version of operating system will dictate which version of R to download and install. Make note of your computer’s operating system.\nWindows systems are easier and Windows 10 and 11 operating systems will both use the same R versions.\nMacs are somewhat more complicated. The version depends on your cpu. Visit this link to determine.\nThere will be two cpu options, Intel 64-bit for macOS 10.13 or Apple silicon arm64 for macOS 11 and higher.\nCloud Options:\nIf you do not have a laptop (let me know) or do not have 5GB of hard drive space available on your computer, you might consider a cloud version of the software. One is maintained by Posit (formerly RStudio) and the other is maintained by CMC.\n\nPosit (25 free compute hours a month – make time out)\nRemote Desktop Protocol (No limit on compute hours) (contact me if interested). This is managed by CMC but may not be reliable."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#downloading-r",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#downloading-r",
    "title": "Installing R & RStudio",
    "section": "Downloading R",
    "text": "Downloading R\nOnce you know your processor, navigate to https://cran.r-project.org/ and in the “Download and Install R” section, select your operating system. You can also select from below and follow the indented sections that follow.\n\nDownload R for Linux (Debian, Fedora/Redhat, Ubuntu)\nDownload R for macOS\nDownload R for Windows\n\nWindows users should select the base version of R and download version 4.4.1 (no other version) to your computer. If this version is not on the main page, go to the “Other Builds” section and select “previous releases” and download the correct version.\nMac users should download either R-4.4.1.pkg or R-4.4.1x86_64.pkg version depending on the cpu noted earlier. Do not download any version other than 4.4.1 and please do not update throughout the semester."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#downloading-rstudio",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#downloading-rstudio",
    "title": "Installing R & RStudio",
    "section": "Downloading RStudio",
    "text": "Downloading RStudio\nUse the urls below to download RStudio and save it to the same directory location on your computer as you saved R.\nWindows 10/11: https://download1.rstudio.org/electron/windows/RStudio-2024.04.2-764.exe\nMacOS 12+: https://download1.rstudio.org/electron/macos/RStudio-2024.04.2-764.dmg\nMacOS 10.15-11: https://s3.amazonaws.com/rstudio-ide-build/electron/macos/RStudio-2023.09.1-494.dmg\nLinux: go to https://posit.co/download/rstudio-desktop/\nNote: If you have a 32bit operating system, you will need to install an older version: https://www.rstudio.com/products/rstudio/older-versions/"
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#installing-r-then-install-rstudio",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#installing-r-then-install-rstudio",
    "title": "Installing R & RStudio",
    "section": "Installing R (then install RStudio)",
    "text": "Installing R (then install RStudio)\nInstalling should be easy and you can accept all of the defaults although the desktop icons are not needed, especially for R because you will never need it; RStudio will find R for you. You can follow these videos for simple installing.\nPC: How to Install R and R Studio on Windows 10/11\nMac: Installing R and RStudio on a Mac\nNote: If you leave the desktop icon for R, you can remove that later. You will never need it because RStudio will find R for you."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#additional-step-for-mac-users",
    "href": "modules_setup/Installation & Setup/installing_r_and_rstudio.html#additional-step-for-mac-users",
    "title": "Installing R & RStudio",
    "section": "Additional Step for Mac Users:",
    "text": "Additional Step for Mac Users:\nDownload and Install XQuartz\nSome functions in R require an “X11 Server” and/or libraries associated with an X11 server. Apple does not provide this software with OS X anymore so unfortunately you have to do it on your own via a third-party application called XQuartz for OS X 10.9 or later.\nUse the url below to download the XQuartz file and save it to your computer. Follow the same install instructions as above for installing the XQuartz file.\nFor macOS 10.9 or later, download this XQuartz file and save it to your computer and install: https://github.com/XQuartz/XQuartz/releases/download/XQuartz-2.8.5/XQuartz-2.8.5.pkg"
  },
  {
    "objectID": "modules_setup/Installation & Setup/index.html",
    "href": "modules_setup/Installation & Setup/index.html",
    "title": "Installation & Setup",
    "section": "",
    "text": "For this course, we will use the R programming language to create all data visualizations. Although you may have a preferred IDE other than RStudio, my recommendation is to use RStudio as all instructions for the course will be in RStudio. For report documents, we will use the R Markdown language, which integrates easily with RStudio. Moreover, RStudio projects will be used for managing your work space in order to simplify your working directory and file paths, manage history, and your R Markdown files (e.g., .Rmd) and code script files (.R). These RStudio projects will be version-control projects maintained at a remote repository on GitHub.com. Finally, the Git program will be used to communicate with that remote repository."
  },
  {
    "objectID": "modules_setup/Installation & Setup/index.html#overview",
    "href": "modules_setup/Installation & Setup/index.html#overview",
    "title": "Installation & Setup",
    "section": "",
    "text": "For this course, we will use the R programming language to create all data visualizations. Although you may have a preferred IDE other than RStudio, my recommendation is to use RStudio as all instructions for the course will be in RStudio. For report documents, we will use the R Markdown language, which integrates easily with RStudio. Moreover, RStudio projects will be used for managing your work space in order to simplify your working directory and file paths, manage history, and your R Markdown files (e.g., .Rmd) and code script files (.R). These RStudio projects will be version-control projects maintained at a remote repository on GitHub.com. Finally, the Git program will be used to communicate with that remote repository."
  },
  {
    "objectID": "modules_setup/Installation & Setup/index.html#setup-structure",
    "href": "modules_setup/Installation & Setup/index.html#setup-structure",
    "title": "Installation & Setup",
    "section": "Setup Structure",
    "text": "Setup Structure\n\nInstall R and RStudio\nCreate a GitHub account (if you do not have one)\nInstall Git if your computer system needs it (it’s not already installed)"
  },
  {
    "objectID": "modules_setup/Installation & Setup/index.html#other-setup-topics",
    "href": "modules_setup/Installation & Setup/index.html#other-setup-topics",
    "title": "Installation & Setup",
    "section": "Other Setup Topics",
    "text": "Other Setup Topics\nFor those requiring refreshers about R Markdown, functions, and scripts can be found in this topic section."
  },
  {
    "objectID": "modules/visualizing_trends.html",
    "href": "modules/visualizing_trends.html",
    "title": "Visualizing trends",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/visualizing_trends.html#readings",
    "href": "modules/visualizing_trends.html#readings",
    "title": "Visualizing trends",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing Trends\nWilke (2019). Fundamentals of Data Visualization. Visualizing Time Series"
  },
  {
    "objectID": "modules/visualizing_associations.html",
    "href": "modules/visualizing_associations.html",
    "title": "Visualizing associations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/visualizing_associations.html#readings",
    "href": "modules/visualizing_associations.html#readings",
    "title": "Visualizing associations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from FDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing associations"
  },
  {
    "objectID": "modules/visualizing_associations.html#external-functions",
    "href": "modules/visualizing_associations.html#external-functions",
    "title": "Visualizing associations",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/visualizing_associations.html#libraries",
    "href": "modules/visualizing_associations.html#libraries",
    "title": "Visualizing associations",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting"
  },
  {
    "objectID": "modules/visualizing_associations.html#load-libraries",
    "href": "modules/visualizing_associations.html#load-libraries",
    "title": "Visualizing associations",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "href": "modules/visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "title": "Visualizing associations",
    "section": "A Simple Scatterplot with geom_point()",
    "text": "A Simple Scatterplot with geom_point()\nThe typical xy scatter plot is used to visualize the relationship between two numeric variables. Those numeric variables may be continuous or discrete, though you will see that data visualizations involving discrete numeric data do have some limitations. We will attempt to circumvent some of those limitations using different functions from {ggplot2} in the examples presented. These approaches used can also be applied to continuous data.\nAs with all geoms, geom_point() can accept its own data and aesthetics or inherit them from the initialized ggplot() object. Similar to geom_col(), we need an x and a y variable to create a point plot. The specification of x or y may depended on variables as predictors or outcomes or based on the goal of the plot.\nBecause we have swim data represeting completion times for events of different distances, we will set x = Distance and y = Time so that we can visualize Time as a function of Distance.\nTaking the data frame and piping that to ggplot(), we declare the data and the mapping to x and y.\ngeom_point(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nWe can add the geom_point() layer that instructs how to display the data. Right out of the box, we get:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nYour first point plot! You see small black points, axis labels, tick marks for intervals, and some apparent clustering of points around certain distances. You also see the association between distances and time, a positive association.\nWe will filter some of the event data to illustrate the {ggplot2} functionality.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nThe association is still apparent in the plot. The tick marks along the x-axis changed but the clustering of points is still present. We will reserve discussion of axes for a later topic but the clustering is still present. This issue will often present itself when plotting a continuous variable like time against a discrete variable like event distance.\nIn another world, the variables may be reversed such that swimmers are tasked with swimming for a given time t, and their performance outcome is the distance they traveled. On one hand, this approach may be efficient because there would be no waiting around for slower swimmers to finish an event. On the other hand, measurement of distance in a liquid medium may be extremely difficult and time consuming, event completion may be lack luster for athletes, and the wait for results would be annoyingly painful for fans as they wait in agony for the measurement results to declare a winner. In the end, we would still have a discrete variable, now time, and a continuous variable, now distance. The data would still plague the visualization in the same way.\n\nAssociations with some smoothing\ngeom_smooth() is {ggplot2}’s solution to seeing some patterns of association in the data.\ngeom_smooth(\n  mapping = NULL,\n  data = NULL,\n  stat = \"smooth\",\n  position = \"identity\",\n  ...,\n  method = NULL,\n  formula = NULL,\n  se = TRUE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nBy default, geom_smooth() does not add a linear fit to the data. Instead, method = 'loess' applies a Loess function on y ~ x, which will highlight curvature or wiggliness of the fit moving through data. The amounts of movement of Loess can also be controlled by the span arguemnt. You can also add your own formula to the smoothing function by passing it to the formula argument.\nAdding a geom_smooth() layer:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\nYou see the function curving in blue through the data and a gray shading around it.\nImportantly, you might want to apply another method of fit, for example a linear model, which you can achieve using method = \"lm\".\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNow you see a line of best fit along with that gray shading again. That shading represents error variance in the model, which we will address in a topic on visualizing uncertainty. We can turn it off by setting se = FALSE.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nOf some plots, you may also not see the fit line through the entire plot. For example, changing the limits on the x axis, from 0 to 800 by adding plot layer, xlim(0, 800), will demonstrate a problem that you might experience and wish to fix.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can change the default behavior using fullrange = T:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\", \n              fullrange = T\n              )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe line now extends to the limets. geom_smooth() has many options but for now you see how we can plot points and add various fits to them."
  },
  {
    "objectID": "modules/visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "href": "modules/visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "title": "Visualizing associations",
    "section": "geom_point() when a variable is a factor",
    "text": "geom_point() when a variable is a factor\nPoint plots can all be used for plotting individual data points for categorical data.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou see now that geom_point() will plot only the existing levels of Distance in the data set and provides the level label at each tick mark. If your goal is to change your tick marks for numeric data, this is not the solution because the scale will violate rules of mathematics.\n\nSetting aesthetic\nWe can change color, fill, shape, size, and alpha of points in the plot either by setting a constant or mapping color to an aesthetic. We will address setting here and mapping later.\nHere we plot open circles in black, filled with green, and make them somewhat transparent.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(shape = 21, \n             size = 3,\n             col = \"black\", \n             fill = \"green\",\n             alpha = .3\n             )\n\n\n\n\nThe procedure of mapping aesthetics introduces other variables from the data set into the plot. We do not need to change the color or shape of points for each event distance for the viewer to understand the plot. Position along x already communicates the distance. Mapping aesthetics of variables already present would confound the data and result in a plot that manipulates both position and color to communicate one variable, distance. This is not needed. By contrast, mapping variables that are not already present in the data introduces new information and complexity. These represent a different class of plots altogether."
  },
  {
    "objectID": "modules/visualizing_associations.html#multiclass-scatterplots",
    "href": "modules/visualizing_associations.html#multiclass-scatterplots",
    "title": "Visualizing associations",
    "section": "Multiclass Scatterplots",
    "text": "Multiclass Scatterplots\nThe typical xy scatter plot is used to visualize the relationship between two continuous variables. When your data vary in a different way and you don’t want to create a 3-dimensional plot (you really don’t want to anyway), you can map a third variable to the point plot to create a multiclass scatterplot that decorates the plot with a new aesthetic (e.g., color, size, transparency, etc.).\nIn most instances, you will want to map categorical variable to aesthetics like size or shape and numeric variables to aesthetics like size and alpha.\n\nMapping existing variables to aesthetics\nWe can map an existing variable to a new aesthetic. For example, Distance is already present in the plot but we can map it the color aesthetic. using aes(col = Distance). Well, because color may best be used or categorical variables, we will make it factor on the fly.\nUsing aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = factor(Distance)),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nWe are not encoding a third variable in this plot but rather confounding color with an existing variable in the point plot. This approach can bias attention to particular subsets of the data unintentionally especially when some colors share properties with some colors used in the plot but not others.\nWe could also map an existing numeric variable to the color aesthetic. Using aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Distance),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nThe darker blue points are now associated with shorter distances, which itself may be conceptually difficult but the point here is that a data element can be mapped to an aesthetic.\nThese two examples, however, do not may new variables that introduce new information to understand subsets of the data.\n\n\nMapping new variables to aesthetics\nWe can map a new variable to the plot. Looking at the variables present, we can map School to the color in order to see whether time and distance are related in the same way across schools. The legend will be really big, so we will also remove it for now.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend=F\n    )\n\n\n\n\nAnd for men and women:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Team),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    )\n\n\n\n\n\n\nAdding model fits using geom_smooth():\nIn order to see a linear association, however, we might want to fit a linear model to the subsets. We will need to make sure there are no factor() or as.character() functions for the variables or you will not see a line.\nSpecifically, we will use geom_smooth() to add a fit line to the plot.\nThe pattern for all schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe will that a line is fit through ALL of the data illustrating of course that time increases as a function of distance. Yes, this is silly but the main goal here is to understand how {ggplot} works.\nIn order to examine the linear fit pattern for all schools, we would map the School variable as an aesthetic to geom_smooth().\nNotice, however, that we are now passing aes(col = School) in geom_point() to make points for schools vary by color and in geom_smooth() to apply fit lines for each school. Remember that geom_*() aesthetics are inderited from ggplot() by default (e.g., inherit.aes = TRUE).\nLet’s just map aes(col = School) in ggplot() instead so that both geom_*()s inherit it.\nThe pattern across schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = School),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nYou see that the linear fits are almost identical for the two schools. You can comment out show.legend = F to see the school names.\nWhat about across male and female swimmers?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = Team),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe visualization now shows that the slope differs by subgroup, in particular that the slope is steeper for female swimmers. Again, comment out show.legend = F to see. We can add confidence intervals or error to the fit line on the plot but doing so is something we will deal with in the topic on visualizing uncertainty. That being said, the astute student of statistics should also know there is uncertainty to the lint-of-best-fit because it represents a fit of the current data, which may have sampling error. Bootstrapping the model fit will allow or visualization of uncertainty of the model fit.\n\n\nBubble Plots\nWhen the decorative element is point size, the plot type is referred to as a bubble plot and this is a special case of a multiclass scatterplot. Though some may refer to is as such, technically speaking, adding a color element is not bubble plot for obvious reasons.\n\n\nMapping existing variables to aesthetics\nWe will map a variable to the size aesthetic of the point plot. For now, don’t worry about arguments other than size.\nWe can map size = Time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\nThe bubbles here simply represent the y variable mapped to the size aesthetic. We are not conveying a third variable in this plot but rather confounding size with an existing variable in the point plot. One thing to know is that the visual system loves size and to shading (e.g,. contrast). Both are present here, so be mindful of bias such a plot has on visual attention and perception. We will address such issues when we address concepts of attentional control.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\n\n\nMapping new variables to aesthetics\nWe will look at the data in a different way now. The data frame contains split times for the first 50. A split time is a time measurement of partial distance in swimming. For example, for a 200 meter event, you can measure split times for ways you a split the event (e.g., 25, 50, 100 meters). A swimmer who maintains the same time across splits is performing differently from one who swims at different paces across splits.\nLet’s look at split times for 50 meters as a function of distance. You will notice that Distance = 50 is dropped out of the plots because there is no split time.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Split50)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nYou can see that the split times for the first 50 meters seems to increase as the distance of the event increases. Swimmers are pacing differently.\nAnd for splits and even time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nLonger split times are associated with overall longer event times.\nMapping a new variable like Distance to point size will adjust the size of the points by the event distance.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    aes(size = Distance),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWe can see that the point diameter increases with distance. Although this bubble plot introduces a new variable, Distance, to the plot which was not visualized before, it really fails to communicate something useful in the data that was not already presented.\nWhat if we plotted Time as as function of Distance and mapped Split50 to the size aesthetic?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThis bubble plot now illustrates that the split times vary within the event distance and is associate with longer event times.\nAnd if we map event types to color:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .3,\n    position = \"jitter\",\n    show.legend = F\n    )\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWe can see that the larger point sizes reflecting longer split times also appears to be associated with the event participated in. Notice the color palette used and the size of the points in the legend. Some color are difficult to differentiate when the alpha is dialed down. But without lowering alpha, the points would have a different problem. If this were a plot we wanted to share, we would need to fix it a lot. Later on, we will cover ways to change colors, the size of the points in the legend later, change the scale and tick marks on the axes, etc.\nYou can see how in some cases, bubble plots may be appropriate for presenting 4-Dimensional data for which two variables are numeric (X and Y), an additional variable is categorical and mapped to color (or shape) and another variable is numeric and mapped to size.\n{ggplot2}} will also provide warnings when applying a discrete variable to an aesthetic like size, for example, Using size for a discrete variable is not advised."
  },
  {
    "objectID": "modules/visualizing_associations.html#connected-scatterplots",
    "href": "modules/visualizing_associations.html#connected-scatterplots",
    "title": "Visualizing associations",
    "section": "Connected Scatterplots",
    "text": "Connected Scatterplots\nThere are instances when you may wish to visualize the order of events in a scatterplot. For example, the demand and price or a good may be associated but those may also change at different time points. These are sometimes presented as connected scatterplots.\nWhereas geom_line() will create a line between x and y data (imaging invisible points), geom_path() will connect those x and y positions to reveal other associations like the time pattern.\nLet’s compare the two functions using some made up data.\n\nDAT &lt;- data.frame(\n  x = c(1, 2, 3, 4, 5, 4, 7),\n  y = c(12, 16, 13, 15, 19, 20, 22),\n  label = c(2013:2019)\n  ) \n\nA geom_line():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_line()\n\n\n\n\nA geom_path():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\")\n\n\n\n\nAdding labels as text (and changing their color and size):\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\") +\n  geom_text(aes(label = label,\n                size = factor(label), \n                col = label)\n            )\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\nNote that geom_line() does not work well with the existing swim data. Points will be connected.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_line()\n\n\n\n\nAnd geom_path() will connect the based on the order of the date but this type of plot is not relevant here as there is no order or time course.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_path()"
  },
  {
    "objectID": "modules/statistical_transformations.html",
    "href": "modules/statistical_transformations.html",
    "title": "Statistical transformations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/statistical_transformations.html#readings",
    "href": "modules/statistical_transformations.html#readings",
    "title": "Statistical transformations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Weighting data\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Stats"
  },
  {
    "objectID": "modules/statistical_transformations.html#external-functions",
    "href": "modules/statistical_transformations.html#external-functions",
    "title": "Statistical transformations",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions_view_html.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/statistical_transformations.html#libraries",
    "href": "modules/statistical_transformations.html#libraries",
    "title": "Statistical transformations",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting"
  },
  {
    "objectID": "modules/statistical_transformations.html#load-libraries",
    "href": "modules/statistical_transformations.html#load-libraries",
    "title": "Statistical transformations",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/statistical_transformations.html#data-aggregation-using-group_by",
    "href": "modules/statistical_transformations.html#data-aggregation-using-group_by",
    "title": "Statistical transformations",
    "section": "Data aggregation using group_by()",
    "text": "Data aggregation using group_by()\nLet’s go through a simple example of data aggregation using group_by().\n\nDATA &lt;- data.frame(\n  Student = c(\"Jim\", \"Sally\", \"June\", \"Mildred\", \"Tilford\", \"Beavis\", \"Herman\", \"Peppa\", \"Kay\", \"Jake\", \"Name Missing\"),\n  Score  = c(80, 85, 79, 80, 81, 91, 89, 60, 65, 67, 65), \n  School = c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\"), \n  District = c(\"West\", \"West\", \"West\", \"West\", \"East\", \"East\", \"East\", \"North\", \"North\" , \"North\", \"North\")\n  ) \n\nYou can see that the performance for all students is on average, for example, if you didn’t know where they went to school. We would take only the mean.\n\nDATA %&gt;%\n  summarize(Score = mean(Score))     # calculate average\n\n     Score\n1 76.54545\n\n\nLet’s say we try to determine average performance for “all students” if we had the data aggregated as the school level and not the individual level.\n\nDATA %&gt;%\n  group_by(School) %&gt;%\n  summarize(Score = mean(Score)) %&gt;% # get the school level aggregated data\n  summarize(Score = mean(Score))     # then calculate average across all schools\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  75.5\n\n\nLet’s say we try to determine average performance for “all students” if we had the data aggregated as the district level and not the individual level.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Score = mean(Score)) %&gt;% # get the district level aggregated data\n  summarize(Score = mean(Score))     # then calculate average across all districts\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  77.4\n\n\nSo what’s the average performance for students? Well, that interpretation differs based on how values are treated. At the highest level, all students’ Scores are weighed equally. Each student contributes to the data in the same way. When aggregated by School, each school contributes to the calculation equally, even if the number of bodies per school differs. And finally, when data are aggregated at the District level, all districts are treated equally in the calculation independent on the number of schools in a district. Only with weighting means would you end up with the same average performance.\nMeasures of variability in the data, however, reveal something else. Schools differ in variability and schools within districts vary as well. Depending on the level of aggregation, you may never notice interesting patterns in data that lead to questions to investigate and later policies to change. For example, addressing a school that is left behind others or a district that is left behind others. Aggregation can also lead to inefficient allocations of resources. If one school in a district needs help rather than all schools in the district needing help, the cost may differ substantially.\n\nstd_error &lt;- function(x) { sd(na.omit(x)) / sqrt(length(na.omit(x))) }\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Var = var(Score),\n            SD  = sd(Score),\n            SEM = std_error(Score),\n            min = min(Score),\n            max = max(Score)\n  ) %&gt;% mutate(range = max - min)\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 8\n# Groups:   School [5]\n  School District   Var    SD   SEM   min   max range\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      12.5 3.54   2.5     80    85     5\n2 B      West       0.5 0.707  0.5     79    80     1\n3 C      East      28   5.29   3.06    81    91    10\n4 D      North     12.5 3.54   2.5     60    65     5\n5 E      North      2   1.41   1       65    67     2"
  },
  {
    "objectID": "modules/statistical_transformations.html#grouping-structure-of-group_by-and-mutate",
    "href": "modules/statistical_transformations.html#grouping-structure-of-group_by-and-mutate",
    "title": "Statistical transformations",
    "section": "Grouping structure of group_by() and mutate()",
    "text": "Grouping structure of group_by() and mutate()\nLet’s mutate() the mean for Score after sub-setting with group_by().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  mutate(Score = mean(na.omit(Score)))\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim           82.5 A      West    \n 2 Sally         82.5 A      West    \n 3 June          79.5 B      West    \n 4 Mildred       79.5 B      West    \n 5 Tilford       87   C      East    \n 6 Beavis        87   C      East    \n 7 Herman        87   C      East    \n 8 Peppa         62.5 D      North   \n 9 Kay           62.5 D      North   \n10 Jake          66   E      North   \n11 Name Missing  66   E      North   \n\n\nThere are two things to watch when using this mutate() following group_by().\n1. A Score will be assigned to each row/case or Student in the data frame.\nWhen schools and districts are grouped, each student in the same school will have the same assigned average value. All rows are maintained, none dropped.\n2. The returned tibble takes on a new structure.\nLooking at the feedback in the console, you see the following report preceding the data.\nA tibble: 11 × 3\n# Groups:   School, District [5]\nYou also see this structure using glimpse().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  mutate(Score = mean(na.omit(Score))) %&gt;%\n  glimpse()\n\nRows: 11\nColumns: 4\nGroups: School, District [5]\n$ Student  &lt;chr&gt; \"Jim\", \"Sally\", \"June\", \"Mildred\", \"Tilford\", \"Beavis\", \"Herm…\n$ Score    &lt;dbl&gt; 82.5, 82.5, 79.5, 79.5, 87.0, 87.0, 87.0, 62.5, 62.5, 66.0, 6…\n$ School   &lt;chr&gt; \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\"\n$ District &lt;chr&gt; \"West\", \"West\", \"West\", \"West\", \"East\", \"East\", \"East\", \"Nort…\n\n\nRows: 11\nColumns: 3\nGroups: School, District [5]\nWhat does the [5] mean? Well, before we answer this, let’s use summarize()."
  },
  {
    "objectID": "modules/statistical_transformations.html#grouping-structure-of-group_by-and-summarize",
    "href": "modules/statistical_transformations.html#grouping-structure-of-group_by-and-summarize",
    "title": "Statistical transformations",
    "section": "Grouping structure of group_by() and summarize()",
    "text": "Grouping structure of group_by() and summarize()\nLet’s summarize() the mean for Score after sub-setting with group_by().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nThere are two things to watch when using this summarize() following group_by().\n1. A Score average is assigned to each row/case or School in this aggregated data frame.\nWhen schools and districts are grouped, each school will have its own average value. Rows from the data frame are dropped as are columns that are not passed to group_by(). In this case, School, District, and the new variable, Score are returned.\n2. The returned tibble takes on a new structure.\nThe feedback in the console is a little more detailed here.\n`summarise()` has grouped output by 'School'. You can override using the `.groups` argument.\n# A tibble: 5 × 3\n# Groups:   School [5]\nYou see reference to overriding the grouping using .groups. According to the tidyverse documentation for grouping, this parameter “controls the grouping structure of the output. The historical behaviour of removing the right hand side grouping variable corresponds to .groups = \"drop_last\" without a message or .groups = NULL with a message (the default)”.\nYou have most likely paid little attention to this message. By default summarize() keeps the first grouping variable passed to group_by() in the returned tibble. This is why you see School referenced and not District or both variables. So, do you want your data frame to contain groups or no groups? Stated differently, do you just want that data summarized by your grouping variables and have a simple nxm data frame or do you want something more complex?\nTo see the structure better, let’s first look a the structure of DATA and then more closely at the summarized version.\n\nstr(DATA)\n\n'data.frame':   11 obs. of  4 variables:\n $ Student : chr  \"Jim\" \"Sally\" \"June\" \"Mildred\" ...\n $ Score   : num  80 85 79 80 81 91 89 60 65 67 ...\n $ School  : chr  \"A\" \"A\" \"B\" \"B\" ...\n $ District: chr  \"West\" \"West\" \"West\" \"West\" ...\n\n\nLet’s assign the summarized data frame to an object for inspection.\n\nDSUM &lt;- DATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\nFor DSUM, the structure is different. In particular, you see reference to (S3: grouped_df/tbl_df/tbl/data.frame). This tells you that the data frame is not a simple nxm but contains groups. You could think of this as 3 nxm data frames organized together. For more details, see the dplyr documentation.\n\nstr(DSUM)\n\ngropd_df [5 × 3] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ School  : chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n $ District: chr [1:5] \"West\" \"West\" \"East\" \"North\" ...\n $ Score   : num [1:5] 82.5 79.5 87 62.5 66\n - attr(*, \"groups\")= tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ School: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ .rows : list&lt;int&gt; [1:5] \n  .. ..$ : int 1\n  .. ..$ : int 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n  .. ..$ : int 5\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\n\ngroup_by() and summarize() with .groups\nWhen you group data using group_by() and then summarize(), the summary variables (e.g., mean) will result in a single row for each level of a single grouping variable. If there are more than one grouping variable, the additional grouping variable will be introduced to the data frame as a second column. The total number of rows in the data frame will be equal to the number of levels of group 1 x number of levels of group 2 if an only if each levels of group 1 has a corresponding level for group 2,\nfor example:\nsex   age    mean\nmen   young  x\nmen   old    x\nwomen young  x\nwomen old    x\nIf there is no pairing of levels in the data (e.g., no men who are old), that row will be omitted from the returned data frame.\nfor example:\nsex   age    mean\nmen   young  x\nwomen young  x\nwomen old    x\nrather than:\nsex   age    mean\nmen   young  x\nmen   old    NA\nwomen young  x\nwomen old    x\nYou really need to query ?dplyr::summarize to understand .groups, which controls the grouping of the returned data frame. This is also experimental to summarize(), so it might not be available in the future.\nThere are four argument options:\n\n\"drop_last\": dropping the last level of grouping. This was the only supported option before version 1.0.0.\n\"drop\": All levels of grouping are dropped.\n\"keep\": Same grouping structure as .data.\n\"rowwise\": Each row is its own group.\n\n\n.groups = \"drop_last\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop_last\")\n\n# A tibble: 14 × 3\n# Groups:   Event [6]\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that the grouping for Distance is not in the grouping structure because it was the last grouping.\n# A tibble: 14 × 3\n# Groups:   Event [6]\n   Event        Distance   Time\n\n\n.groups = \"drop\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop\")\n\n# A tibble: 14 × 3\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that all group are dropped from the grouping structure.\n# A tibble: 14 × 3\n   Event        Distance   Time\n\n\n.groups = \"keep\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"keep\")\n\n# A tibble: 14 × 3\n# Groups:   Event, Distance [14]\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that all group are kept in the grouping structure.\n# A tibble: 14 × 3\n# Groups:   Event, Distance [14]\n   Event        Distance   Time\n\n\n.groups = \"rowwise\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"rowwise\")\n\n# A tibble: 14 × 3\n# Rowwise:  Event, Distance\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that there groups but these are not based on the\n# A tibble: 14 × 3\n# Rowwise:  Event, Distance\nThe grouping structure always matters for subsequent computations. But with \"rowwise\" you will see this clearly. Following from above, let’s say we wanted to compute the mean across all of the Events in the data frame returned by group_by() then summarize(). We add mutate(mean = mean(Time)) on a new line of our piped code block.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"rowwise\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n# Rowwise:  Event, Distance\n   Event        Distance   Time   mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8   59.8\n 2 Backstroke        200  124.   124. \n 3 Breaststroke      100   61.6   61.6\n 4 Breaststroke      200  139.   139. \n 5 Butterfly         100   55.3   55.3\n 6 Butterfly         200  125.   125. \n 7 Freestyle          50   23.6   23.6\n 8 Freestyle         100   51.9   51.9\n 9 Freestyle         200  107.   107. \n10 Freestyle         500  306.   306. \n11 Freestyle        1650 1143.  1143. \n12 IM                200  126.   126. \n13 IM                400  269.   269. \n14 Medley            200  104.   104. \n\n\nThe mean column does not contain a single mean replicated for each row in the data frame. Rather the grouping was per row, so each row has its one mean. The mean of a single value is, of course, itself.\n\n\nRevisiting \".groups = drop_last\":\nReturning to the default .groups structure, which is \"drop_last\", we can add the same mutate() to see what happens.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop_last\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  92.1\n 2 Backstroke        200  124.   92.1\n 3 Breaststroke      100   61.6 100. \n 4 Breaststroke      200  139.  100. \n 5 Butterfly         100   55.3  90.4\n 6 Butterfly         200  125.   90.4\n 7 Freestyle          50   23.6 326. \n 8 Freestyle         100   51.9 326. \n 9 Freestyle         200  107.  326. \n10 Freestyle         500  306.  326. \n11 Freestyle        1650 1143.  326. \n12 IM                200  126.  197. \n13 IM                400  269.  197. \n14 Medley            200  104.  104. \n\n\nThe mean column still has different values but they are replicated on rows with the same Event group. This is because the data are grouped that way.\n\n\nRevisiting .groups = \"drop\":\nLet’s again add the same mutate() to see what happens.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  193.\n 2 Backstroke        200  124.   193.\n 3 Breaststroke      100   61.6  193.\n 4 Breaststroke      200  139.   193.\n 5 Butterfly         100   55.3  193.\n 6 Butterfly         200  125.   193.\n 7 Freestyle          50   23.6  193.\n 8 Freestyle         100   51.9  193.\n 9 Freestyle         200  107.   193.\n10 Freestyle         500  306.   193.\n11 Freestyle        1650 1143.   193.\n12 IM                200  126.   193.\n13 IM                400  269.   193.\n14 Medley            200  104.   193.\n\n\n\n\nConsider ungroup():\n.groups = \"drop\" in effect works the same as does ungroup(). The grouping structure is broken and all subsequent operations are based on the ungrouped data frame.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  mutate(mean = mean(Time))\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  193.\n 2 Backstroke        200  124.   193.\n 3 Breaststroke      100   61.6  193.\n 4 Breaststroke      200  139.   193.\n 5 Butterfly         100   55.3  193.\n 6 Butterfly         200  125.   193.\n 7 Freestyle          50   23.6  193.\n 8 Freestyle         100   51.9  193.\n 9 Freestyle         200  107.   193.\n10 Freestyle         500  306.   193.\n11 Freestyle        1650 1143.   193.\n12 IM                200  126.   193.\n13 IM                400  269.   193.\n14 Medley            200  104.   193.\n\n\nKeep in mind that functions work as they are programmed to work. Functions do not work like you think they work. You must understand the function and check our work to ensure your calculations are what you intend them to be.\n\n\nThe order of operations matters\nTo illustrate further, consider you want to calculate some summary statistics. You set out to obtain the mean and the standard deviation for your data. Those computations will be performed according to the grouping structure.\nWhen you compute standard deviation and the mean of Time, you assign the mean to Time because you want your plot to contain a clean name rather than one like Time_Mean that you will have to address in the plot.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time_sd = sd(Time),  # get sd of Time\n            Time = mean(Time)    # get mean, assign to same name\n            )\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance Time_sd   Time\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100    4.47   59.8\n 2 Backstroke        200    8.02  124. \n 3 Breaststroke      100    5.76   61.6\n 4 Breaststroke      200   10.5   139. \n 5 Butterfly         100    4.32   55.3\n 6 Butterfly         200    7.74  125. \n 7 Freestyle          50    1.99   23.6\n 8 Freestyle         100    4.00   51.9\n 9 Freestyle         200   10.8   107. \n10 Freestyle         500   20.3   306. \n11 Freestyle        1650   98.2  1143. \n12 IM                200    8.13  126. \n13 IM                400   22.2   269. \n14 Medley            200    3.41  104. \n\n\nBoth variables use the same data because the standard deviation assigns the value to a different variable name Time_sd. The mean() is not based on some changed variable.\nThe output is different from the one returned when the mean is computed before the standard deviation and in particular when the mean is assigned to Time. In this case, the standard deviation is based on this new Time variable. Because the standard deviation is a measure of variability, and Time does not vary based on the grouping structure, NA is returned.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),   # get mean, assign to same name\n            Time_sd = sd(Time)   # get sd of Time        \n            )\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance   Time Time_sd\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 Backstroke        100   59.8      NA\n 2 Backstroke        200  124.       NA\n 3 Breaststroke      100   61.6      NA\n 4 Breaststroke      200  139.       NA\n 5 Butterfly         100   55.3      NA\n 6 Butterfly         200  125.       NA\n 7 Freestyle          50   23.6      NA\n 8 Freestyle         100   51.9      NA\n 9 Freestyle         200  107.       NA\n10 Freestyle         500  306.       NA\n11 Freestyle        1650 1143.       NA\n12 IM                200  126.       NA\n13 IM                400  269.       NA\n14 Medley            200  104.       NA\n\n\nIf you really wanted the standard deviation of all the means, consider ungrouping and then compute the standard deviation or use .groups =  \"drop\" in summarize(). Realize, however, this latter functionality is experimental and may not work sometime later. You are likely better off using ungroup().\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%  # get mean, assign to same name\n  ungroup() %&gt;%\n  mutate(sd = sd(Time))\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n   Event        Distance   Time    sd\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  285.\n 2 Backstroke        200  124.   285.\n 3 Breaststroke      100   61.6  285.\n 4 Breaststroke      200  139.   285.\n 5 Butterfly         100   55.3  285.\n 6 Butterfly         200  125.   285.\n 7 Freestyle          50   23.6  285.\n 8 Freestyle         100   51.9  285.\n 9 Freestyle         200  107.   285.\n10 Freestyle         500  306.   285.\n11 Freestyle        1650 1143.   285.\n12 IM                200  126.   285.\n13 IM                400  269.   285.\n14 Medley            200  104.   285."
  },
  {
    "objectID": "modules/statistical_transformations.html#new-variable-columns",
    "href": "modules/statistical_transformations.html#new-variable-columns",
    "title": "Statistical transformations",
    "section": "New Variable Columns",
    "text": "New Variable Columns\ngroup_by() is not designed to create new variables but rather create groups. The function, however, does not require variables in a data frame in order to group based on their levels or differences in values.\n\ngroup_by() using a function\nHeretofore, we have grouped by column variables in a data frame. But you can also group in other ways, for example, by a variable calculated by a function. For example, if you wanted to group by standard deviations, you could calculated the standard deviation (Score-mean(Score)) / sd(Score) for each student and then cut() that variable into groups. cut will take a numeric vector variable and turn it into a factor variable of n groups as determined by what you pass to breaks. There is also an argument to make the factor ordered if you wish, ordered_result = TRUE but the default behavior does not order the factor. You can also change the level labels if you inspect the function.\n\nDATA %&gt;%\n  group_by(., z_factor = cut( x = ((Score - mean(Score)) / sd(Score) ), \n                          breaks = 5, \n                          ordered_result = T\n                          )\n  )\n\n# A tibble: 11 × 5\n# Groups:   z_factor [4]\n   Student      Score School District z_factor       \n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;          \n 1 Jim             80 A      West     (0.194,0.781]  \n 2 Sally           85 A      West     (0.781,1.37]   \n 3 June            79 B      West     (0.194,0.781]  \n 4 Mildred         80 B      West     (0.194,0.781]  \n 5 Tilford         81 C      East     (0.194,0.781]  \n 6 Beavis          91 C      East     (0.781,1.37]   \n 7 Herman          89 C      East     (0.781,1.37]   \n 8 Peppa           60 D      North    (-1.57,-0.979] \n 9 Kay             65 D      North    (-1.57,-0.979] \n10 Jake            67 E      North    (-0.979,-0.392]\n11 Name Missing    65 E      North    (-1.57,-0.979] \n\n\nYou can see that there are 4 different levels of the grouping variable. The tibble is grouped of course too.\nIf you struggle with remembering the formula for a z score, scale() will to the same thing.\n\nDATA %&gt;%\n  mutate(z = (Score - mean(Score))/sd(Score),\n         scale = scale(Score)\n         )\n\n        Student Score School District          z      scale\n1           Jim    80      A     West  0.3269018  0.3269018\n2         Sally    85      A     West  0.8000492  0.8000492\n3          June    79      B     West  0.2322724  0.2322724\n4       Mildred    80      B     West  0.3269018  0.3269018\n5       Tilford    81      C     East  0.4215313  0.4215313\n6        Beavis    91      C     East  1.3678261  1.3678261\n7        Herman    89      C     East  1.1785671  1.1785671\n8         Peppa    60      D    North -1.5656877 -1.5656877\n9           Kay    65      D    North -1.0925403 -1.0925403\n10         Jake    67      E    North -0.9032814 -0.9032814\n11 Name Missing    65      E    North -1.0925403 -1.0925403\n\n\nIf you want n groups based on specific breaks, then pass a vector of those break units. For example, if we want levels to correspond to some meaningful standard-deviation cuts. For example, if you wanted to group those with z scores ranging from infinitely negative to -2, -2 to -1, - to 1, 1 to 2, and 2 to infinitely large, you could specify the breaks. If there are no values in those ranges, then there won’t be any data for those breaks.\n\nDATA %&gt;%\n  group_by(z_factor = cut( scale(Score), \n                          breaks = c(-Inf, -2, -1, 1, 2, Inf),\n                          ordered_result = T\n                          ), \n           ) %&gt;%\n  ungroup() \n\n# A tibble: 11 × 5\n   Student      Score School District z_factor\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;   \n 1 Jim             80 A      West     (-1,1]  \n 2 Sally           85 A      West     (-1,1]  \n 3 June            79 B      West     (-1,1]  \n 4 Mildred         80 B      West     (-1,1]  \n 5 Tilford         81 C      East     (-1,1]  \n 6 Beavis          91 C      East     (1,2]   \n 7 Herman          89 C      East     (1,2]   \n 8 Peppa           60 D      North    (-2,-1] \n 9 Kay             65 D      North    (-2,-1] \n10 Jake            67 E      North    (-1,1]  \n11 Name Missing    65 E      North    (-2,-1] \n\n\nYou can also just group by the function without using cut() if you wish to group by those with identical values on the variable. In this case, using count() or tally() reveals there are only two instances with the same score.\n\nDATA %&gt;%\n  group_by(., z_factor = ((Score - mean(Score)) / sd(Score) )) %&gt;%\n  count(sort = TRUE)     # tally(sort = TRUE)\n\n# A tibble: 9 × 2\n# Groups:   z_factor [9]\n  z_factor     n\n     &lt;dbl&gt; &lt;int&gt;\n1   -1.09      2\n2    0.327     2\n3   -1.57      1\n4   -0.903     1\n5    0.232     1\n6    0.422     1\n7    0.800     1\n8    1.18      1\n9    1.37      1"
  },
  {
    "objectID": "modules/statistical_transformations.html#adddrop-grouping-variable-columns",
    "href": "modules/statistical_transformations.html#adddrop-grouping-variable-columns",
    "title": "Statistical transformations",
    "section": "Add/drop Grouping Variable Columns",
    "text": "Add/drop Grouping Variable Columns\nBy default, group_by() on a data frame that is already grouped (see earlier on grouped data frame), the existing grouping structure will be replaced by new grouping structure.\nLet’s get an example. Please note that this example assigned the tibble to an object but whether you assign or not, the grouped structure exists. So functions that follow the group_by() keep that structure.\n\nschool_grouped &lt;- DATA %&gt;%\n  group_by(School) \n\nschool_grouped\n\n# A tibble: 11 × 4\n# Groups:   School [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNow group by a new column:\n\nschool_grouped %&gt;%\n  group_by(District)\n\n# A tibble: 11 × 4\n# Groups:   District [3]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nYou will see the grouping structure has changed.\n# A tibble: 11 × 4\n# Groups:   District [3]\n\nRetain Grouping\nIf you want to retain the existing group, you would need to use .add = TRUE.\n\nschool_grouped %&gt;%\n  group_by(District, .add = TRUE)\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNotice in the console, that both School and District are included in the groups.\n# A tibble: 11 × 4\n# Groups:   School, District [5]"
  },
  {
    "objectID": "modules/statistical_transformations.html#why-care-about-grouping-structure",
    "href": "modules/statistical_transformations.html#why-care-about-grouping-structure",
    "title": "Statistical transformations",
    "section": "Why Care About Grouping Structure",
    "text": "Why Care About Grouping Structure\nWell, the functions you apply to a grouped tibble will sometimes lead to calculations that are not what you intend. We provided some examples earlier but given the importance of the issue, we may benefit from another example.\nLet’s say you want to compute the average for each school and add that school average for each student. This would tell you how the student differs from their school performance. Then you want to obtain the mean of all the schools and see how the school differs from all the schools.\nYou code it out:\n\nDATA %&gt;%\n  # group \n  group_by(School) %&gt;%\n  # calculate the mean of Score for each School\n  mutate(School_Mean = mean(Score)) %&gt;%  \n  # calculate the mean of all values (think Grand Mean from stats)\n  mutate(Mean_of_all = mean(School_Mean)) %&gt;%\n  # calculate the school performance relative to all\n  mutate(School_Performance = factor(case_when(\n    School_Mean &lt; Mean_of_all ~ \"Below Average\",\n    School_Mean == Mean_of_all ~ \"Average\",\n    School_Mean &gt; Mean_of_all ~ \"Above Average\"\n    ), ordered = T)\n  )\n\n# A tibble: 11 × 7\n# Groups:   School [5]\n   Student      Score School District School_Mean Mean_of_all School_Performance\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;ord&gt;             \n 1 Jim             80 A      West            82.5        82.5 Average           \n 2 Sally           85 A      West            82.5        82.5 Average           \n 3 June            79 B      West            79.5        79.5 Average           \n 4 Mildred         80 B      West            79.5        79.5 Average           \n 5 Tilford         81 C      East            87          87   Average           \n 6 Beavis          91 C      East            87          87   Average           \n 7 Herman          89 C      East            87          87   Average           \n 8 Peppa           60 D      North           62.5        62.5 Average           \n 9 Kay             65 D      North           62.5        62.5 Average           \n10 Jake            67 E      North           66          66   Average           \n11 Name Missing    65 E      North           66          66   Average           \n\n\nPerfect. OK, let’s plot it. Oh but first let me inspect the data. Um, why is School_Performance the same for all Students? Schools are not performing the same so they cannot all be average. Check your case_when() for errors because that where the new variable was created. Then you spend 40 days and 40 nights trying to fix your code. No matter what you do with case_when(), you cannot fix the problem. So you try to create 42 data frames to solve your problem. Even grandma knows that is a ridiculous strategy. She suggests you read the documentation for all of the functions you used because one time her pot-luck cake flopped and she inspected the expiration date for all of her ingredients and found the baking soda was old.\nYou discover that the grouping structure is retained on all operations until that grouping structure is removed or replaced."
  },
  {
    "objectID": "modules/statistical_transformations.html#variable-loss-with-summarize",
    "href": "modules/statistical_transformations.html#variable-loss-with-summarize",
    "title": "Statistical transformations",
    "section": "Variable loss with summarize()",
    "text": "Variable loss with summarize()\nBecause summarize() returns a tibble based on the grouping structure, you will lose all variables that are not in the grouping structure. By design, it no longer allows you to return a data frame with duplicated rows based on the variables passed to group_by().\nReturning to the school data, what this means, is that you cannot retain the School if you group by the District in order to obtain averages by district.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Mean = mean(Score))\n\n# A tibble: 3 × 2\n  District  Mean\n  &lt;chr&gt;    &lt;dbl&gt;\n1 East      87  \n2 North     64.2\n3 West      81  \n\n\nIf you try to add School to group_by(), then you will only obtain the averages by schools within districts.\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Mean = mean(Score)) \n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District  Mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou can try to summarize based on a variable without assign it to a function but that is no longer allowed with summarize(). The following code block will throw an error.\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Mean = mean(Score),\n          School               # add school \n          )"
  },
  {
    "objectID": "modules/statistical_transformations.html#an-alternative-to-summarize-reframe",
    "href": "modules/statistical_transformations.html#an-alternative-to-summarize-reframe",
    "title": "Statistical transformations",
    "section": "An alternative to summarize(): reframe()",
    "text": "An alternative to summarize(): reframe()\nInstead, you can use reframe(), which allows for previous functionality of summarize() that is now deprecated.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  reframe(Mean = mean(Score),\n          School,\n          Student\n          )\n\n# A tibble: 11 × 4\n   District  Mean School Student     \n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;       \n 1 East      87   C      Tilford     \n 2 East      87   C      Beavis      \n 3 East      87   C      Herman      \n 4 North     64.2 D      Peppa       \n 5 North     64.2 D      Kay         \n 6 North     64.2 E      Jake        \n 7 North     64.2 E      Name Missing\n 8 West      81   A      Jim         \n 9 West      81   A      Sally       \n10 West      81   B      June        \n11 West      81   B      Mildred     \n\n\nRemember that the operations in summarize(), mutate(), and reframe() all depend on the grouping structure. If you wanted to add variables, you would need to group a different way and you would need to add all variables into summarize() every step of the way.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  reframe(District_Mean = mean(Score),\n          School, \n          Student,\n          Score\n          ) %&gt;%\n  ungroup() %&gt;%\n  group_by(School) %&gt;%\n  reframe(School_Mean = mean(Score),\n          School, \n          Student,\n          Score,\n          District_Mean\n          ) %&gt;%\n  ungroup()\n\n# A tibble: 11 × 5\n   School School_Mean Student      Score District_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n 1 A             82.5 Jim             80          81  \n 2 A             82.5 Sally           85          81  \n 3 B             79.5 June            79          81  \n 4 B             79.5 Mildred         80          81  \n 5 C             87   Tilford         81          87  \n 6 C             87   Beavis          91          87  \n 7 C             87   Herman          89          87  \n 8 D             62.5 Peppa           60          64.2\n 9 D             62.5 Kay             65          64.2\n10 E             66   Jake            67          64.2\n11 E             66   Name Missing    65          64.2"
  },
  {
    "objectID": "modules/statistical_transformations.html#retaining-distinct-data-after-mutate-using-distinct",
    "href": "modules/statistical_transformations.html#retaining-distinct-data-after-mutate-using-distinct",
    "title": "Statistical transformations",
    "section": "Retaining distinct data after mutate() using distinct()`",
    "text": "Retaining distinct data after mutate() using distinct()`\nThis is just too tedious. Your better option is mutate() as all variables will be added to the full data frame. All variables are neatly and logically appended to the right hand side of the data frame.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\n\n# A tibble: 11 × 6\n# Groups:   School [5]\n   Student      Score School District District_Mean School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n 1 Jim             80 A      West              81          82.5\n 2 Sally           85 A      West              81          82.5\n 3 June            79 B      West              81          79.5\n 4 Mildred         80 B      West              81          79.5\n 5 Tilford         81 C      East              87          87  \n 6 Beavis          91 C      East              87          87  \n 7 Herman          89 C      East              87          87  \n 8 Peppa           60 D      North             64.2        62.5\n 9 Kay             65 D      North             64.2        62.5\n10 Jake            67 E      North             64.2        66  \n11 Name Missing    65 E      North             64.2        66  \n\n\nAlso, when you use a new group_by(), it will replace previous grouping structure by default. The following two code blocks return the same data frame.\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\n  \nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  ungroup() %&gt;%                   # ungroup\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\nIf you wish those variables to remain, you have a couple of options. The first would be to use mutate().\nNotice, however, that if you want to extract the summaries from the large data frame as you would have had you used summarize() , you cannot just select() your column of interest because the repetitions will exist for each row in the data frame.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  select(c(\"School\", \"District_Mean\"))\n\nAdding missing grouping variables: `District`\n\n\n# A tibble: 11 × 3\n# Groups:   District [3]\n   District School District_Mean\n   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n 1 West     A               81  \n 2 West     A               81  \n 3 West     B               81  \n 4 West     B               81  \n 5 East     C               87  \n 6 East     C               87  \n 7 East     C               87  \n 8 North    D               64.2\n 9 North    D               64.2\n10 North    E               64.2\n11 North    E               64.2\n\n\nYou can obtain the rows that are distinct() (unique) and then pick() the ones to keep.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  distinct(., pick(c(\"District\", \"District_Mean\")))\n\n# A tibble: 3 × 2\n# Groups:   District [3]\n  District District_Mean\n  &lt;chr&gt;            &lt;dbl&gt;\n1 West              81  \n2 East              87  \n3 North             64.2\n\n\nBut you will need to ungroup() before distinct() because, as we have mentioned before, all subsequent functions other than group_by() will maintain the previous grouping structure by default.\n\nDATA %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score)) %&gt;%\n  ungroup()\n\n# A tibble: 11 × 5\n   Student      Score School District School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n 1 Jim             80 A      West            82.5\n 2 Sally           85 A      West            82.5\n 3 June            79 B      West            79.5\n 4 Mildred         80 B      West            79.5\n 5 Tilford         81 C      East            87  \n 6 Beavis          91 C      East            87  \n 7 Herman          89 C      East            87  \n 8 Peppa           60 D      North           62.5\n 9 Kay             65 D      North           62.5\n10 Jake            67 E      North           66  \n11 Name Missing    65 E      North           66"
  },
  {
    "objectID": "modules/statistical_transformations.html#the-jitter-problem-with-full-data-frame",
    "href": "modules/statistical_transformations.html#the-jitter-problem-with-full-data-frame",
    "title": "Statistical transformations",
    "section": "The Jitter problem with full data frame",
    "text": "The Jitter problem with full data frame\nJittering takes place at the row level. Because the full data frame is used, each row plotted gets jitter. This means that the group mean that is on each row (redundant per group) is plotted. In such cases, you might be better off using one data frame for the full plot and a summarized data frame for the other plot. You can define the data frame in ggplot() or in the specific geom_point(). In this example, we will define it in ggplot() along with aesthetics. This will be inherited by default for the first geom_point() and then we can specify for the second geom_point().\nBecause there are different data frames, Time can be used in both data sets. There is no need to have two different variables as there is for the full data set.\n\nSWIMMEAN &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;% \n  summarize(Time = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  # and we need to add a shape too\n  mutate(\n    Shape  = ifelse(stringr::str_detect(School, \"CMS\"), 21, 24) # filled\n  ) \n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\nSWIMMEAN\n\n# A tibble: 12 × 4\n   Event        School  Time Shape\n   &lt;chr&gt;        &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke   CMS     97.8    21\n 2 Backstroke   PP     100.     24\n 3 Breaststroke CMS    105.     21\n 4 Breaststroke PP      89.3    24\n 5 Butterfly    CMS     73.9    21\n 6 Butterfly    PP      80.5    24\n 7 Freestyle    CMS     81.2    21\n 8 Freestyle    PP     102.     24\n 9 IM           CMS    162.     21\n10 IM           PP     126.     24\n11 Medley       CMS    104.     21\n12 Medley       PP     104.     24\n\n\nNotice that this data frame contains only four variables: Event, School, Time, and Shape. All aesthetics for a plot using that data set will be constrained to those variables. Because both data frames contain them, we can just add the aesthetics to the plot object rather than the geom.\n\nsubset_identity_plot &lt;- SWIM_NEW %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event,\n                       y = Time, \n                       shape = Shape\n                       )\n         ) +\n  # plot all data (y = Time) from SWIM\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             alpha = .8,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = Time) from SWIMMEAN\n  geom_point(data = SWIMMEAN,\n             size = 3,\n             fill = \"grey60\",\n             stroke = 1,\n             alpha = 1,\n             position = position_jitter(seed = 167, height = 0, width = .3)\n             ) +\n  coord_flip() +\n  scale_shape_identity() +\n  labs(caption = \"Caption illustration:\\nCMS (cicle),  PP (triangle); Mean (filled)\")\n\nsubset_identity_plot\n\n\n\n\nBoth plots together:\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(full_identity_plot, \n                       subset_identity_plot, ncol = 1)\n  )\n)\n\n\n\n\nWhat you see in the second plot is what you might expect. Remember, that if you want to pass a grouping variable summary as an additional layer of a plot, you might be better off creating a separate data frame and pass it separately."
  },
  {
    "objectID": "modules/statistical_transformations.html#examples-of-color-versions",
    "href": "modules/statistical_transformations.html#examples-of-color-versions",
    "title": "Statistical transformations",
    "section": "Examples of Color Versions",
    "text": "Examples of Color Versions\n\ncolor_plot1 &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;%\n  mutate(MeanTime = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  ggplot(., aes(x = Event, \n                y = Time, \n                col = School, \n                fill = School\n                )\n         ) +\n  # plot all data (y = Time)\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             pch = 1,\n             alpha = .7,\n             stroke = 1,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = MeanTime)\n  geom_point(aes(y = MeanTime), \n             size = 2,\n             alpha = .4\n             ) +\n  coord_flip() +\n  labs(caption = \"Caption illustration:\\nMeans are closed circles\")\n\ncolor_plot2 &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;% \n  mutate(MeanTime = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  ggplot(., aes(x = Event, \n                y = Time, \n                col = School, \n                fill = School\n                )\n         ) +\n  # plot all data (y = Time)\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             alpha = .7,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = MeanTime)\n  geom_point(aes(y = MeanTime), \n             pch = 1,\n             size = 2,\n             stroke = 1,\n             alpha = .4\n             ) +\n  coord_flip() +\n  labs(caption = \"Caption illustration:\\nMeans are open circles\")\n\nplot(gridExtra::arrangeGrob(color_plot1, color_plot2, ncol = 1))"
  },
  {
    "objectID": "modules/statistical_transformations.html#a-note-on-size",
    "href": "modules/statistical_transformations.html#a-note-on-size",
    "title": "Statistical transformations",
    "section": "A note on size",
    "text": "A note on size\nFor geom_point(), you should understand what is happening when you pass an argument (e.g., size = 2) to the parameter because of its implications for bias in data visualizations. The size parameter scales on both the x and y dimensions proportionately which means that for any circle that doubles the size of the point, its radius will also double. When the radius doubles, however, the diameter and circumference also double. You might guess where this discussion is going.\nIf size is a constant, this likely will not be a problem. If, however, size is mapped to a variable, then then you have a perceptual challenge related to difficulty with comparing area. See Cleveland & McGill (1984). Moreover, because the area of a circle is proportional to the square of its radius, doubling the point size increases area fourfold.\nHere is an example.\n\nggplot(data = \n         data.frame(x     = 0, \n                    y     = 0, \n                    panel = c(\"Size = 13\", \"Size = 26\"), \n                    size = c(13, 26)),\n       mapping = aes(x, y, size = size)\n       ) + \n  geom_point() +\n  scale_x_continuous(limits = c(-5, 5),\n                     breaks = seq(-5, 5, 1)) +\n  scale_y_continuous(limits = c(-5, 5),\n                     breaks = seq(-5, 5, 1)) +\n  scale_size_identity() +\n  facet_wrap(.~panel) + \n  labs(x = NULL, y = NULL)"
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html",
    "href": "modules/project_management/using_git_and_github.html",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "",
    "text": "This module focuses on getting organized. Rather than save files in a haphazard way that will just introduce stress to your life, we will focus on creating order. The best way to create order and stay organized is to 1) create projects in RStudio, 2) create directories and sub-directories that leave no ambiguity about where your files are, and 3) manage all directory paths and file paths simply using the {here} library. Another way is to connect that project with a remote repository saved someplace like GitHub for collaboration. In certain classes (and for your team project), you will use Git to interact with remote repositories connected to Projects in RStudio.\nIn order to maintain organization for this class and the project, you will set up a class folder (aka directory) on your computer. You will then create an RStudio project and connect it to a remote private repository on your GitHub account. The reason for its privacy is because of data related to certain exercises.\nYou will use this RStudio project for all class exercises and homework so that there is no ambiguity about where your files are saved. Finally, you will create directories within your new project directory so that you have an organized directory structure for storing your files. Systems paths for project files and directories will be manage using the {here} library. This process will also ensure that each student’s computer is configured in the same manner.\nReading through these steps, however, will facilitate your ability to apply the concepts and run the associated functions in class. Thus, all students will gain some basic experience with Git commands and a remote repository. Students will be collaborators of a repository for their team project. Coding leads will carry the responsibility of maintaining the organization of the team’s private repository."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#overview",
    "href": "modules/project_management/using_git_and_github.html#overview",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "",
    "text": "This module focuses on getting organized. Rather than save files in a haphazard way that will just introduce stress to your life, we will focus on creating order. The best way to create order and stay organized is to 1) create projects in RStudio, 2) create directories and sub-directories that leave no ambiguity about where your files are, and 3) manage all directory paths and file paths simply using the {here} library. Another way is to connect that project with a remote repository saved someplace like GitHub for collaboration. In certain classes (and for your team project), you will use Git to interact with remote repositories connected to Projects in RStudio.\nIn order to maintain organization for this class and the project, you will set up a class folder (aka directory) on your computer. You will then create an RStudio project and connect it to a remote private repository on your GitHub account. The reason for its privacy is because of data related to certain exercises.\nYou will use this RStudio project for all class exercises and homework so that there is no ambiguity about where your files are saved. Finally, you will create directories within your new project directory so that you have an organized directory structure for storing your files. Systems paths for project files and directories will be manage using the {here} library. This process will also ensure that each student’s computer is configured in the same manner.\nReading through these steps, however, will facilitate your ability to apply the concepts and run the associated functions in class. Thus, all students will gain some basic experience with Git commands and a remote repository. Students will be collaborators of a repository for their team project. Coding leads will carry the responsibility of maintaining the organization of the team’s private repository."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#libraries-used",
    "href": "modules/project_management/using_git_and_github.html#libraries-used",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.3: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials\n{gh}: 1.4.1: for querying the github api\n{gert}: 2.0.1: optional R library approach for git commands\n\n\nReadings and Preparation\nBefore Class: First, watch course videos (and/or read) to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nComplete the items in the To Do: Steps of the Task section.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\nWarning\nDo not try to cheat the system and jump ahead. If you do, just like playing the Monopoly board game, your chance card may read “Go to jail. Go directly to jail. Do not pass go. Do not collect $200.” In other words, you cannot complete these steps without ensuring that your credentials are set. You will run into errors and try to contact me. If the following code does not return information for your login, your github account, scopes, and a token, you will be unable to proceed. If it does but your token is expired, you cannot proceed. Ensure you have set your credentials.\ngh::gh_whoami()\n\n\nTo Do: Steps of the Task\nFollowing the sections below, you will:\n\nCreate a Version-Control Project with RStudio\n\n\nName it dataviz-exercises (for class exercises and your homework)\n\n\nMake file edits, stage those edits, and commit them\nPush commits to GitHub\n\nIn class, we will practice using RStudio along with some simple Git commands for adding, committing, and pushing files."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#creating-a-local-directory-for-class",
    "href": "modules/project_management/using_git_and_github.html#creating-a-local-directory-for-class",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Creating a Local Directory for Class",
    "text": "Creating a Local Directory for Class\nCreate a folder (aka directory) named \"dataviz\" (yes, all lowercase) on your computer. I recommend creating the directory someplace where you might not accidentally delete it. Create only one so as not to confuse yourself."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#connecting-the-repository-to-an-rstudio-project",
    "href": "modules/project_management/using_git_and_github.html#connecting-the-repository-to-an-rstudio-project",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Connecting the Repository to an RStudio Project",
    "text": "Connecting the Repository to an RStudio Project\nYou should already have a repository on GitHub named “dataviz-exercises” which you created from this template repository. You will now create an RStudio project and connect it to that remote repository on your GitHub account.\nWhen you create the project inside your class directory, your directory structure will look like this:\n└── dataviz\n│   └── dataviz-exercises \n\nIn RStudio, File &gt; New Project &gt; Version Control &gt; Git.\nIn the pop-up, you will see a request for the “repository URL”. Paste the URL of the GitHub repository. This URL will be the same as what you see on your GitHub account. However, we need to add .git to the end of it.\n\n    https://github.com/&lt;your_github_username&gt;/dataviz-exercises.git\n\nWhen you create the project, a directory will be created as a sub-directory of your main /dataviz directory. Thus, you will see /dataviz/dataviz-exercises.\n\nWARNING: Do not create the project inside of an existing project’s directory.\nNote: I recommend that you also select “Open in new session” in order to compartmentalize projects. When you work on the team project, open the project. When you work on your homework or other class exercises, open your homework project.\n\nClick “Create Project” to create the new project directory, which will create:\n\na project directory on your computer\na project file with file extension .Rproj\na Git repository or link to the remote GitHub repository for the project (also an RStudio Project)\n\n\nIf the repository already exists on GitHub (and it does in this instance) you should see RStudio flash a connection to GitHub and likely pull the repo contents down to your newly-created project directory. In this case, however, your local Git repository on RStudio will contain few files."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#unzipping-the-directory-structure",
    "href": "modules/project_management/using_git_and_github.html#unzipping-the-directory-structure",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Unzipping the Directory Structure",
    "text": "Unzipping the Directory Structure\nAlthough building the directory structure on your own is possible, the repository has a .zip file which contains all of the directories needed for the project. You can unzip them manually or do this in RStudio with the \"unzip_compressed_file.R\" script. The script has not been tested on a Mac so there may be an error."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#understanding-the-directory-structure",
    "href": "modules/project_management/using_git_and_github.html#understanding-the-directory-structure",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Understanding the Directory Structure",
    "text": "Understanding the Directory Structure\nDirectory structures are used for organization. Each directory and sub directory has a purpose, which is to contain files of a certain type. As long as you know what the goal of the file is, you know where to save it. When working with teams, this common language avoids many problems.\nAlthough there are different ways to create project directory structures and different ways to name those directories, we will use the following structure. Not all directories will be used for all types of projects.\nInside your /dataviz/dataviz-exercises directory your full project directory structure should look like the one below.\n└── data\n│   └── interim \n│   ├── processed\n│   └── raw\n├── dataviz-exercises.Rproj (the R project file)\n├── docs\n├── .gitignore              (a version-control gitignore file)\n├── README.md               (a read me file)\n├── refs\n└── reports\n│   ├── figs\n│   └── images\n└── src\n│   ├── data\n│   ├── figs\n│   ├── functions\n│   └── utils\n\nDirectory and Sub-Directory Purpose\nThe purpose of each directory and sub-directory is explained following the structure.\n\n/data: for raw/virgin data files and modified data files\n/docs: for document files like the project description, any dictionary of variable names, etc.\n/refs: for references, papers, reading materials, and other document\n/report: for R Markdown (e.g., .Rmd) report files and their output file types (e.g., .docx, .pdf, .html)\n/src: for all source code related files (e.g., .R scripts, functions, .py files, etc.). General scripts can be saved in the top level /src but most of your script files will be saved in /src/figs because you will create figures\n\nMore directory descriptions are provided below.\nData Files\nInside /data, add the following sub-directories:\n\n/raw, for /data/raw/: containing raw data files obtained from sources (e.g., .csv, .tsv, .xlxs)\n/interim, for /data/interim/: .Rds (highly recommended) files containing intermediate transformed data; cleaned, merged, etc. but not processed fully to be in final form\n/processed, for /data/processed/; .Rds (highly recommended) files containing finalized data (e.g., aggregated, summaries, and data frames ready for plotting\n\nNOTE: For this course, you will see me write data as .Rds files using the saveRDS() function because this format will preserve variable formatting which will affect plots.\nWARNING: If you process and save those data files as .csv, .xlsx, or similar, you will likely find yourself working harder by recoding solutions you have already performed. I do not recommend this except for final versions that no longer require processing.\nSource/Code Files\nInside /src, add the following sub-directories:\n\n/data, for /src/data/: containing .R scripts needed to download or generate data\n/figs, for /src/figs/: containing .R scripts needed to create visualizations\n/functions, for /src/functions/: containing all .R functions needed that do not belong to libraries\n\nFiles for Reports\nInside /report, add the following sub-directories:\n\n/figs for /report/figs/: containing visualization files (e.g., .png) for the report\n/images for /report/images/: containing image files (e.g., .png) for the report\n\nWhen testing your plots, you may wish to add notes or other written content that you can use in conjunction with your plots. In such cases, I recommend creating R Markdown files with meaningful names for taking notes. You can save these reports in the top-level of /report and then source your .R figure script\nBelow are examples of an .R script for creating your visualizations and an .Rmd file that reads the .R script and renders the .png file within it. These files are also located under the Example Files & Other course tab. Your team report will utilize this same structure, though details and files will be also located under the Project course tab.\n\nexample-rmarkdown-file-with-fig-script.Rmd\nexample-figure-script.R\n\nMoving forward, save all data to their relevant sub-directories within /data; create all .R code files and scripts in files in /src, including scripts use to create your visualizations and .png plot files; create all exercise or homework R Markdown files (e.g., .Rmd) in /report. Finally, any readings or references can can saved in /refs and any other document files can be saved in /docs. Reserve /report/figs for writing/saving plots or figures. All paths to directories and files for reading and writing files will be managed using the {here} library."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#summary",
    "href": "modules/project_management/using_git_and_github.html#summary",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Summary",
    "text": "Summary\nYou now understand how to create projects in R, how to connect projects to remote GitHub repositories, and how to use directories intentionally."
  },
  {
    "objectID": "modules/project_management/using_git_and_github.html#other-resources",
    "href": "modules/project_management/using_git_and_github.html#other-resources",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Other Resources",
    "text": "Other Resources\n\nGit Client:\n\nGit clients work like the RStudio Gui option described above but likely much better. One client is GitKraken. * If you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface. * GitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\n\nhappygitwithr"
  },
  {
    "objectID": "modules/legends_and_arrangement.html",
    "href": "modules/legends_and_arrangement.html",
    "title": "Legends and arrangement",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#readings",
    "href": "modules/legends_and_arrangement.html#readings",
    "title": "Legends and arrangement",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Redundant coding"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#external-functions",
    "href": "modules/legends_and_arrangement.html#external-functions",
    "title": "Legends and arrangement",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions_view_html.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#libraries",
    "href": "modules/legends_and_arrangement.html#libraries",
    "title": "Legends and arrangement",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting\n{forcats} 1.0.0: for factor reordering"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#load-libraries",
    "href": "modules/legends_and_arrangement.html#load-libraries",
    "title": "Legends and arrangement",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(forcats)"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#ggplot2guide_legend",
    "href": "modules/legends_and_arrangement.html#ggplot2guide_legend",
    "title": "Legends and arrangement",
    "section": "ggplot2::guide_legend()",
    "text": "ggplot2::guide_legend()\nguide_legend() is the go to function for customizing both the appearance and behavior of legends. For example, if the legends require some fine-tuning from their out-of-the-box behavior, you can override its behavior. The goal should be to improve the overall presentation in order to facilitate perception, interpretation, memory for, and decision-making about the data visualization representing the data.\nThere is much you can do with guide_legend():\nguide_legend(\n  title = waiver(),\n  title.position = NULL,\n  title.theme = NULL,\n  title.hjust = NULL,\n  title.vjust = NULL,\n  label = TRUE,\n  label.position = NULL,\n  label.theme = NULL,\n  label.hjust = NULL,\n  label.vjust = NULL,\n  keywidth = NULL,\n  keyheight = NULL,\n  direction = NULL,\n  default.unit = \"line\",\n  override.aes = list(),\n  nrow = NULL,\n  ncol = NULL,\n  byrow = FALSE,\n  reverse = FALSE,\n  order = 0,\n  ...\n)"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#ggplot2guides",
    "href": "modules/legends_and_arrangement.html#ggplot2guides",
    "title": "Legends and arrangement",
    "section": "ggplot2::guides()",
    "text": "ggplot2::guides()\nguides() can be used to set guides for each scale. The documentation explains also that the guides can be set for each scale individually using the guide argument, or en masse with guides(). For example, scale_shape(guide = \"legend\") will\nBecause the legend is also part of an overall plot theme, some legend adjustments can be made using ggplot2::theme()."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#scale_aesthetic_type-functions",
    "href": "modules/legends_and_arrangement.html#scale_aesthetic_type-functions",
    "title": "Legends and arrangement",
    "section": "scale_<aesthetic>_<type>() functions",
    "text": "scale_&lt;aesthetic&gt;_&lt;type&gt;() functions\nGuides can be specified in each scale_&lt;aesthetic&gt;_&lt;type&gt;() function or more generally in guides(). As the {ggplot} documentation explains, guide = \"legend\" used inside a scale_&lt;aesthetic&gt;_&lt;type&gt;() , function is “syntactic sugar” for guide = guide_legend(). For example, scale_color_manual(guide = \"legend\") would achieve the same outcome as guides(col = guide_legend()). A benefit for the latter is that you may not need to remember the aesthetic and type of the variable mapped. In order to learn more about setting specific characteristics of each scale in more detail, review the documentation for guides()."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#examining-base-plots-legend-elements",
    "href": "modules/legends_and_arrangement.html#examining-base-plots-legend-elements",
    "title": "Legends and arrangement",
    "section": "Examining Base Plots: Legend Elements",
    "text": "Examining Base Plots: Legend Elements\nIn the initial base plot, you can see that the Team variable mapped to the col aesthetic appears in the legend positioned to the right of the plot. There is a title, which inherently takes on the name of the column variable in the data frame. There are keys, which inherently take on the values of the variations (e.g., levels). If the variable mapped to the aesthetic is a constant, or has no variation or levels within its vector, the legend will nevertheless appear but will present only a single key. In such instances, a legend likely has little to no perceptual utility and should either be removed from the plot and/or be set manually using one of the scale_&lt;aesthetic&gt;_manual() functions.\nIn the additional base plots, legends again appear to the right of the plot. There are titles for each legend as well as their keys. When there is more than one legend, legends are ordered positionally."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#removing-a-legend",
    "href": "modules/legends_and_arrangement.html#removing-a-legend",
    "title": "Legends and arrangement",
    "section": "Removing a Legend",
    "text": "Removing a Legend\nThe most crude way to change a legend position is to remove it completely from the visualization. Although the plots have more than one key in their legend, which add some perceptual utility, there may be instances where you would wish to remove the plot completely. For instance, perhaps you use direct labeling, annotation, or some other detail that obviate the legend’s utility.\n\nUsing theme() with a single legend:\n\nbase_plot + theme(legend.position = \"none\")\n\n\n\n\n\n\nUsing theme() with multiple legends:\nWhen there is more than one legend, all legends will be removed when set to legend.position = \"none\".\n\nbase_plot_2 + theme(legend.position = \"none\")\n\n\n\n\n\n\nUsing guides() with a single legend:\nguides(&lt;aesthetic&gt; = \"none\")\nThe guides() function allows you to change many legend properties. Although the syntax is a little bit more complicated, guides() along with helper function guide_legend() used to control the legend guide may provide greater flexibility in the long run.\nBecause the plot contains a variable mapping to col, the legend can also be removed using guides() and either set the aesthetic element to \"none\" or FALSE. As you will see with other functions, however, FALSE may be deprecated. In addition, although in many examples you will see the aesthetic referenced by its full name color, using its abbreviated name col will achieve the same outcome. For this purpose, my examples in this module will use the abbreviated form so that it matches that which I use in mapping = aes().\n\nbase_plot + guides(col = \"none\")\n\n\n\n# or base_plot + guides(col = FALSE)\n\n# or base_plot + guides(color = \"none\") will also work\n\n\n\nUsing guides() with a multiple legends:\nWith Plot 2, there is both col and size, so we would specify one or both.\nRemove the color legend:\n\nbase_plot_2 + guides(col = \"none\")\n\n\n\n# or base_plot_2 + guides(col = FALSE)\n\nRemove the size legend:\n\nbase_plot_2 + guides(size = \"none\")\n\n\n\n\nRemove both legends:\n\nbase_plot_2 + guides(col = \"none\", \n                     size = FALSE\n                     )\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\n\nUsing scale_&lt;aesthetic&gt;_&lt;type&gt;() with a single legend:\nWhen using scale_*() functions, you need to set guide = \"none\" as the use of FALSE has been deprecated.\nRemove the color legend:\n\nbase_plot +\n  scale_color_discrete(guide = \"none\")\n\n\n\n\nRemove the size legend:\n\nbase_plot +\n  scale_size(guide = \"none\")\n\n\n\n\nRemove both legends:\n\nbase_plot_2 +\n  scale_color_discrete(guide = \"none\") +\n  scale_size(guide = \"none\")\n\n\n\n\nWhen using specific scale_&lt;aesthetic&gt;_&lt;type&gt;() functions, however, you must ensure that they are applied according to their aesthetic and type or that functions assuming a particular aesthetic and type (e.g., scale_color_gradient()) adhere to the aesthetic and type defined in the plot object. For example, because the variable type is discrete, scale_color_manual(guide = \"legend\"), scale_color_continuous(guide = \"legend\"), scale_color_binned(guide = \"legend\") and some others will throw errors although scale_color_hue(guide = \"legend\"), scale_color_brewer(guide = \"legend\") will not throw errors. You just need to remember that your functions need to match the aesthetic and type already used in the plot object. this"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#repositioning-legends-right-left-top-bottom",
    "href": "modules/legends_and_arrangement.html#repositioning-legends-right-left-top-bottom",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (Right, Left, Top, Bottom)",
    "text": "Repositioning Legends (Right, Left, Top, Bottom)\nThe default position is \"right\". Changing the spatial positioning of the legend can be achieved using the same theme() function and by setting the legend.position argument to \"left\", \"top\", \"bottom\". Only some of these position modifications will be illustrated here. You can also achieve this using the guides() and guide_legend() combination illustrated earlier.\n\nUsing theme() with a single legend:\n\nbase_plot +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nUsing theme() with multiple legends:\n\nbase_plot_2 +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#repositioning-legends-changing-their-spatial-order",
    "href": "modules/legends_and_arrangement.html#repositioning-legends-changing-their-spatial-order",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (Changing their Spatial Order)",
    "text": "Repositioning Legends (Changing their Spatial Order)\nWhen you have more than one legend, their ordering can be rearranged using guides() and by specifying an order within helper function guide_legend(). To control each legend specifically, remember the guide argument is the aesthetic itself as seen here.\nguides(&lt;aesthetic&gt; = guide_legend())\nguides(\n  col = guide_legend(),\n  fill = guide_legend(),\n  shape = guide_legend(),\n  size = guide_legend()\n  )"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#creating-a-complex-plot",
    "href": "modules/legends_and_arrangement.html#creating-a-complex-plot",
    "title": "Legends and arrangement",
    "section": "Creating a Complex Plot",
    "text": "Creating a Complex Plot\nWe will create a more complex plot to better illustrate reordering methods.\n\n(plot_complex &lt;- SWIM |&gt;\n  filter(Event %in% c(\"Breaststroke\", \"Backstroke\")) |&gt;\n  filter(Distance &lt;= 200) |&gt;\n  mutate(Distance = factor(Distance)) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time,\n                       fill = Team,\n                       size = Time,\n                       col = Event,\n                       shape = Distance\n                       )\n         ) +\n  geom_point()\n)\n\n\n\n\nplot_complex contains four legends. The variables are ordered from top to bottom: Time, Event, Distance, and Team and the aesthetics are ordered: size, col, shape and fill. These orders indicated that legends do not appear arranged alphabetically by variable name or aesthetic. Rather than worry about how they are ordered by default, lets just concern ourselves with arranging the order to what we want.\n\nplot_complex\n\n\n\nplot_complex +\n  guides(\n    col = guide_legend(order = 1),\n    fill = guide_legend(order = 3),\n    shape = guide_legend(order = 2),\n    size = guide_legend(order = 4)\n  )\n\n\n\n\nThe numbers do not need to be sequential but rather just differ in magnitude.\n\nplot_complex +\n  guides(\n    col = guide_legend(order = 21),\n    fill = guide_legend(order = 1),\n    shape = guide_legend(order = 38),\n    size = guide_legend(order = 49)\n  )\n\n\n\n\nNote: If you wish to make changes to a legend corresponding to a continuous aesthetic like col (or color) may be, guide_legend() will not work. You will need to use guide_colorbar() as show here.\n\nSWIM |&gt;\n  filter(Event %in% c(\"Breaststroke\", \"Backstroke\")) |&gt;\n  filter(Distance &lt;= 200) |&gt;\n  mutate(Distance = factor(Distance)) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time,\n                       fill = Team,\n                       size = Time,\n                       col = Time,\n                       shape = Distance\n                       )\n         ) +\n  geom_point() +\n  guides(\n    col = guide_colorbar(order = 1),\n    fill = guide_legend(order = 2),\n    shape = guide_legend(order = 3),\n    size = guide_legend(order = 4)\n  )"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#repositioning-legends-xy-coordinates",
    "href": "modules/legends_and_arrangement.html#repositioning-legends-xy-coordinates",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (xy Coordinates)",
    "text": "Repositioning Legends (xy Coordinates)\nIn addition to global positioning, you can have more direct control over the exact coordinates of the legend position if the gross location options are not appropriate. This type of repositioning is necessary when you want to position a legend in the site the plot itself rather than next to it.\nThe fine-grained tuning is achieved by specifying a two-element vector for the xy coordinates of the plot but not according to the x and y axis scales. Using four xy coordinate pairs, we can see that the plot ranged from 0,0 to 1,1 so our numeric values need to fall between 0 and 1 inclusive.\n\nsuppressWarnings(plot(gridExtra::arrangeGrob(\n  base_plot + \n    theme(legend.position = c(0, 0)) + \n    labs(title = \"legend.position = c(0, 0)\"),\n  \n  base_plot + \n    theme(legend.position = c(0, 1)) + \n    labs(title = \"legend.position = c(0, 1)\"),\n  \n  base_plot + \n    theme(legend.position = c(1, 0)) + \n    labs(title = \"legend.position = c(1, 0)\"),\n    \n  base_plot + \n    theme(legend.position = c(1, 1)) + \n    labs(title = \"legend.position = c(1, 1)\"),\n  ncol = 2\n  ))\n  )\n\n\n\n\nBy deduction, legend.position = c(.5, .5) will position the legend in the plot center.\n\nbase_plot + \n    theme(legend.position = c(.5, .5))\n\n\n\n\nWe can also place it more strategically someplace in the bottom right.\n\nbase_plot + \n    theme(legend.position = c(.8, .2))\n\n\n\n\nNote: Depending on the plot dimensions and the uniformity of the x and y axis scales, you may need to experiment a bit."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#adjusting-legend-label-position",
    "href": "modules/legends_and_arrangement.html#adjusting-legend-label-position",
    "title": "Legends and arrangement",
    "section": "Adjusting Legend Label Position",
    "text": "Adjusting Legend Label Position\nThe text labels corresponding to the aesthetics can be rearranged by setting label.position to \"right\", \"left\", \"top\", \"bottom\" (e.g., guide_legend(label.position = \"top\")). You can also remove the labels using guides(col = guide_legend(label = FALSE)) although a color or shape seen in a plot without a corresponding label would be confusing.\n\nRemoving a Legend Labels\nguides(&lt;aesthetic&gt; = guide_legend(label = FALSE))\n\nbase_plot_2 +\n  guides(col = guide_legend(label = FALSE))\n\n\n\n\nBut what do the colors represent?\n\n\nChanging Legend Label Position\n\nsuppressWarnings(\n  plot(gridExtra::arrangeGrob(\n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"right\")) + # default\n      labs(title = 'label.position = \"right\"', tag = \"A\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"left\")) +\n      labs(title = 'label.position = \"left\"', tag = \"B\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"top\")) +\n      labs(title = 'label.position = \"top\"', tag = \"C\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"bottom\")) +\n      labs(title = 'label.position = \"bottom\"', tag = \"D\"),\n    ncol = 2\n  ))\n) \n\n\n\n\n\n\nChanging the Labels Direction/Orientation\nLegend labels are often presented vertically when legends are placed to the right or left of the plot and presented horizontally when oriented to the top or bottom of the plot. You may with to change this detail.\n\nAdjusting generally using theme()\ntheme(legend.direction = \"\") will adjust all legends to be \"horizontal\" or \"vertical\" (default).\n\nbase_plot_2 + \n  theme(legend.direction = \"vertical\")\n\n\n\nbase_plot_2 + \n  theme(legend.direction = \"horizontal\")\n\n\n\n\n\n\nAdjusting specifically using guides() and `guide_legend()\nguides(&lt;aesthetic&gt; = guide_legend(direction = \"\"))\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"vertical\"),\n         size = guide_legend(direction = \"horizontal\")\n         )\n\n\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"horizontal\"),\n         size = guide_legend(direction = \"horizontal\")\n         )\n\n\n\n\n\n\nAdjusting the orientation and the location with theme() and guides():\n\nbase_plot_2 + \n  theme(legend.direction = \"horizontal\", \n        legend.position = \"bottom\"\n        )\n\n\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"horizontal\"),\n         size = guide_legend(direction = \"horizontal\")\n         ) +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#comparing-legend-point-size-in-plots",
    "href": "modules/legends_and_arrangement.html#comparing-legend-point-size-in-plots",
    "title": "Legends and arrangement",
    "section": "Comparing Legend Point Size in Plots",
    "text": "Comparing Legend Point Size in Plots\nLet’s create some data visualizations in order to investigate the legend properties. One plot will reflect the default behavior of geom_point() adding a legend to a plot corresponding to the mapping a variable to the color aesthetic using col = Team. Another plot will map col = Team but also set size = 4. A final plot will map col = Team and map size = Team so the size will be determined by the geom.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(col = Team)) +\n  labs(title = \"default\",\n       tag = \"A\"\n       )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(size = 4, aes(col = Team)) +\n  labs(title = \"size = 4\",\n       tag = \"B\"\n       )\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(size = Team, col = Team)) + # note the warning: Using size for a discrete variable is not advised.\n  labs(title = \"aes(size = Team)\",\n       tag = \"C\"\n       )\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(plot1, plot2, plot3, ncol = 1)\n  )\n  \n)\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Using size for a discrete variable is not advised.\n\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAll three plots contain legends but they differ in the rendering of point size. Plot A has the smallest circles and Plot C has variation in circle size because both col and size are mapped to the variable. Importantly, the point size in the legend and in the plot are the same and this characteristic is important mapping a variable to size. Mismatching point sizes between the plot and the legend would certainly be confusing. When size is a constant, however, changing their size in the legend can ease the processing demand. The point size on the legend may result in difficulty with seeing the color, even for those which normal color vision. You don’t want your audience to squint when you are given your talk or stare at the legend in an attempt to understand the color differences."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#adjusting-keys-in-legends",
    "href": "modules/legends_and_arrangement.html#adjusting-keys-in-legends",
    "title": "Legends and arrangement",
    "section": "Adjusting Keys in Legends",
    "text": "Adjusting Keys in Legends\nFor various reasons, you may need to adjust the orientation, size, color, or some aesthetic property of legend keys in order to make plots more user friendly. We will work through some examples of these modifications using guide_legend() for a given aesthetic.\n\nReversing the Legend Keys\nIf your legend order can be reversed to solve a perceptual inconsistency, just reverse them. Reversing the order may be a solution to some problems and works easily when there are only two groups but such a simple fix may not work when there are three or more groups to label.\nguides(&lt;aesthetic&gt; = guide_legend(reverse = TRUE))\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(plot1, \n                           \n                           plot1 + labs(title = 'guides(col = guide_legend(reverse = TRUE))') + \n                             guides(col = guide_legend(reverse = TRUE)), \n                           ncol = 1\n                           )\n  )\n)\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nOverriding Key size in Legends\nIn most cases, you simply want to make the legend colors more visible for your users. Either you want to increase the size of points that are potentially too small or decrease the size of points that are just too large. Remember that aesthetic properties are inherited from data. Legend properties are inherited from the aesthetic mappings of their geoms. The legend properties may, however, benefit from modifications. When you want to change the legend properties manually, you can use the guide() function and specify arguments with helper functions guide_legend().\nWe will use guides() along with guide_legend() in order to override aesthetics. The general behavior will be to add a layer to a plot object like that shown below.\nNote: The goal of these examples is to illustrate how to change the key characteristics, not how to make everything match.\nguides(\n     &lt;aesthetic&gt; = guide_legend(\n                       override.aes = list(\n                            &lt;same or other aesthetic&gt; = numeric or string value\n                            )\n                   )\n      )\n\n\nDealing with a Constant Key Size\nWhen the legend provide a key that corresponds to an aesthetic other than size, changing the size of them does not compromise the plot integrity. We will take a single plot and adjust the size in four ways. Some points will be smaller than the default and some larger.\nWe will use guides() along with guide_legend() in order to override the size aesthetic using override.aes = list(size = numeric value). Please note that point size is visibly present in default plots but not controlled by any coding. Importantly, remember that all aesthetics that you see in the plot (and some you don’t see because they are invisible) are controlled in some manner, whether by you the creator or by the developers of {ggplot2}. In the default case, size is controlled but by the developers default choices.\nguides(col = guide_legend(override.aes = list(size = numeric value)))\n\nsuppressWarnings(\n  plot(\n    gridExtra::arrangeGrob(plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 1))',\n                                  tag = \"A\") +\n                             guides(col = guide_legend(override.aes = list(size = 1))), \n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 2))',\n                                  tag = \"B\") + \n                             guides(col = guide_legend(override.aes = list(size = 2))), \n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 3))',\n                                  tag = \"C\") + \n                             guides(col = guide_legend(override.aes = list(size = 3))),\n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 6))',\n                                  tag = \"A\") + \n                             guides(col = guide_legend(override.aes = list(size = 6))),\n                           ncol = 2)\n  )\n)\n\n\n\n\nWhich override do you like best? Which is most helpful for your client? Which legend strikes the best balance between the point points and the legend points?\nOf course, you really might wish to do something like reverse the legend labels as well by adding arguments.\n\nplot1 + \n  guides(col = guide_legend(override.aes = list(size = 3),\n                            reverse = TRUE\n                            )\n       ) +\n  labs(title = \"\", tag = \"\")\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nDealing with a Variable Key Size\nIf you do not like the size of the points and you are unsure what numeric value is associated with a shape, you can always control this yourself by adding a variable to the data frame and setting the scale_size_manual(). This way, you can adjust the legend size and ensure that the sizes in the legend correspond to the size in plot just as the default behavior works for a legend.\nHere we will mutate() a new variable using case_when() that specifies a numeric value to serve as the size of points for each Team. We will then override the size of the legend keys corresponding to the col aesthetic by passing a two-element vector containing the same values. In the event that we want to reuse these sizes (and prevent some errors), we will assign the values to a named vector that we will use in both places in the plot code.\n\nlegend_point_size &lt;- c(\"Men\" = 3, \"Women\" = 4.5)\n\nSWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) |&gt;\n  mutate(TeamSize = case_when(\n    Team == \"Men\" ~ legend_point_size[1],\n    Team == \"Women\" ~ legend_point_size[2],\n    )) |&gt;\n  ggplot(mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(col = Team, size = TeamSize)) +\n  labs(title = \"default\",\n       tag = \" --- \"\n       ) +\n  scale_size_identity() +\n  guides(col = guide_legend(override.aes = list(size = legend_point_size)))\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nYou could achieve the same plot by setting numeric values specifically as with the following:\nguides(col = guide_legend(override.aes = list(size = c(3, 4.5))))"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#overriding-other-aesthetics-of-legend-keys",
    "href": "modules/legends_and_arrangement.html#overriding-other-aesthetics-of-legend-keys",
    "title": "Legends and arrangement",
    "section": "Overriding other aesthetics of Legend Keys",
    "text": "Overriding other aesthetics of Legend Keys\nExamples:\nChange the shape, size, color, and alpha of the col aesthetic. Because there are two labels for the col aesthetic, we need to pass one value for a constant applied to all or a two-element vector if you wish for them to vary.\n\nbase_plot_3 +\n  guides(col  = guide_legend(override.aes = list(shape = 15,\n                                                 size = 4, \n                                                 col = c(\"firebrick\", \"goldenrod\"),\n                                                 alpha = .3\n                                                 ))\n        )\n\n\n\n\nChange the shape, size, color, fill, alpha, and stroke of the size aesthetic:\nBecause there are three labels for the size aesthetic, we need to pass three of each to vary.\n\nbase_plot_3 +\n  guides(size  = guide_legend(override.aes = list(shape = 22,\n                                                  size = c(2, 4, 6), \n                                                  col = c(\"cornflowerblue\", \n                                                          \"goldenrod\", \n                                                          \"firebrick\"\n                                                          ),\n                                                  fill = \"grey\",\n                                                  alpha = .6,\n                                                  stroke = 2\n                                                  ))\n        )"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#reordering-legend-labels",
    "href": "modules/legends_and_arrangement.html#reordering-legend-labels",
    "title": "Legends and arrangement",
    "section": "Reordering Legend Labels",
    "text": "Reordering Legend Labels\nLegend labels are presented in an order, whether from top to bottom or from left to right. We have discussed previously that legend labels are not always presented alphabetically. The order depends on the variable type. When variables are character vectors, they will be ordered alphabetically but if they are factors, they will be ordered based on their order, which will differ based on them being factors or ordered factors. Using unique(), we can see the unique levels.\n\nunique(SWIM$Team)\n\n[1] \"Mixed\" \"Women\" \"Men\"  \n\n\nThis is simply a character vector. When this type of Team variable is mapped to the aesthetic, the order of the labels in the legend do not map on to the spatial positioning of the data in the plot.\nMoreover, there are no levels to Team because character vectors don’t have level. Factors have levels so when we use alllevels() to examine the variables, we will see nothing is returned.\n\nlevels(SWIM$Team)\n\nNULL\n\n\nVectors that are factors will contain levels, so converting the vector will return its levels.\n\nlevels(factor(SWIM$Team))\n\n[1] \"Men\"   \"Mixed\" \"Women\"\n\n\nThe levels returned make the order parent: \"Men\", \"Mixed\", and \"Women\". When displayed in the legend, they will take on this order from top to bottom for the default legend orientation (e.g., \"right\"). This order will not address the the mismatch of the labels in the data. Including all three levels of the Team variable will make this mismatch more apparent. Such an arrangement will make cognitive processing of the visualization more challenging.\nHere is plot with three levels."
  },
  {
    "objectID": "modules/legends_and_arrangement.html#reordering-factor-levels-using-forcats",
    "href": "modules/legends_and_arrangement.html#reordering-factor-levels-using-forcats",
    "title": "Legends and arrangement",
    "section": "Reordering Factor Levels using {forcats}",
    "text": "Reordering Factor Levels using {forcats}\nOne of the easiest ways to ensure that the order to the legend labels matches that of the data presented in the plot when you are dealing with a categorical variable is to convert the vector to a factor and reorder it based on the data. The {forcats} library makes this task easy using two functions, using fct_reorder() and fct_reorder2().\nThe two functions will reorder a factor’s levels by sorting them based on another variable. The main difference between the two functions is that fct_reorder() will reorder based on a single dimension and is thus best for 1-dimensional displays whereas fct_reorder2() will reorder based on two dimensions and is best for 2-dimensional displays where the factor is mapped to a non-position aesthetic.\nIn order to see how the factor levels may be arranged based on the numeric variables for the scatter plot, we can use group_by() and summarize() the median, which is the default behavior of fct_reorder().\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  group_by(Team) |&gt;\n  summarize(Time = median(Time)) |&gt;\n  ungroup() |&gt;\n  arrange(Time)\n\n# A tibble: 3 × 2\n  Team   Time\n  &lt;chr&gt; &lt;dbl&gt;\n1 Mixed  93.5\n2 Men   105. \n3 Women 119. \n\n\nThe means from fastest to slowest are \"Mixed\", \"Men\", and \"Women\".\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  group_by(Team) |&gt;\n  summarize(Split50 = median(Split50)) |&gt;\n  ungroup() |&gt;\n  arrange(Split50)\n\n# A tibble: 3 × 2\n  Team  Split50\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Mixed    22.7\n2 Men      24.5\n3 Women    27.6\n\n\nThe means for the split time at 50 m from fastest to slowest is again \"Mixed\", \"Men\", and \"Women\". We need to ensure that our plot legend is from top to bottom \"Women\", \"Men\", and \"Mixed\" or from left to right \"Mixed\", \"Men\", and \"Women\".\n\nComparing Plots with fct_reorder() and fct_reorder2()\nYou can reorder the vector in the data frame before passing to ggplot() or within the aes() mapping in the object. However, if you have multiple variable-aesthetic mappings to that variable, your more efficient approach will be to change in the data frame.\nSome key features of both functions:\n.f: the factor .x: the variable for reordering with fct_reorder() .x and .y: the variable(s) for reordering with fct_reorder2()\n\nUsing forcats::fct_reorder():\nAdjust the grouping of Team by Split50.\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team, \n                                     .x = Split50\n                                     )\n         ) |&gt;\n  pull(Team)\n\n [1] Women Women Women Women Women Women Women Women Women Women Women Women\n[13] Women Women Women Women Women Women Women Women Men   Men   Men   Men  \n[25] Men   Men   Men   Men   Men   Men   Men   Men   Men   Men   Mixed Mixed\n[37] Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed\n[49] Mixed\nLevels: Mixed Men Women\n\n\nNotice this order is \"Mixed\", \"Men\", and then \"Women\".\n\n\nUsing forcats::fct_reorder2():\nAdjust the grouping of Team by Time and Split50.\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  mutate(Team = forcats::fct_reorder2(.f = Team, \n                                      .x = Time, \n                                      .y = Split50\n                                      )\n         ) |&gt;\n  pull(Team)\n\n [1] Women Women Women Women Women Women Women Women Women Women Women Women\n[13] Women Women Women Women Women Women Women Women Men   Men   Men   Men  \n[25] Men   Men   Men   Men   Men   Men   Men   Men   Men   Men   Mixed Mixed\n[37] Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed\n[49] Mixed\nLevels: Women Men Mixed\n\n\nNotice this order is \"Women\", \"Men\", and then \"Mixed\". This ordering may appear odd because the mixed group is faster than men but this is outcome results from the fact that the Distance variable that is not accounted for in the data filtering. For illustration purposes, with our plot we don’t care about that. Nevertheless, the horizontal order would be good if the legend was positioned along the top/bottom. The vertical order is problematic unless we reverse it.\n\n\n\nPlotting and Comparing Reordering using fct_reorder() and fct_reorder2()\nWe will specify .f = Team and .x as Split50 and when used, .y = Time.\n\nPlotting with a Reordering by forcats::fct_reorder2():\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder2(.f = Team, \n                                       .x = Split50, \n                                       .y = Time\n                                       )) |&gt; \n   ggplot(mapping = aes(x = Split50, \n                        y = Time,\n                        )\n          ) +\n   geom_point(mapping = aes(size = Time,\n                            shape = Team,\n                            fill = Team,\n                            col = Team\n                            ),\n              position = position_jitter(), \n              alpha = .7,\n              col = \"grey20\",\n              stroke = 1\n              ) +\n  scale_shape_manual(values = c(21, 22, 24)) +\n  guides(size = \"none\")\n\n\n\n\nWhen the legend is positioned to the right of the plot, the vertical positioning of the legend labels now matches the data.\nTo position the legend at the bottom of the plot, we get:\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder2(.f = Team, \n                                       .x = Split50, \n                                       .y = Time\n                                       )) |&gt; \n   ggplot(mapping = aes(x = Split50, \n                        y = Time,\n                        )\n          ) +\n   geom_point(mapping = aes(size = Time,\n                            shape = Team,\n                            fill = Team,\n                            col = Team\n                            ),\n              position = position_jitter(), \n              alpha = .7,\n              col = \"grey20\",\n              stroke = 1\n              ) +\n  scale_shape_manual(values = c(21, 22, 24)) +\n  guides(size = \"none\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\nWhen the legend is positioned at the bottom, the horizontal positioning of the legend labels does not match the data. You can also change the .x and .y variables if necessary.\n\n\n\nPlotting with a Reordering by forcats::fct_reorder():\nfct_reorder() will reorder Team only by a single variable. You could choose either Split50 or Time.\n\nBar plots\nWhen you have a bar plot, reordering the factor will help arrange the data from lowest to highest, thus making the data more easy to perceive. When dealing with variables plotting a continuous and a discrete variable, use fct_reorder().\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder(.f = Team, .x = Time)) |&gt; \n   ggplot(mapping = aes(x = Team, \n                        y = Time,\n                        )\n          ) +\n   geom_boxplot(mapping = aes(fill = Team))\n\n\n\n\nAlthough we have ordered the box plots, the legend is not in an order that matches the vertical ordering. If you want the legend labels oriented vertically, consider adjusting them using labels and breaks settings with scale_*_manual() functions. However, moving the legend to the bottom, top, or changing the direction to horizontal would suffice. You can also consider direct labeling of the plot.\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder(.f = Team, .x = Time)) |&gt; \n   ggplot(mapping = aes(x = Team, \n                        y = Time,\n                        )\n          ) +\n   geom_boxplot(mapping = aes(fill = Team)) +\n   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#reordering-the-labels-in-a-legend",
    "href": "modules/legends_and_arrangement.html#reordering-the-labels-in-a-legend",
    "title": "Legends and arrangement",
    "section": "Reordering the Labels in a Legend",
    "text": "Reordering the Labels in a Legend\nThis topics relates to creating perceptually-efficient data visualizations nevertheless we will address this topic. The legend information is supposed to support the data presented in a plot. Sometimes, however, the ordering of the labels in the legend compromises perceptual processing by the user.\nLet’s take another look at a plot. We will remove the size legend just to reduce confusion. Remember we can do this using guides(&lt;aesthetic&gt; = \"none\").\n\nbase_plot_3 + \n  guides(size = \"none\")\n\n\n\n\nIn this plot, the legend label order is opposite that of the data. Men are faster than Women so processing the fill and the shape aesthetics but the legend is arranged in the reversed order. There is no utility in ordering the labels in a way that increases the cognitive demand on the user. Not paying attention to such issues may result in your plots being less effective than is necessary. Although there are often desirable difficulties associated with increased cognitive effort, the trade off here is a misinterpretation of the plot.\nWhat can we do? Well, we already discussed changing the legend position by modifying legend.position. We can move the legend to the bottom (below the plot). By doing so, the left-right arrangement matches the location of the data along the x axis.\n\nbase_plot_3 + \n  guides(size = \"none\") +\n  theme(legend.position = \"bottom\") \n\n\n\n\nBut let’s say either we do not want to position a legend along the top or bottom or that doing so does not solve the problem. The more levels and labels there are, the more difficult this will be do achieve. We will need to rearrange the labels themselves.\n\nbase_plot_3 + \n  guides(size = \"none\") +\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#changing-legend-title-guides",
    "href": "modules/legends_and_arrangement.html#changing-legend-title-guides",
    "title": "Legends and arrangement",
    "section": "Changing Legend Title guides()",
    "text": "Changing Legend Title guides()\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(base_plot_3 + \n                             labs(title = 'default'),\n                           \n                           # fill only\n                           base_plot_3 + \n                             guides(fill = guide_legend(title = \"Teams\")) +\n                             labs(title = 'change fill only'),\n                           \n                           # fill, shape, col\n                           base_plot_3 + \n                             guides(fill = guide_legend(title = \"Teams\"),\n                                    shape = guide_legend(title = \"Teams\"),\n                                    col = guide_legend(title = \"Teams\"),\n                                    ) +\n                             labs(title = 'change col, fill, and shape'),\n                           \n                           ncol = 1\n    ))\n  )"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#changing-legend-title-position",
    "href": "modules/legends_and_arrangement.html#changing-legend-title-position",
    "title": "Legends and arrangement",
    "section": "Changing Legend Title Position",
    "text": "Changing Legend Title Position\nYou don’t need to change the title using labs(). Here, we change the title and title.position for the col aesthetic only within guide_legend(). Adding other aesthetic changes would be as simple as specifying them in guides().\n\nbase_plot_3 + guides(col = guide_legend(title = \"New Title\", \n                                        title.position = \"left\"\n                                       )\n                   )"
  },
  {
    "objectID": "modules/legends_and_arrangement.html#changing-legend-direction-and-label-position",
    "href": "modules/legends_and_arrangement.html#changing-legend-direction-and-label-position",
    "title": "Legends and arrangement",
    "section": "Changing Legend Direction and Label Position",
    "text": "Changing Legend Direction and Label Position\nHere, we also change the direction and label.position for the col, size, and shape in guides().\n\nplot3 + guides(\n  # color aesthetic  \n  col = guide_legend(title = \"Color Title\",\n                     direction = \"horizontal\",\n                     title.position = \"bottom\",\n                     label.position = \"top\"\n                     ),\n  # the size dimension\n  size = guide_legend(title = \"Size Title\",\n                      direction = \"vertical\",\n                      title.position = \"top\",\n                      label.position = \"top\"\n                      ),\n    # the shape aesthetic (does not appear because point all all the same shape) \n    shape = guide_legend(\"Shape Title\")\n ) + \n  theme(legend.position = \"bottom\")\n\nWarning: Using size for a discrete variable is not advised.\n\n\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWhether this outcome is appropriate is up for discussion. When you need to change such legend elements, however, the above examples will be helpful."
  },
  {
    "objectID": "modules/graphical_perception.html",
    "href": "modules/graphical_perception.html",
    "title": "Graphical perception",
    "section": "",
    "text": "In this module, we will address some aspects of how people perceive elements of data visualizations. We will briefly cover some concepts you may have been exposed to in a Cognitive Psychology or Perception course as they are applied to processing data visualizations. You will likely learn that you are not as accurate as you might have thought at extracting data from visual representations.\nAfter Project Management involving RStudio and Git, there is no coding for this this topic. Take a break, practice with Git, or review some details about the team project start considering what the team needs to do for the project."
  },
  {
    "objectID": "modules/graphical_perception.html#readings",
    "href": "modules/graphical_perception.html#readings",
    "title": "Graphical perception",
    "section": "Readings",
    "text": "Readings\n\nLooking at Data, from Data Visualization: A Practical Introduction. Healy, K. (2018)"
  },
  {
    "objectID": "modules/designing_perceptually_efficient_visualizations.html",
    "href": "modules/designing_perceptually_efficient_visualizations.html",
    "title": "Designing perceptually-efficient visualizations",
    "section": "",
    "text": "Creating visualizations is easy as long as you know a little about the tools available to you for creating them. Creating visualizations that are clear and not misleading is more challenging. One reason for this is that the cognitive processes by which humans perceive and understand visualizations involve those for which we are unaware (e.g., automatic cognitive processing). As a result, creating visualization that are easy to perceive, that are not attentionally demanding, that reduce confusion, that are not overly complex, that facilitate comparisons rather that compromise them, and so forth is more challenging. The latter involves an understanding of how people perceive and attend to elements of plots (e.g., aesthetics) and well as how the interpret, remember, and make-decisions about data visualizations. With this information, you create visualizations that are perceptually accessible and efficient. This module will introduce you to some of the literate in the area."
  },
  {
    "objectID": "modules/designing_perceptually_efficient_visualizations.html#reference-reservation-process",
    "href": "modules/designing_perceptually_efficient_visualizations.html#reference-reservation-process",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Reference Reservation Process",
    "text": "Reference Reservation Process\nIn order to make your reading selection, you will reserve a paper from the list by editing this shared file. Next to each reading, you will see parentheses (). You will decide on a paper to read and summarize according to some specific questions. Once you decide upon a paper, type your name inside the parentheses in order to reserve the reading. Selection is first-come, first-served; if two individuals from the same class have reserved a paper, it is no longer available for reading. Do not replace someone’s name. Do not delete any content.\nIf you wish to pair up with someone (in the same class or other class), read the paper together and submit your summary responses for others as a team, feel free to do so. Just ensure that you add both contributors names."
  },
  {
    "objectID": "modules/designing_perceptually_efficient_visualizations.html#paper-summary-task",
    "href": "modules/designing_perceptually_efficient_visualizations.html#paper-summary-task",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Paper Summary Task",
    "text": "Paper Summary Task\nThere is a Summary Template on Page 2 of the file and on Page 3 a section for Summary Entries. You should copy the content from the template and paste it into the document for entering your summary of the paper. Follow the prompts as listed below but feel free to provide other information that you believe is relevant for understanding the take-home message of the paper. In class, you will have some time to walk your peers through the piece of research so that they can understand it at a general level. The summary content will be available for all so that everyone can benefit from the reading of the collective group. Advice provided herein should be considered when deciding how your team creates visualizations for your project.\nItems to include in your summary\n\nYour Names(s)\nPaper Title\nWhat was the goal of the research?\nDescribe the general research methodology.\nWhat was the general finding or pattern of data (outcome variables ~ predictors)? If you did not make the variables and levels of variables clear in the previous item, do so here.\nIf there are multiple experiments, was a pattern consistent across experiments or did manipulations provide a nuanced view of cognitive processes?\nWhat explanation or theory was provided to account for the data? Keep in mind that an explanation for data does not simply mean the pattern of the data. Rather, the theory is offered to explain why the pattern might exist.\nWhat data visualization advice do you have for your peers based on this piece of research?\n\nNote: Feel free to include screen clippings of data or images if they help understand the methodology, manipulations, or data."
  },
  {
    "objectID": "modules/designing_perceptually_efficient_visualizations.html#reading-options",
    "href": "modules/designing_perceptually_efficient_visualizations.html#reading-options",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Reading Options",
    "text": "Reading Options\n\n\nBorkin et al. (2015). Beyond memorability: Visualization recognition and recall  \nMatlen, Genter, & Franceroni (2020). Spatial alignment facilitates visual comparison\nNothelfer et al. (2017). Redundant encoding strengthens segmentation and grouping in visual displays of data \nSarikaya & Gleicher (2018). Scatterplots: Tasks, Data, and Designs\nShah & Carpenter (1995). Conceptual limitations in comprehending line graphs \nXiong, Franconeri (2022). Visual arrangements of bar charts influence comparisons in viewer takeaways\nXiong, Franconeri et al. (2023). Seeing what you believe or believing what you see: Belief biases correlation estimation"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html",
    "href": "modules/data_frame_manipulation_and_wrangling.html",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "In this module, we will start manipulating data frames. Data frames are composed of column variables and row observations/cases and we will address how to perform operations on both. We will learn how to use {dplyr}, rather than base R to select, remove, add, and modify vectors in data frames. In addition, we will address how to filter and arrange rows in various ways. The focus will be on cleaning or wrangling data. Helper functions from libraries like {tidyr}, {stringr}, and {tidyselect} are also used in conjunction with {dplyr}.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\nData Transformation\nHuber: Transforming Data\n\n\n\n\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{stringr}: 1.5.1: for working with strings\n{tidyselect}: 1.2.1: for selecting sets from strings \n\n\n\n\nview_html(): for viewing data frames in HTML format, which I created as an alternative to View(). You can source() this from your /src/functions directory or download from here.\n\nTo define all functions in your /src/functions directory, R.utils::sourceDirectory() will be helpful:\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#readings-and-preparation",
    "href": "modules/data_frame_manipulation_and_wrangling.html#readings-and-preparation",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#supplementary-readings-optional",
    "href": "modules/data_frame_manipulation_and_wrangling.html#supplementary-readings-optional",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "Data Transformation\nHuber: Transforming Data"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#libraries",
    "href": "modules/data_frame_manipulation_and_wrangling.html#libraries",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{stringr}: 1.5.1: for working with strings\n{tidyselect}: 1.2.1: for selecting sets from strings"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#external-functions",
    "href": "modules/data_frame_manipulation_and_wrangling.html#external-functions",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "view_html(): for viewing data frames in HTML format, which I created as an alternative to View(). You can source() this from your /src/functions directory or download from here.\n\nTo define all functions in your /src/functions directory, R.utils::sourceDirectory() will be helpful:\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#selecting-variables-using-dplyrselect",
    "href": "modules/data_frame_manipulation_and_wrangling.html#selecting-variables-using-dplyrselect",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting Variables using dplyr::select()",
    "text": "Selecting Variables using dplyr::select()\nYou can reference variables by their names or by their column position in a data frame (e.g., 1, 25, etc.).\nUsing select(), you can select columns/variables from a data frame. The variables you select are retained and variables omitted that you don’t select are omitted in the returned data frame.\nBefore using a function you have never used before, you would always review the documentation for what the function is designed to accomplish.\nhelp(dplyr::select)\nOr:\n?dplyr::select\nYou can see that select() is used for selecting variables from a data frame and there are many selection features for accomplishing such tasks.\nParameters/Arguments:\n\n.data: a data frame\n...: one ore more expressions separated by commas\n\nWe will definitely need a data frame and we will need variables to select.\nLet’s start with a data frame. The USAressts data is built into R so let’s just use that for now. Let’s use select() to subset a data frame in two ways, first without piping and then with piping (preferred method).\n\nWithout piping\n\nAt a bare minimum, we will need to pass a data frame to select() at very least. But what happens if we don’t pass variables to select?\n\nselect(.data = USArrests)\n\ndata frame with 0 columns and 50 rows\n\n\nselect() is designed to take a data frame and select column variables from that data frame. If you do not specify what to select, you will see the that the returned data frame has 0 columns and 50 rows.\n\nPiping using |&gt;\n\nIf you pipe the data frame into the function, .data = USArrests is inherited and you do not need to declare it within select().\n\nUSArrests |&gt;\n  select()\n\ndata frame with 0 columns and 50 rows\n\n\nAgain, the returned data frame has 0 columns and 50 rows. If you use select() without specifying any variables for the function to select, as seen in both examples, you will have data frame that contains no columns. Let’s address some methods for selecting variables.\n\nSelecting Variables by Column Position\nVariables are columns in a data frame, so they can be selected by their element position . If you wanted to select the first and third column, one way is to specify each position separated by a comma.\n\nUSArrests |&gt;        # take the data frame\n  select(1, 3)      # select columns 1 and 3\n\n               Murder UrbanPop\nAlabama          13.2       58\nAlaska           10.0       48\nArizona           8.1       80\nArkansas          8.8       50\nCalifornia        9.0       91\nColorado          7.9       78\nConnecticut       3.3       77\nDelaware          5.9       72\nFlorida          15.4       80\nGeorgia          17.4       60\nHawaii            5.3       83\nIdaho             2.6       54\nIllinois         10.4       83\nIndiana           7.2       65\nIowa              2.2       57\nKansas            6.0       66\nKentucky          9.7       52\nLouisiana        15.4       66\nMaine             2.1       51\nMaryland         11.3       67\nMassachusetts     4.4       85\nMichigan         12.1       74\nMinnesota         2.7       66\nMississippi      16.1       44\nMissouri          9.0       70\nMontana           6.0       53\nNebraska          4.3       62\nNevada           12.2       81\nNew Hampshire     2.1       56\nNew Jersey        7.4       89\nNew Mexico       11.4       70\nNew York         11.1       86\nNorth Carolina   13.0       45\nNorth Dakota      0.8       44\nOhio              7.3       75\nOklahoma          6.6       68\nOregon            4.9       67\nPennsylvania      6.3       72\nRhode Island      3.4       87\nSouth Carolina   14.4       48\nSouth Dakota      3.8       45\nTennessee        13.2       59\nTexas            12.7       80\nUtah              3.2       80\nVermont           2.2       32\nVirginia          8.5       63\nWashington        4.0       73\nWest Virginia     5.7       39\nWisconsin         2.6       66\nWyoming           6.8       60\n\n\nLet’s remind ourselves of how piping works. Remember that piping will modify the data frame in steps, with each pipe passing the current form of the data frame to the next function. Not that you ever want to write two lines of code and perform this extra step to select only column 1 but you could pipe the data frame to another select().\n\nUSArrests |&gt;        # take the data frame\n  select(1, 3) |&gt;   # select columns 1 and 3\n  select(1)         # then select column 1 only\n\n               Murder\nAlabama          13.2\nAlaska           10.0\nArizona           8.1\nArkansas          8.8\nCalifornia        9.0\nColorado          7.9\nConnecticut       3.3\nDelaware          5.9\nFlorida          15.4\nGeorgia          17.4\nHawaii            5.3\nIdaho             2.6\nIllinois         10.4\nIndiana           7.2\nIowa              2.2\nKansas            6.0\nKentucky          9.7\nLouisiana        15.4\nMaine             2.1\nMaryland         11.3\nMassachusetts     4.4\nMichigan         12.1\nMinnesota         2.7\nMississippi      16.1\nMissouri          9.0\nMontana           6.0\nNebraska          4.3\nNevada           12.2\nNew Hampshire     2.1\nNew Jersey        7.4\nNew Mexico       11.4\nNew York         11.1\nNorth Carolina   13.0\nNorth Dakota      0.8\nOhio              7.3\nOklahoma          6.6\nOregon            4.9\nPennsylvania      6.3\nRhode Island      3.4\nSouth Carolina   14.4\nSouth Dakota      3.8\nTennessee        13.2\nTexas            12.7\nUtah              3.2\nVermont           2.2\nVirginia          8.5\nWashington        4.0\nWest Virginia     5.7\nWisconsin         2.6\nWyoming           6.8\n\n\nThe better approach is just to select column 1 in a single line.\n\nUSArrests |&gt;\n  select(1)\n\n               Murder\nAlabama          13.2\nAlaska           10.0\nArizona           8.1\nArkansas          8.8\nCalifornia        9.0\nColorado          7.9\nConnecticut       3.3\nDelaware          5.9\nFlorida          15.4\nGeorgia          17.4\nHawaii            5.3\nIdaho             2.6\nIllinois         10.4\nIndiana           7.2\nIowa              2.2\nKansas            6.0\nKentucky          9.7\nLouisiana        15.4\nMaine             2.1\nMaryland         11.3\nMassachusetts     4.4\nMichigan         12.1\nMinnesota         2.7\nMississippi      16.1\nMissouri          9.0\nMontana           6.0\nNebraska          4.3\nNevada           12.2\nNew Hampshire     2.1\nNew Jersey        7.4\nNew Mexico       11.4\nNew York         11.1\nNorth Carolina   13.0\nNorth Dakota      0.8\nOhio              7.3\nOklahoma          6.6\nOregon            4.9\nPennsylvania      6.3\nRhode Island      3.4\nSouth Carolina   14.4\nSouth Dakota      3.8\nTennessee        13.2\nTexas            12.7\nUtah              3.2\nVermont           2.2\nVirginia          8.5\nWashington        4.0\nWest Virginia     5.7\nWisconsin         2.6\nWyoming           6.8\n\n\n\n\nSelecting Variables by Column Name\nRather than position, you will likely wish to select by variable name. We will address several approaches for doing so. Each approach are beneficial in different contexts.\nIn order to know the names of the data frame, you can pass the data frame to the names() function, which will return the column names.\n\nUSArrests |&gt;\n  names()\n\n[1] \"Murder\"   \"Assault\"  \"UrbanPop\" \"Rape\"    \n\n\nOr pass the data frame to head() to see the names atop each colomn.\n\nUSArrests |&gt;\n  head()\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nThere are many ways to inspect variable names but those will suffice for now.\n\nSelecting Variables as Unquoted Expressions\nVariables can be passed separately without quotes. We can pass two arguments, one with Murder and the other with Assault, separating each with a comma. Because of some special characteristics of the {dplyr}, we can use variable names without quotes. Let’s also reduce the returned data frame using head() in order to save space.\n\nUSArrests |&gt; \n  select(Murder, Assault) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables as Characters/Strings\nYou are most likely familiar with variable names as quoted strings. We can pass two arguments here using the variable names in quotes. This approach is more similar to procedures used with base R functions as you cannot pass unquoted expressions in base R.\n\nUSArrests |&gt; \n  select(\"Murder\", \"Assault\") |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables as a Character Vector\nWhat if your variables were in a vector, c(\"Murder\", \"Assault\"))?\n\nUSArrests |&gt;\n  select(c(\"Murder\", \"Assault\")) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\nThe same will work if you passed a numeric vector c(1, 3).\n\n\nSelecting Using an External Vector Object\nIn many use cases, you will will have a vector of variable names that would will want to pass rather than type individually. This approach also reduces confusion when you have key variables that you want to work with. Create a vector using c() (to combine elements) once and then use again and again. If you make any changes, you will only have to make them once, rather than in multiple places.\nFirst, create the vector using c() that contains two string elements.\n\nc(\"Murder\", \"Assault\")\n\n[1] \"Murder\"  \"Assault\"\n\n\nAt this point, there is no object holding the vector. We can assign the vector to a name so that we have a vector object. Let’s name it keep_vars to represent variables in the data frame that we want to keep.\nAssign the vector to keep_vars using the assignment operator, &lt;-:\n\nkeep_vars &lt;- c(\"Murder\", \"Assault\")\n\nInspecting the keep_vars object by typing its name will return it. You can see that it contains 2 character/string elements.\n\nkeep_vars\n\n[1] \"Murder\"  \"Assault\"\n\n\nNow that we know what we are dealing with, pass the vector obect as as arugme to select():\n\nUSArrests |&gt;\n  select(keep_vars) \n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(keep_vars)\n\n  # Now:\n  data %&gt;% select(all_of(keep_vars))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n               Murder Assault\nAlabama          13.2     236\nAlaska           10.0     263\nArizona           8.1     294\nArkansas          8.8     190\nCalifornia        9.0     276\nColorado          7.9     204\nConnecticut       3.3     110\nDelaware          5.9     238\nFlorida          15.4     335\nGeorgia          17.4     211\nHawaii            5.3      46\nIdaho             2.6     120\nIllinois         10.4     249\nIndiana           7.2     113\nIowa              2.2      56\nKansas            6.0     115\nKentucky          9.7     109\nLouisiana        15.4     249\nMaine             2.1      83\nMaryland         11.3     300\nMassachusetts     4.4     149\nMichigan         12.1     255\nMinnesota         2.7      72\nMississippi      16.1     259\nMissouri          9.0     178\nMontana           6.0     109\nNebraska          4.3     102\nNevada           12.2     252\nNew Hampshire     2.1      57\nNew Jersey        7.4     159\nNew Mexico       11.4     285\nNew York         11.1     254\nNorth Carolina   13.0     337\nNorth Dakota      0.8      45\nOhio              7.3     120\nOklahoma          6.6     151\nOregon            4.9     159\nPennsylvania      6.3     106\nRhode Island      3.4     174\nSouth Carolina   14.4     279\nSouth Dakota      3.8      86\nTennessee        13.2     188\nTexas            12.7     201\nUtah              3.2     120\nVermont           2.2      48\nVirginia          8.5     156\nWashington        4.0     145\nWest Virginia     5.7      81\nWisconsin         2.6      53\nWyoming           6.8     161\n\n\nHmm. Warning message.\nNote: select(keep_vars) is deprecated as a solution, so if you see this approach someplace, it won’t work properly at this time or in the future. The warning message states that cannot do this without some modifications. What is suggested is all_of(). When your variables are in an external variable, all_of(keep_vars) will tell select() that your variables are all of the variables in the vector. Yes, this is an extra step but worth the flexibility.\n\nUSArrests |&gt;\n  select(all_of(keep_vars)) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\nUsing all_of() could be problematic if even one variable in your vector does not exist. Let’s add some variables that are not in the data frame and then pass that vector.\nkeep_vars_more &lt;- c(\"Murder\", \"Assault\", \"Var_x\", \"Var_y\", \"Var_z\")\n\nUSArrests |&gt;\n  select(all_of(keep_vars_more)) |&gt; \n  head()\nYou will see the following error message:\nError in `all_of()`:\n! Can't subset columns that don't exist.\n✖ Columns `Var_x`, `Var_y`, and `Var_z` don't exist.\nTip: Rather than using tidyselect::all_of(), use tidyselect::any_of(). In this instance, any of the variables that exist in the data frame will be selection. Those variables that are not in the data frame will be ignored. With this approach, your code will not break if there something changes.\n\nUSArrests |&gt;\n  select(any_of(keep_vars_more)) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables Starting with or Ending with Certain Characters\nWhen you load the {dplyr} library, there are functions from other libraries that are imported along with {dplyr}’s own functions. These important functions are designed to work with each other, so the people who maintain the libraries have packaged them up nicely so you don’t have to load separate libraries.\nMany of the functions are imported from the {tidyselect} library and these functions are what give you additional manipulation ability. Some imported functions are: all_of(), any_of(), contains(), ends_with(), everything(), last_col(), matches(), and starts_with().\nWith functions like starts_with(), contains(), and ends_with(), you can select variables containing character patterns in their names. For example, rather than code out all variables for a memory span task, you might want to grab variables that contain the characters \"span\".\nRather than hard coding variable names (e.g., \"measure_time1\", \"measure_time2\", c(\"Murder\", \"Assault\"), etc.) to pass as an argument to select(), you would use another function to help you perform the heaving lifting for you (e.g.,starts_with()). This is often referred to as a helper function. In the case of starts_with(), the variable names that starts_with() specific character patterns get passed to select(). This process represents a good example of what is referred to as functional programming. This usage represents a good example of working smarter, not harder. Rather than coding specifically what to pass as an argument to another function, you utilize another function to pass its returned object as an argument to another function.\n\n\nSelecting Variables Using starts_with()\n\nUnderstanding starts_with()\nWe first need to understand what dplyr::starts_with(), actually does. The function name should provide you some insight but for more information, use ?starts_with. You should always read the docs on functions so that you know how they work. You cannot brute force a function to do something it does not do. One thing to keep in mind is that starts_with() and many other functions operate on vectors and not data frames. Yes, data frames are comprised of vectors but you cannot apply many functions to the entire data frame without performing some iteration of the function for each vector in that data frame.\nstarts_with(match, \n            ignore.case = TRUE, \n            vars = NULL\n            )\nParameters/Arguments:\n\nmatch: a character vector\nignore.case: if TRUE, the default, ignores case when matching names. This is most flexible.\nvars: a character vector of variable names. If not supplied, the variables are taken from the current selection context (as established by functions like select() or pivot_longer()).\n\nThe best way to understand the function is to use it (after reading the documentation). Let’s try out starts_with(). Let’s set a required pattern match = some character and because vars = NULL by default, let’s just set vars = some character vector. If you reviewed the documentation or looked at the arguments above, vars is not the second parameter, so you will want to name it in the function call if it takes that second position as seen below. We will first test this function without using it on a data frame.\nWe set match = \"a\" and vars = c(\"Hello\", \"Hi\", \"Bye\"). This will look for character \"a\" to match the elements of a character vector c(\"Hello\", \"Hi\", \"Bye\").\n\nstarts_with(match = \"a\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\ninteger(0)\n\n\nWhat is returned is integer(0), which is actually speak for “there is no match”. Not very intuitive. Hmm, OK. Let’s try another character.\n\nstarts_with(match = \"b\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\n[1] 3\n\n\nOK, so now an integer is returned (yes, try is.integer() if you don’t believe me).\n\nis.integer(\n  starts_with(\"b\", \n              vars = c(\"Hello\", \"Hi\", \"Bye\")\n              ))\n\n[1] TRUE\n\n\nAnd even though you only see one value, this object is still a vector. We can check using is.vector().\n\nis.vector(\n  starts_with(\"b\", \n              vars = c(\"Hello\", \"Hi\", \"Bye\")\n              )\n  )\n\n[1] TRUE\n\n\nImportantly, starts_with() returns a vector of values. What do the values correspond to? The values in the vector refer to the element index/position of a match and the number of the elements in the vector tells refers to the number of matches found. Because the third string element \"Bye\" starts with \"b\", that’s what is returned.\nTry something else:\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\n[1] 1 2\n\n\nNow the function returns a vector containing 1 and a 2, giving length = 2, representing both the first and the second elements start with “h”.\nImportantly, letter casing is ignored because ignore.case = TRUE by default. Set to FALSE if you want your match to be case sensitive.\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\"), \n            ignore.case = FALSE\n            )\n\ninteger(0)\n\n\nAnd now there are no matches.\n\n\nSelecting Variables from a Data Frame using starts_with()\nYou will typically use starts_with() when working with a data frame and in conjunction with other functions, like select() in order to select variables that start with certain characters. When using starts_with() in the context of select(), the vars argument is essentially passing vars = the names of the columns of the data frame passed to select().\nFrom .data, select variable names that start with this pattern of characters.\nExample:\nselect(.data = mydataframe,\n       starts_with(match = \"my pattern\",\n                   vars = \"var names of mydataframe\"\n                   )\n      )\nLet’s provide two use cases:\n\nWithout Piping\n\nYou can pass the data frame as the first argument to select(). You can then pass that (now modified) data frame using a second |&gt; pipe to the head() in order to see the first 6 rows only.\n\nselect(.data = USArrests, \n       starts_with(\"m\")\n       ) |&gt; \n  head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nAs long as you remember that the first argument is the data frame, you can omit the parameter.\n\nselect(USArrests, \n       starts_with(\"m\")\n       ) |&gt; \n  head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nNotice that the only column variable that is returned is Murder.\n\nWith Piping\n\nA better approach, and one used more commonly, is to start with the data frame and then |&gt; it to your functions. Such an approach also makes code editing easier.\nPipe the data frame into select(), which assumes the first argument is a data frame. This is a process you will see used often by others.\n\nUSArrests |&gt;\n  select(starts_with(\"m\")) |&gt; \n  head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nWARNING: When piping data frames into functions, some students set a data frame within select() as shown below. This will either cause R to throw an error message or will lead to you working with incorrect data. This is especially true if you are specifying different data frames. Always remember that functions inherit what has been piped to them, either data frames or vectors.\nDo not do also set .data = USArrests:\nUSArrests |&gt;\n  select(.data = USArrests, \n         starts_with(\"m\")\n         ) |&gt; \n  head()\n\n\nSelecting Variables using ends_with()\nYou can use dplyr::ends_with() to find matches at the end of strings. This function is useful if you have variables that end based on their measurement type (e.g., “_rt” or “_acc” for reaction times and accuracy, respectively). Having the foresight to create variables is such a way to make accessing them easily later is a good example of working smarter, not harder.\n\nUSArrests |&gt;\n  select(ends_with(\"t\")) |&gt; \n  head()\n\n           Assault\nAlabama        236\nAlaska         263\nArizona        294\nArkansas       190\nCalifornia     276\nColorado       204\n\n\n\n\n\n\nSelecting and Selecting Out Variables By/Between Index\nSo far, we have address selecting variables. There are, however, many approaches for selecting but also selecting out or omitting column variables. In other words, rather than including 14 out of 15 variables, you could simply exclude 1 of the 15 variables to achieve the same result.\nYou can pass multiple arguments for each specification or you can pass a single vector that contains all specifications.\n\nselect(1, 2): select first and second columns\nselect(c(1, 2)): select first and second columns\nselect(-c(1, 2)) or select(!c(1, 2)): select out first and second columns\nselect(1:2): select first through second columns\nselect(c(1:2)): select first through second columns\nselect(-c(1:2)) or select(!c(1:2)): select out first through second columns\n\nPotential Recommendation: Use options utilizing c() to pass a vector because this habit will be more versatile with base R functionality. However, online solutions will likely not take this approach.\nLet’s first make a data frame to work with. We will name the data frame DAT even though this is a terrible name because it lacks diagnosticity for what the data represent. Using data.frame(), define variable names and for each assign a vector of elements of the same length. Some vectors are numeric and others are character/string as seen by the quotes. The are assigned to a name DAT using the &lt;- operator. Within the function, however, notice that you cannot assign vectors to variables using &lt;-. Inside functions, you use = for assignment or for passing arguments to their parameters.\n\nDAT &lt;- \n  data.frame(\n    Id  = c(100, 101, 102, 103, 104, 100, 105),\n    Sex = c('male', 'female', 'Male', NA, 'man', \"male\", \"neither\"),\n    Age = c(25, 33, 27, 40, 44, 25, 40),\n    Renting = c(\"yes\", NA, \"yes\", NA, \"no\", \"yes\", \"yes\")\n)\n\nSelect columns 1 and 2:\n\nDAT |&gt;\n  select(1, 2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT |&gt;\n  select(c(1, 2)) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect out columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT |&gt;\n  select(-c(1,2)) \n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nOr not these columns using !:\n\nDAT |&gt;\n  select(!c(1,2)) \n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect from columns 1 through 2 using the : operator:\n\nDAT |&gt;\n  select(1:2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect from columns 1 through 3 using a vector (notice the inclusion of c()) containing the : operator:\n\nDAT |&gt;\n  select(c(1:3)) \n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out columns 1 through 3 using !:\n\nDAT |&gt;\n  select(-c(1:3))   \n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\n\n\nSelecting and Selecting Out Variables By or Between Character Name\nThese approaches are similar to those offered earlier except that some involve passing variables by their name (e.g., character names). Whereas the order of the variables in a data frame may move around, the names may be more stable or permanent, at least after you have cleaned up the names. Consequently, passing variables by name may be more foolproof.\nYou don’t have to be familiar with all approaches and you may settle on using one that makes the most sense to you.\n\nselect(\"var1\", \"var2\")\nselect(c(\"var1\", \"var2\"))\nselect(-c(\"var1\", \"var2\"))\nselect(!c(\"var1\", \"var2\"))\nselect(var1:var2))\nselect(c(\"var1\":\"var2))\nselect(-c(\"var1\":\"var2))\nselect(!c(\"var1\":\"var2))\n\nRecommendation: use options utilizing c() as this will be more versatile with base R functionality.\nThese function approaches also work but they may lead to some confusion regarding usage of quotes:\n\nselect(var1, var2)\nselect(c(var1, var2))\nselect(-c(var1, var2))\nselect(!c(var1, var2))\n\nSelect variables Id though Age using the : operator:\n\nDAT |&gt;\n  select(Id:Age)          # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age passed as strings using the : operator:\n\nDAT |&gt;\n  select(\"Id\":\"Age\")      # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT |&gt;\n  select(c(\"Id\":\"Age\"))    # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out, or remove, variables Id though Age as a vector (e.g., c()) containing the variable names passed as strings and using the : operator:\n\nDAT |&gt;\n  select(-c(\"Id\":\"Age\"))     # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\nYou can also use the ! operator to select NOT these variables (therefore, all others)\n\nDAT |&gt;\n  select(!c(\"Id\":\"Age\"))                    # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\nSometimes you will use another function to help you select() variables from the data frame. This is the case when you want to select variables without specifying them by name or position but rather by some quality. For example, you want to select variables with similar names, patterns, in their names or select variables that are numeric only.\nWhen you use another function inside of another function, the function may be referred to as a helper function. In the following examples, we use starts_with(), ends_with(), and contains() as helpfer functions for select().\n\n\nSelecting and Selecting Out Variables Characters in Their Names\n\nselect(starts_with(\"some character or set of characters\"))\nselect(ends_with(\"some character or set of characters\"))\nselect(contains(\"some character or set of characters\"))\n\n\nSelecting using starts_with()\nSelect variables which start with character “i”:\n\nDAT |&gt; \n  select(starts_with(\"i\"))\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 100\n7 105\n\n\nSelect variables which DO NOT start with character “s”:\n\nDAT |&gt; \n  select(-starts_with(\"s\"))\n\n   Id Age Renting\n1 100  25     yes\n2 101  33    &lt;NA&gt;\n3 102  27     yes\n4 103  40    &lt;NA&gt;\n5 104  44      no\n6 100  25     yes\n7 105  40     yes\n\n\n\n\nSelecting using ends_with()\nSelect variables which end with character “e”:\n\nDAT |&gt; \n  select(ends_with(\"e\"))\n\n  Age\n1  25\n2  33\n3  27\n4  40\n5  44\n6  25\n7  40\n\n\nSelect variables which end with character “e”:\n\nDAT |&gt; \n  select(-ends_with(\"e\"))\n\n   Id     Sex Renting\n1 100    male     yes\n2 101  female    &lt;NA&gt;\n3 102    Male     yes\n4 103    &lt;NA&gt;    &lt;NA&gt;\n5 104     man      no\n6 100    male     yes\n7 105 neither     yes\n\n\n\n\nSelecting using contains()\nSelect variables which contain character “g”:\n\nDAT |&gt; \n  select(contains(\"g\"))\n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect variables which DO NOT contain character “g”:\n\nDAT |&gt; \n  select(-contains(\"g\"))\n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\n\n\nSelecting using regular expressions\nSometimes you do not want to search for specific character strings. Instead, you might want to look for strings that contain particular character patterns. For example, typing out var1, var2, var3 could be annoying. You might prefer just grabbing variables that match the pattern \"var\".\nWe will use some regular expressions, or regex, to help us. For the regex, you we will need to specify some code for finding patterns. For example, \\\\d{4} will search for patterns with 4 digits, whereas the dot star .* will help with all patterns. In particular, . refers to any character (e.g,. digit, alpha character, or any other special character) and * means zero or more times, so this pattern will search for all files that start with 4 digits followed by anything in the name. A pattern will restrict the search to files containing that exact character string. Some example will be helpful.\nA brief note on mutate().  In order to work through some examples using some regular expressions, we will add, or create, new variables in the data frame. The dplyr::mutate() function will be explained in detail later but for now just understand that it can be used to add variables. We will add 4 new variables which very similar names, which also contain different numbers of digits. Some digits will be at the end of the variable name and some digits will be contained someplace within the name. For simplicity, we will set all rows of the variable equal to the value of 1. Each variable will passed as an argument to mutate() and thus separated by a comma. When they are coded on separate lines, the are easier to see and remove. Focus on making code easy to read.\nDAT |&gt; \n  mutate(var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         )\n\nSelecting variables of all patterns using \".*\"\nSelect variables containing a regular expression, use matches():\n.* will grab all column variable names. As a regular expression, it translates to any character and any number of instances. Put quotes around it to make it a string.\n\nDAT |&gt; \n  select(matches(\".*\")) \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\n\n\nSelecting variables with digits using \"\\\\d\"\nAdd the new variables and |&gt; select. Use the regular expression \\\\d will grab all variables containing a digit. Put quotes around it so that it is a string:\n\nDAT |&gt;                 \n  mutate(var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) |&gt;\n  select(matches(\"\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\n\nSelecting variables that start and contain characters \"v.*\\\\d\"\nv.*\\\\d will grab all variables that start with v and then contain any characters which are followed by a digit:\n\nDAT |&gt;\n    mutate(var_1    = 1,\n           var_11   = 1,\n           var_3    = 1,\n           var1_var = 1\n         ) |&gt;\n  select(matches(\"v.*\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\n\nSelecting variables that end with a digit using \"\\\\d$\"\n\\\\d$ will grab all variables ending in a digit ($ means at the end):\n\nDAT |&gt; \n    mutate(var_1    = 1,\n           var_11   = 1,\n           var_3    = 1,\n           var1_var = 1\n           ) |&gt;\n  select(matches(\"\\\\d$\"))\n\n  var_1 var_11 var_3\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n7     1      1     1\n\n\n\n\n\nSelecting variables by negation\nYou can also negate all regular expression matches if you want to exclude variable names ending with digits:\n\nDAT |&gt;\n      mutate(var_1    = 1,\n             var_11   = 1,\n             var_3    = 1,\n             var1_var = 1\n             ) |&gt;\n  select(matches(\"\\\\d$\"))\n\n  var_1 var_11 var_3\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n7     1      1     1\n\n\nNote: The functions will return lowercase and uppercase variable name matches because the default behavior is ignore.case = TRUE. Set to FALSE if you want to perform precise surgery on the variables.\n\n\n\nSelecting and Selecting Out Variables by Type\nA very useful function for selecting variables by type is from the {tidyselect} library, tidyselect::where(). Examine how it works.\nhelp(where)\nIt has one main parameter, fn to which you pass another function. where() will return variables for which the function argument returns TRUE. Some common functions one might wish to pass as arguments to fn include is.numeric() for numeric columns, is.character() for character/string columns, or is.factor() for factor columns. For all of these, the is. part of the function informs you that the function is asking whether something is that type.\nFor example,\n\nis.numeric(c(1, 2, 3, 4))\n\n[1] TRUE\n\n\n\nis.numeric(c(\"1\", \"2\", \"3\", \"4\"))\n\n[1] FALSE\n\n\nThe complement to is.*() is as.*() which is used to convert vectors. Convert, then check.\n\nis.numeric(as.numeric(c(\"1\", \"2\", \"3\", \"4\")))\n\n[1] TRUE\n\n\nOne trickly part to using where() is that you cannot include the () for the function. Instead, we need to drop those off. Let’s try this with the data frame.\nSelect variables that are numeric:\n\nDAT |&gt;\n  select(where(is.numeric))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nNow, select() will return only the numeric columns.\nSelect variables that are NOT numeric:\n\nDAT |&gt; \n  select(-where(is.numeric))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are character:\n\nDAT |&gt; \n  select(where(is.character))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are NOT character:\n\nDAT |&gt;\n  select(-where(is.character))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are logical (TRUE to FALSE):\n\nDAT |&gt; \n  select(where(is.logical))\n\ndata frame with 0 columns and 7 rows\n\n\nSelect variables that are NOT logical (TRUE to FALSE):\n\nDAT |&gt; \n  select(-where(is.logical))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-constant-value",
    "href": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-constant-value",
    "title": "Data frame manipulation and wrangling",
    "section": "Creating/Mutating A Constant Value",
    "text": "Creating/Mutating A Constant Value\nLet’s create a new variable, new_var and set it equal to 1.\n\nUSArrests |&gt;\n  mutate(new_var1 = 1)\n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2        1\nAlaska           10.0     263       48 44.5        1\nArizona           8.1     294       80 31.0        1\nArkansas          8.8     190       50 19.5        1\nCalifornia        9.0     276       91 40.6        1\nColorado          7.9     204       78 38.7        1\nConnecticut       3.3     110       77 11.1        1\nDelaware          5.9     238       72 15.8        1\nFlorida          15.4     335       80 31.9        1\nGeorgia          17.4     211       60 25.8        1\nHawaii            5.3      46       83 20.2        1\nIdaho             2.6     120       54 14.2        1\nIllinois         10.4     249       83 24.0        1\nIndiana           7.2     113       65 21.0        1\nIowa              2.2      56       57 11.3        1\nKansas            6.0     115       66 18.0        1\nKentucky          9.7     109       52 16.3        1\nLouisiana        15.4     249       66 22.2        1\nMaine             2.1      83       51  7.8        1\nMaryland         11.3     300       67 27.8        1\nMassachusetts     4.4     149       85 16.3        1\nMichigan         12.1     255       74 35.1        1\nMinnesota         2.7      72       66 14.9        1\nMississippi      16.1     259       44 17.1        1\nMissouri          9.0     178       70 28.2        1\nMontana           6.0     109       53 16.4        1\nNebraska          4.3     102       62 16.5        1\nNevada           12.2     252       81 46.0        1\nNew Hampshire     2.1      57       56  9.5        1\nNew Jersey        7.4     159       89 18.8        1\nNew Mexico       11.4     285       70 32.1        1\nNew York         11.1     254       86 26.1        1\nNorth Carolina   13.0     337       45 16.1        1\nNorth Dakota      0.8      45       44  7.3        1\nOhio              7.3     120       75 21.4        1\nOklahoma          6.6     151       68 20.0        1\nOregon            4.9     159       67 29.3        1\nPennsylvania      6.3     106       72 14.9        1\nRhode Island      3.4     174       87  8.3        1\nSouth Carolina   14.4     279       48 22.5        1\nSouth Dakota      3.8      86       45 12.8        1\nTennessee        13.2     188       59 26.9        1\nTexas            12.7     201       80 25.5        1\nUtah              3.2     120       80 22.9        1\nVermont           2.2      48       32 11.2        1\nVirginia          8.5     156       63 20.7        1\nWashington        4.0     145       73 26.2        1\nWest Virginia     5.7      81       39  9.3        1\nWisconsin         2.6      53       66 10.8        1\nWyoming           6.8     161       60 15.6        1\n\n\nTo mutate more than one variable, you can add a new name-value pair as a new argument:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1,\n         new_var2 = 9999\n         )\n\n               Murder Assault UrbanPop Rape new_var1 new_var2\nAlabama          13.2     236       58 21.2        1     9999\nAlaska           10.0     263       48 44.5        1     9999\nArizona           8.1     294       80 31.0        1     9999\nArkansas          8.8     190       50 19.5        1     9999\nCalifornia        9.0     276       91 40.6        1     9999\nColorado          7.9     204       78 38.7        1     9999\nConnecticut       3.3     110       77 11.1        1     9999\nDelaware          5.9     238       72 15.8        1     9999\nFlorida          15.4     335       80 31.9        1     9999\nGeorgia          17.4     211       60 25.8        1     9999\nHawaii            5.3      46       83 20.2        1     9999\nIdaho             2.6     120       54 14.2        1     9999\nIllinois         10.4     249       83 24.0        1     9999\nIndiana           7.2     113       65 21.0        1     9999\nIowa              2.2      56       57 11.3        1     9999\nKansas            6.0     115       66 18.0        1     9999\nKentucky          9.7     109       52 16.3        1     9999\nLouisiana        15.4     249       66 22.2        1     9999\nMaine             2.1      83       51  7.8        1     9999\nMaryland         11.3     300       67 27.8        1     9999\nMassachusetts     4.4     149       85 16.3        1     9999\nMichigan         12.1     255       74 35.1        1     9999\nMinnesota         2.7      72       66 14.9        1     9999\nMississippi      16.1     259       44 17.1        1     9999\nMissouri          9.0     178       70 28.2        1     9999\nMontana           6.0     109       53 16.4        1     9999\nNebraska          4.3     102       62 16.5        1     9999\nNevada           12.2     252       81 46.0        1     9999\nNew Hampshire     2.1      57       56  9.5        1     9999\nNew Jersey        7.4     159       89 18.8        1     9999\nNew Mexico       11.4     285       70 32.1        1     9999\nNew York         11.1     254       86 26.1        1     9999\nNorth Carolina   13.0     337       45 16.1        1     9999\nNorth Dakota      0.8      45       44  7.3        1     9999\nOhio              7.3     120       75 21.4        1     9999\nOklahoma          6.6     151       68 20.0        1     9999\nOregon            4.9     159       67 29.3        1     9999\nPennsylvania      6.3     106       72 14.9        1     9999\nRhode Island      3.4     174       87  8.3        1     9999\nSouth Carolina   14.4     279       48 22.5        1     9999\nSouth Dakota      3.8      86       45 12.8        1     9999\nTennessee        13.2     188       59 26.9        1     9999\nTexas            12.7     201       80 25.5        1     9999\nUtah              3.2     120       80 22.9        1     9999\nVermont           2.2      48       32 11.2        1     9999\nVirginia          8.5     156       63 20.7        1     9999\nWashington        4.0     145       73 26.2        1     9999\nWest Virginia     5.7      81       39  9.3        1     9999\nWisconsin         2.6      53       66 10.8        1     9999\nWyoming           6.8     161       60 15.6        1     9999\n\n\nOr you can add a new mutate() by piping:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1) |&gt;  # add the variable \n  mutate(new_var1 = 9999)  # then add another variable \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999\n\n\nWhatever your approach, keep the variable creation on separate lines. Don’t put both variable specification on the same line just to same space as seen here:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1, new_var1 = 9999)   \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999\n\n\nAlthough there is nothing technically incorrect with doing so, (1) this is harder to read, (2) the R community won’t like it, and importantly (3) it is less flexible when you want to temporarily comment out a line of your code as seen here.\n\nUSArrests |&gt;\n#  mutate(new_var1 = 1) |&gt;  # add the variable \n  mutate(new_var1 = 9999)  # then add another variable \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999\n\n\nSame for:\n\nUSArrests |&gt;\n  mutate(#new_var1 = 1,\n         new_var2 = 9999\n         )\n\n               Murder Assault UrbanPop Rape new_var2\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-constant-character",
    "href": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-constant-character",
    "title": "Data frame manipulation and wrangling",
    "section": "Creating/Mutating A Constant Character",
    "text": "Creating/Mutating A Constant Character\n\nUSArrests |&gt;\n  mutate(new_var1 = \"Below Average\",\n         )\n\n               Murder Assault UrbanPop Rape      new_var1\nAlabama          13.2     236       58 21.2 Below Average\nAlaska           10.0     263       48 44.5 Below Average\nArizona           8.1     294       80 31.0 Below Average\nArkansas          8.8     190       50 19.5 Below Average\nCalifornia        9.0     276       91 40.6 Below Average\nColorado          7.9     204       78 38.7 Below Average\nConnecticut       3.3     110       77 11.1 Below Average\nDelaware          5.9     238       72 15.8 Below Average\nFlorida          15.4     335       80 31.9 Below Average\nGeorgia          17.4     211       60 25.8 Below Average\nHawaii            5.3      46       83 20.2 Below Average\nIdaho             2.6     120       54 14.2 Below Average\nIllinois         10.4     249       83 24.0 Below Average\nIndiana           7.2     113       65 21.0 Below Average\nIowa              2.2      56       57 11.3 Below Average\nKansas            6.0     115       66 18.0 Below Average\nKentucky          9.7     109       52 16.3 Below Average\nLouisiana        15.4     249       66 22.2 Below Average\nMaine             2.1      83       51  7.8 Below Average\nMaryland         11.3     300       67 27.8 Below Average\nMassachusetts     4.4     149       85 16.3 Below Average\nMichigan         12.1     255       74 35.1 Below Average\nMinnesota         2.7      72       66 14.9 Below Average\nMississippi      16.1     259       44 17.1 Below Average\nMissouri          9.0     178       70 28.2 Below Average\nMontana           6.0     109       53 16.4 Below Average\nNebraska          4.3     102       62 16.5 Below Average\nNevada           12.2     252       81 46.0 Below Average\nNew Hampshire     2.1      57       56  9.5 Below Average\nNew Jersey        7.4     159       89 18.8 Below Average\nNew Mexico       11.4     285       70 32.1 Below Average\nNew York         11.1     254       86 26.1 Below Average\nNorth Carolina   13.0     337       45 16.1 Below Average\nNorth Dakota      0.8      45       44  7.3 Below Average\nOhio              7.3     120       75 21.4 Below Average\nOklahoma          6.6     151       68 20.0 Below Average\nOregon            4.9     159       67 29.3 Below Average\nPennsylvania      6.3     106       72 14.9 Below Average\nRhode Island      3.4     174       87  8.3 Below Average\nSouth Carolina   14.4     279       48 22.5 Below Average\nSouth Dakota      3.8      86       45 12.8 Below Average\nTennessee        13.2     188       59 26.9 Below Average\nTexas            12.7     201       80 25.5 Below Average\nUtah              3.2     120       80 22.9 Below Average\nVermont           2.2      48       32 11.2 Below Average\nVirginia          8.5     156       63 20.7 Below Average\nWashington        4.0     145       73 26.2 Below Average\nWest Virginia     5.7      81       39  9.3 Below Average\nWisconsin         2.6      53       66 10.8 Below Average\nWyoming           6.8     161       60 15.6 Below Average"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-logical-object",
    "href": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-a-logical-object",
    "title": "Data frame manipulation and wrangling",
    "section": "Creating/Mutating A Logical Object",
    "text": "Creating/Mutating A Logical Object\nLogical objects are TRUE or FALSE. We can perform the logical test by asking whether Assault &gt; Murder. If the Assault value for a row is greater than the Murder value, TRUE will be returned, otherwise FALSE.\n\nUSArrests |&gt;\n  mutate(new_var = Assault &gt; Murder)\n\n               Murder Assault UrbanPop Rape new_var\nAlabama          13.2     236       58 21.2    TRUE\nAlaska           10.0     263       48 44.5    TRUE\nArizona           8.1     294       80 31.0    TRUE\nArkansas          8.8     190       50 19.5    TRUE\nCalifornia        9.0     276       91 40.6    TRUE\nColorado          7.9     204       78 38.7    TRUE\nConnecticut       3.3     110       77 11.1    TRUE\nDelaware          5.9     238       72 15.8    TRUE\nFlorida          15.4     335       80 31.9    TRUE\nGeorgia          17.4     211       60 25.8    TRUE\nHawaii            5.3      46       83 20.2    TRUE\nIdaho             2.6     120       54 14.2    TRUE\nIllinois         10.4     249       83 24.0    TRUE\nIndiana           7.2     113       65 21.0    TRUE\nIowa              2.2      56       57 11.3    TRUE\nKansas            6.0     115       66 18.0    TRUE\nKentucky          9.7     109       52 16.3    TRUE\nLouisiana        15.4     249       66 22.2    TRUE\nMaine             2.1      83       51  7.8    TRUE\nMaryland         11.3     300       67 27.8    TRUE\nMassachusetts     4.4     149       85 16.3    TRUE\nMichigan         12.1     255       74 35.1    TRUE\nMinnesota         2.7      72       66 14.9    TRUE\nMississippi      16.1     259       44 17.1    TRUE\nMissouri          9.0     178       70 28.2    TRUE\nMontana           6.0     109       53 16.4    TRUE\nNebraska          4.3     102       62 16.5    TRUE\nNevada           12.2     252       81 46.0    TRUE\nNew Hampshire     2.1      57       56  9.5    TRUE\nNew Jersey        7.4     159       89 18.8    TRUE\nNew Mexico       11.4     285       70 32.1    TRUE\nNew York         11.1     254       86 26.1    TRUE\nNorth Carolina   13.0     337       45 16.1    TRUE\nNorth Dakota      0.8      45       44  7.3    TRUE\nOhio              7.3     120       75 21.4    TRUE\nOklahoma          6.6     151       68 20.0    TRUE\nOregon            4.9     159       67 29.3    TRUE\nPennsylvania      6.3     106       72 14.9    TRUE\nRhode Island      3.4     174       87  8.3    TRUE\nSouth Carolina   14.4     279       48 22.5    TRUE\nSouth Dakota      3.8      86       45 12.8    TRUE\nTennessee        13.2     188       59 26.9    TRUE\nTexas            12.7     201       80 25.5    TRUE\nUtah              3.2     120       80 22.9    TRUE\nVermont           2.2      48       32 11.2    TRUE\nVirginia          8.5     156       63 20.7    TRUE\nWashington        4.0     145       73 26.2    TRUE\nWest Virginia     5.7      81       39  9.3    TRUE\nWisconsin         2.6      53       66 10.8    TRUE\nWyoming           6.8     161       60 15.6    TRUE\n\n\nWe see that all states (rows) have more assaults than murders. No surprise."
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-based-on-function",
    "href": "modules/data_frame_manipulation_and_wrangling.html#creatingmutating-based-on-function",
    "title": "Data frame manipulation and wrangling",
    "section": "Creating/Mutating Based on Function",
    "text": "Creating/Mutating Based on Function\nHere, the name value pair will contain a function. For example, let’s create a variable based on the mean() of a variable.\n\nUSArrests |&gt;\n  mutate(Mean_Assault = mean(Assault))\n\n               Murder Assault UrbanPop Rape Mean_Assault\nAlabama          13.2     236       58 21.2       170.76\nAlaska           10.0     263       48 44.5       170.76\nArizona           8.1     294       80 31.0       170.76\nArkansas          8.8     190       50 19.5       170.76\nCalifornia        9.0     276       91 40.6       170.76\nColorado          7.9     204       78 38.7       170.76\nConnecticut       3.3     110       77 11.1       170.76\nDelaware          5.9     238       72 15.8       170.76\nFlorida          15.4     335       80 31.9       170.76\nGeorgia          17.4     211       60 25.8       170.76\nHawaii            5.3      46       83 20.2       170.76\nIdaho             2.6     120       54 14.2       170.76\nIllinois         10.4     249       83 24.0       170.76\nIndiana           7.2     113       65 21.0       170.76\nIowa              2.2      56       57 11.3       170.76\nKansas            6.0     115       66 18.0       170.76\nKentucky          9.7     109       52 16.3       170.76\nLouisiana        15.4     249       66 22.2       170.76\nMaine             2.1      83       51  7.8       170.76\nMaryland         11.3     300       67 27.8       170.76\nMassachusetts     4.4     149       85 16.3       170.76\nMichigan         12.1     255       74 35.1       170.76\nMinnesota         2.7      72       66 14.9       170.76\nMississippi      16.1     259       44 17.1       170.76\nMissouri          9.0     178       70 28.2       170.76\nMontana           6.0     109       53 16.4       170.76\nNebraska          4.3     102       62 16.5       170.76\nNevada           12.2     252       81 46.0       170.76\nNew Hampshire     2.1      57       56  9.5       170.76\nNew Jersey        7.4     159       89 18.8       170.76\nNew Mexico       11.4     285       70 32.1       170.76\nNew York         11.1     254       86 26.1       170.76\nNorth Carolina   13.0     337       45 16.1       170.76\nNorth Dakota      0.8      45       44  7.3       170.76\nOhio              7.3     120       75 21.4       170.76\nOklahoma          6.6     151       68 20.0       170.76\nOregon            4.9     159       67 29.3       170.76\nPennsylvania      6.3     106       72 14.9       170.76\nRhode Island      3.4     174       87  8.3       170.76\nSouth Carolina   14.4     279       48 22.5       170.76\nSouth Dakota      3.8      86       45 12.8       170.76\nTennessee        13.2     188       59 26.9       170.76\nTexas            12.7     201       80 25.5       170.76\nUtah              3.2     120       80 22.9       170.76\nVermont           2.2      48       32 11.2       170.76\nVirginia          8.5     156       63 20.7       170.76\nWashington        4.0     145       73 26.2       170.76\nWest Virginia     5.7      81       39  9.3       170.76\nWisconsin         2.6      53       66 10.8       170.76\nWyoming           6.8     161       60 15.6       170.76\n\n\nNotice that the new column contains the mean for all rows.\nWe may also wish to categorize rows based on their relative Assault data. How about assault lower than the mean assault?\n\nUSArrests |&gt;\n  mutate(Lower_than_Mean_Assault = Assault &lt; mean(Assault))\n\n               Murder Assault UrbanPop Rape Lower_than_Mean_Assault\nAlabama          13.2     236       58 21.2                   FALSE\nAlaska           10.0     263       48 44.5                   FALSE\nArizona           8.1     294       80 31.0                   FALSE\nArkansas          8.8     190       50 19.5                   FALSE\nCalifornia        9.0     276       91 40.6                   FALSE\nColorado          7.9     204       78 38.7                   FALSE\nConnecticut       3.3     110       77 11.1                    TRUE\nDelaware          5.9     238       72 15.8                   FALSE\nFlorida          15.4     335       80 31.9                   FALSE\nGeorgia          17.4     211       60 25.8                   FALSE\nHawaii            5.3      46       83 20.2                    TRUE\nIdaho             2.6     120       54 14.2                    TRUE\nIllinois         10.4     249       83 24.0                   FALSE\nIndiana           7.2     113       65 21.0                    TRUE\nIowa              2.2      56       57 11.3                    TRUE\nKansas            6.0     115       66 18.0                    TRUE\nKentucky          9.7     109       52 16.3                    TRUE\nLouisiana        15.4     249       66 22.2                   FALSE\nMaine             2.1      83       51  7.8                    TRUE\nMaryland         11.3     300       67 27.8                   FALSE\nMassachusetts     4.4     149       85 16.3                    TRUE\nMichigan         12.1     255       74 35.1                   FALSE\nMinnesota         2.7      72       66 14.9                    TRUE\nMississippi      16.1     259       44 17.1                   FALSE\nMissouri          9.0     178       70 28.2                   FALSE\nMontana           6.0     109       53 16.4                    TRUE\nNebraska          4.3     102       62 16.5                    TRUE\nNevada           12.2     252       81 46.0                   FALSE\nNew Hampshire     2.1      57       56  9.5                    TRUE\nNew Jersey        7.4     159       89 18.8                    TRUE\nNew Mexico       11.4     285       70 32.1                   FALSE\nNew York         11.1     254       86 26.1                   FALSE\nNorth Carolina   13.0     337       45 16.1                   FALSE\nNorth Dakota      0.8      45       44  7.3                    TRUE\nOhio              7.3     120       75 21.4                    TRUE\nOklahoma          6.6     151       68 20.0                    TRUE\nOregon            4.9     159       67 29.3                    TRUE\nPennsylvania      6.3     106       72 14.9                    TRUE\nRhode Island      3.4     174       87  8.3                   FALSE\nSouth Carolina   14.4     279       48 22.5                   FALSE\nSouth Dakota      3.8      86       45 12.8                    TRUE\nTennessee        13.2     188       59 26.9                   FALSE\nTexas            12.7     201       80 25.5                   FALSE\nUtah              3.2     120       80 22.9                    TRUE\nVermont           2.2      48       32 11.2                    TRUE\nVirginia          8.5     156       63 20.7                    TRUE\nWashington        4.0     145       73 26.2                    TRUE\nWest Virginia     5.7      81       39  9.3                    TRUE\nWisconsin         2.6      53       66 10.8                    TRUE\nWyoming           6.8     161       60 15.6                    TRUE\n\n\nTRUE and False make terrible variable levels, however. Using ifelse(), we will specify conditions for categorization. For example, make rows that are below the mean take on a value, else/otherwise, make the rows a different value.\nExample:\nifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\"))\nIf the Assault value is &lt; Mean_Assault, assign the row a value of \"Below\", else, assign \"Equal or Above\". Let’s use ifelse() to create a name-value pair\nRelative_Assult = ifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\"))\n\nUSArrests |&gt;\n  mutate(Mean_Assault = mean(Assault), \n         Relative_Assult = ifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\")\n         )\n\n               Murder Assault UrbanPop Rape Mean_Assault Relative_Assult\nAlabama          13.2     236       58 21.2       170.76  Equal or Above\nAlaska           10.0     263       48 44.5       170.76  Equal or Above\nArizona           8.1     294       80 31.0       170.76  Equal or Above\nArkansas          8.8     190       50 19.5       170.76  Equal or Above\nCalifornia        9.0     276       91 40.6       170.76  Equal or Above\nColorado          7.9     204       78 38.7       170.76  Equal or Above\nConnecticut       3.3     110       77 11.1       170.76           Below\nDelaware          5.9     238       72 15.8       170.76  Equal or Above\nFlorida          15.4     335       80 31.9       170.76  Equal or Above\nGeorgia          17.4     211       60 25.8       170.76  Equal or Above\nHawaii            5.3      46       83 20.2       170.76           Below\nIdaho             2.6     120       54 14.2       170.76           Below\nIllinois         10.4     249       83 24.0       170.76  Equal or Above\nIndiana           7.2     113       65 21.0       170.76           Below\nIowa              2.2      56       57 11.3       170.76           Below\nKansas            6.0     115       66 18.0       170.76           Below\nKentucky          9.7     109       52 16.3       170.76           Below\nLouisiana        15.4     249       66 22.2       170.76  Equal or Above\nMaine             2.1      83       51  7.8       170.76           Below\nMaryland         11.3     300       67 27.8       170.76  Equal or Above\nMassachusetts     4.4     149       85 16.3       170.76           Below\nMichigan         12.1     255       74 35.1       170.76  Equal or Above\nMinnesota         2.7      72       66 14.9       170.76           Below\nMississippi      16.1     259       44 17.1       170.76  Equal or Above\nMissouri          9.0     178       70 28.2       170.76  Equal or Above\nMontana           6.0     109       53 16.4       170.76           Below\nNebraska          4.3     102       62 16.5       170.76           Below\nNevada           12.2     252       81 46.0       170.76  Equal or Above\nNew Hampshire     2.1      57       56  9.5       170.76           Below\nNew Jersey        7.4     159       89 18.8       170.76           Below\nNew Mexico       11.4     285       70 32.1       170.76  Equal or Above\nNew York         11.1     254       86 26.1       170.76  Equal or Above\nNorth Carolina   13.0     337       45 16.1       170.76  Equal or Above\nNorth Dakota      0.8      45       44  7.3       170.76           Below\nOhio              7.3     120       75 21.4       170.76           Below\nOklahoma          6.6     151       68 20.0       170.76           Below\nOregon            4.9     159       67 29.3       170.76           Below\nPennsylvania      6.3     106       72 14.9       170.76           Below\nRhode Island      3.4     174       87  8.3       170.76  Equal or Above\nSouth Carolina   14.4     279       48 22.5       170.76  Equal or Above\nSouth Dakota      3.8      86       45 12.8       170.76           Below\nTennessee        13.2     188       59 26.9       170.76  Equal or Above\nTexas            12.7     201       80 25.5       170.76  Equal or Above\nUtah              3.2     120       80 22.9       170.76           Below\nVermont           2.2      48       32 11.2       170.76           Below\nVirginia          8.5     156       63 20.7       170.76           Below\nWashington        4.0     145       73 26.2       170.76           Below\nWest Virginia     5.7      81       39  9.3       170.76           Below\nWisconsin         2.6      53       66 10.8       170.76           Below\nWyoming           6.8     161       60 15.6       170.76           Below\n\n\nBu you could also combine the steps together:\n\nUSArrests |&gt;\n  mutate(Relative_Assult = ifelse(Assault &lt; mean(Assault), \"Below\", \"Equal or Above\"))\n\n               Murder Assault UrbanPop Rape Relative_Assult\nAlabama          13.2     236       58 21.2  Equal or Above\nAlaska           10.0     263       48 44.5  Equal or Above\nArizona           8.1     294       80 31.0  Equal or Above\nArkansas          8.8     190       50 19.5  Equal or Above\nCalifornia        9.0     276       91 40.6  Equal or Above\nColorado          7.9     204       78 38.7  Equal or Above\nConnecticut       3.3     110       77 11.1           Below\nDelaware          5.9     238       72 15.8  Equal or Above\nFlorida          15.4     335       80 31.9  Equal or Above\nGeorgia          17.4     211       60 25.8  Equal or Above\nHawaii            5.3      46       83 20.2           Below\nIdaho             2.6     120       54 14.2           Below\nIllinois         10.4     249       83 24.0  Equal or Above\nIndiana           7.2     113       65 21.0           Below\nIowa              2.2      56       57 11.3           Below\nKansas            6.0     115       66 18.0           Below\nKentucky          9.7     109       52 16.3           Below\nLouisiana        15.4     249       66 22.2  Equal or Above\nMaine             2.1      83       51  7.8           Below\nMaryland         11.3     300       67 27.8  Equal or Above\nMassachusetts     4.4     149       85 16.3           Below\nMichigan         12.1     255       74 35.1  Equal or Above\nMinnesota         2.7      72       66 14.9           Below\nMississippi      16.1     259       44 17.1  Equal or Above\nMissouri          9.0     178       70 28.2  Equal or Above\nMontana           6.0     109       53 16.4           Below\nNebraska          4.3     102       62 16.5           Below\nNevada           12.2     252       81 46.0  Equal or Above\nNew Hampshire     2.1      57       56  9.5           Below\nNew Jersey        7.4     159       89 18.8           Below\nNew Mexico       11.4     285       70 32.1  Equal or Above\nNew York         11.1     254       86 26.1  Equal or Above\nNorth Carolina   13.0     337       45 16.1  Equal or Above\nNorth Dakota      0.8      45       44  7.3           Below\nOhio              7.3     120       75 21.4           Below\nOklahoma          6.6     151       68 20.0           Below\nOregon            4.9     159       67 29.3           Below\nPennsylvania      6.3     106       72 14.9           Below\nRhode Island      3.4     174       87  8.3  Equal or Above\nSouth Carolina   14.4     279       48 22.5  Equal or Above\nSouth Dakota      3.8      86       45 12.8           Below\nTennessee        13.2     188       59 26.9  Equal or Above\nTexas            12.7     201       80 25.5  Equal or Above\nUtah              3.2     120       80 22.9           Below\nVermont           2.2      48       32 11.2           Below\nVirginia          8.5     156       63 20.7           Below\nWashington        4.0     145       73 26.2           Below\nWest Virginia     5.7      81       39  9.3           Below\nWisconsin         2.6      53       66 10.8           Below\nWyoming           6.8     161       60 15.6           Below"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#understanding-filtering-operators",
    "href": "modules/data_frame_manipulation_and_wrangling.html#understanding-filtering-operators",
    "title": "Data frame manipulation and wrangling",
    "section": "Understanding Filtering Operators",
    "text": "Understanding Filtering Operators\nWe will filter data using filter() from {dplyr}\nfilter(.data, \n       ...\n       )\nParameters/Arguments:\n\n.data: a data frame\n...: expressions that return a logical value (TRUE or FALSE)\n\nNOTE:: Filtering cases using the filter() verbs works by removing rows that do not match a specific criterion and then by returning the data frame that omits the mismatched condition. It keeps only rows that are TRUE (match) your specification.\nSome useful filtering operators and functions include: ==, &gt;, &gt;=, &, |, !, xor(), c(), is.na(), between(), near()."
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filtering-using-filter",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filtering-using-filter",
    "title": "Data frame manipulation and wrangling",
    "section": "Filtering Using filter()",
    "text": "Filtering Using filter()\nWe will work with different data frames because the the nature of their contents.\nWhat does the data frame look like again?\n\nDAT    # or print(DAT)\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\nRow/Observations/Cases can be filtered to “include” only certain matched conditions or can be filtered to “exclude” by negating those matched conditions. If the column variable Sex is in the data frame and cases are 'male', 'men', 'female', 'women', 'neither', NA, etc., you can specify the column Sex variable and then the row matching condition(s).\n\nFiltering Matches to a Specific Character Value\nThe first argument in filter() is a data frame, and the function all filter(DAT, Sex == 'female') will filter the data frame named DAT to include rows for which the sex column equals 'female'. In other words, TRUE rows.\n\nfilter(DAT, \n       Sex == 'female'\n       )\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nSimilarly, the function call filter(DAT, Sex == 'male') can be read “filter the data frame to include rows for which the value of Sex == 'male' is TRUE”.\nMore flexibly, however, you could specify a vector containing acceptable strings using c(). filter(Sex %in% c('male')) filters the rows to include only those for which the value for sex is in the string vector which includes a single string,'male' whereas filter(Sex %in% c('male', 'Man')) filters the rows to include only those for which the value for Sex is in the string vector which includes 'male' and 'Man'. Cases containing 'Male', 'Men' (R is a case-sensitive language), or 'female', for example, will not be included in the returned data frame because they do not match values in the string vector.\n\n\nFiltering by a Relative Value\nLet’s |&gt; the data frame to filter():\n\nUSArrests |&gt;\n  filter(Murder &gt; 10)\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\n\n\nThe rows with Murder above 10 will be retained (they are TRUE), others removed (they are FALSE).\n\n\nFiltering by a Specific Value\nTo filter() by a specific value rather than a relative value, you will need to perform a test of equality using the == operator.\nFor some quick examples:\n\n\"Hello\" == \"Hello\"\n\n[1] TRUE\n\n\n\n\"Hello\" == \"hello\"\n\n[1] FALSE\n\n\nBecause filter() operates on rows of data frames, the test of equality to a value is performed on each row. When the test is TRUE, that row will be retained.\nGet rows for which Murder == 12.1:\n\nUSArrests |&gt;\n  filter(Murder == 12.1)\n\n         Murder Assault UrbanPop Rape\nMichigan   12.1     255       74 35.1\n\n\nUsing a previous example with this data set, we can filter based on a character variable if we had one. Let’s add one.\n\nUSArrests |&gt;\n  mutate(Relative_Murder = ifelse(Murder &lt; mean(Murder), \"Below\", \"Equal or Above\")) |&gt;\n  filter(Relative_Murder == \"Below\")\n\n              Murder Assault UrbanPop Rape Relative_Murder\nConnecticut      3.3     110       77 11.1           Below\nDelaware         5.9     238       72 15.8           Below\nHawaii           5.3      46       83 20.2           Below\nIdaho            2.6     120       54 14.2           Below\nIndiana          7.2     113       65 21.0           Below\nIowa             2.2      56       57 11.3           Below\nKansas           6.0     115       66 18.0           Below\nMaine            2.1      83       51  7.8           Below\nMassachusetts    4.4     149       85 16.3           Below\nMinnesota        2.7      72       66 14.9           Below\nMontana          6.0     109       53 16.4           Below\nNebraska         4.3     102       62 16.5           Below\nNew Hampshire    2.1      57       56  9.5           Below\nNew Jersey       7.4     159       89 18.8           Below\nNorth Dakota     0.8      45       44  7.3           Below\nOhio             7.3     120       75 21.4           Below\nOklahoma         6.6     151       68 20.0           Below\nOregon           4.9     159       67 29.3           Below\nPennsylvania     6.3     106       72 14.9           Below\nRhode Island     3.4     174       87  8.3           Below\nSouth Dakota     3.8      86       45 12.8           Below\nUtah             3.2     120       80 22.9           Below\nVermont          2.2      48       32 11.2           Below\nWashington       4.0     145       73 26.2           Below\nWest Virginia    5.7      81       39  9.3           Below\nWisconsin        2.6      53       66 10.8           Below\nWyoming          6.8     161       60 15.6           Below\n\n\n\n\nFiltering Using a Function\nThe mean() function will return the mean of a vector. We can pull() a variable from the data frame and pipe it to mean():\n\nUSArrests |&gt;\n  pull(Murder) |&gt;\n  mean()\n\n[1] 7.788\n\n\nAlternatively, use the $ operator:\n\nmean(USArrests$Murder)\n\n[1] 7.788\n\n\nWe now see the mean is 7.788. We can filter the data frame to retain rows for which Murder &gt; 7.788\n\nUSArrests |&gt;\n  filter(Murder &gt; 7.788)\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nAlaska           10.0     263       48 44.5\nArizona           8.1     294       80 31.0\nArkansas          8.8     190       50 19.5\nCalifornia        9.0     276       91 40.6\nColorado          7.9     204       78 38.7\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nKentucky          9.7     109       52 16.3\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nMissouri          9.0     178       70 28.2\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\nVirginia          8.5     156       63 20.7\n\n\nThis approach, however, is not helpful when your data change. And even though you think your data will not change, updates to data, filtering of rows or cases, different cleaning methods, all have a high probability of changing the mean. Working smarter rather than harder involves ensuring that you circumvent such issues.\nNever hard code!\nInstead, use mean() to do this for us.\n\nUSArrests |&gt;\n  filter(Murder &gt; mean(Murder))\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nAlaska           10.0     263       48 44.5\nArizona           8.1     294       80 31.0\nArkansas          8.8     190       50 19.5\nCalifornia        9.0     276       91 40.6\nColorado          7.9     204       78 38.7\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nKentucky          9.7     109       52 16.3\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nMissouri          9.0     178       70 28.2\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\nVirginia          8.5     156       63 20.7\n\n\nIf you have been paying attention, you know that you need to understand how the functions you use work.\nhelp(mean)\nIn the usage section, you see that by default, mean() will not remove NA (missing) values from the vector.\nmean(x, \n     trim = 0, \n     na.rm = FALSE, \n     ...\n     )\nFor example:\n\nmean(c(1, 9, 88, NA))\n\n[1] NA\n\n\nThe mean is clearly not NA but the function is operating just as it should. If you ever get an NA in your vector, the above code will not work. By default, na.rm = FALSE, which means that NA values will not be removed. If they exist, the mean will be returned as NA.\nThe smarter approach is to pass TRUE to the na.rm parameter (na.rm = na remove).\n\nmean(c(1, 9, 88, NA), na.rm = TRUE)\n\n[1] 32.66667\n\n\nAnd for the data frame:\n\nUSArrests |&gt;\n  filter(Murder &gt; mean(Murder, na.rm = TRUE))\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nAlaska           10.0     263       48 44.5\nArizona           8.1     294       80 31.0\nArkansas          8.8     190       50 19.5\nCalifornia        9.0     276       91 40.6\nColorado          7.9     204       78 38.7\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nKentucky          9.7     109       52 16.3\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nMissouri          9.0     178       70 28.2\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\nVirginia          8.5     156       63 20.7\n\n\nNotice changes here because there were not NA values in the variable but there could be at various times."
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using na.omit()",
    "text": "Filter using na.omit()\nFilter the entire data frame:\n\nDAT |&gt;\n  na.omit()                # omit any rows with NAs \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n3 102    Male  27     yes\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using is.na() and !is.na()",
    "text": "Filter using is.na() and !is.na()\nFilter based on a specific variable:\n\nDAT |&gt;\n  filter(is.na(Sex))       # keep NAs by variable\n\n   Id  Sex Age Renting\n1 103 &lt;NA&gt;  40    &lt;NA&gt;\n\n\nBut your goal may likely be to keep everything that is not NA:\n\nDAT |&gt;\n  filter(!is.na(Sex))      # remove NAs by variable\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 104     man  44      no\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nAnd filter step-by-step for each variable using |&gt; and separate function calls:\n\nDAT |&gt;\n  filter(!is.na(Sex)) |&gt;\n  filter(!is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nSo why use separate lines of code if you can use & all in one line? One reason is that separate function calls written as separate lines of code make code inclusion/exclusion extremely easy.\nComment out what you do not want using #:\n\nDAT |&gt;\n  #filter(!is.na(Sex)) |&gt;\n  filter(!is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using complete.cases()",
    "text": "Filter using complete.cases()\nThe complete.cases() function returns a logical vector for which TRUE reflects the row has complete information and no missing cases. Using complete.cases() along with filter(), you would retain all rows TRUE rows.\nThere is a caveat, however, which is that you will need to pipe the data frame with {magrittrs} %&gt;% piping operator. And this involves passing . as the argument to the .data parameter of filter() (the first parameter).\n\nDAT %&gt;%\n  filter(.data = ., complete.cases(.))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nIf you use |&gt;, you will get an error:\nDAT |&gt;\n  filter(.data = ., complete.cases(.))\nA way around this is to create your own function in a .R script and add it to /src/functions. We can name filter_complete_cases.\n\nfilter_complete_cases &lt;- function() {\n  complete.cases(dplyr::cur_data())\n}\n\nAnd then pipe using |&gt;:\n\nDAT |&gt;\n  filter(filter_complete_cases())\n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `filter_complete_cases()`.\nCaused by warning:\n! `cur_data()` was deprecated in dplyr 1.1.0.\nℹ Please use `pick()` instead.\n\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nYou choose your method."
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "href": "modules/data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "title": "Data frame manipulation and wrangling",
    "section": "Removing duplicate rows using distinct()",
    "text": "Removing duplicate rows using distinct()\nWe will examine some other filtering methods that do not use filter() specifically but that which perform filtering operations.\n\ndplyr::distinct(): remove duplicate rows\ndplyr::distinct(., column): remove duplicate rows by specific column\nna.omit(): remove any row with NA’s (missing values)\n\nLet’s use the simple DAT data frame.\n\nDAT\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\n\nthe_file &lt;- gsub(\" \", \"%20\", paste0(get_url_for_module_setup(), \"R Basics/\", \"vectors_and_data_frame_basics.html\"))\n#https://gabrielcook.xyz/dataviz24/modules_setup/R%20Basics/vectors_and_data_frame_basics.html\n\nRemember that data frames are composed of rows and columns. As discussed previously) we can subset in base R to illustrate a point.\nRow 1, all columns:\n\nDAT[1,]\n\n   Id  Sex Age Renting\n1 100 male  25     yes\n\n\nRow 6, all columns:\n\nDAT[6,]\n\n   Id  Sex Age Renting\n6 100 male  25     yes\n\n\nNotice that rows 1 and 6 are the same person (e.g., Id) and have exactly the same data for all variables. If we compare the two logically, we will confirm that all is TRUE.\n\nDAT[1,] == DAT[6,]\n\n    Id  Sex  Age Renting\n1 TRUE TRUE TRUE    TRUE\n\n\nYou clearly do not want duplicates of data. So let’s just remove any rows that are identical using distinct()\n\nRemoving Duplicates Across All Variables\n\nDAT |&gt;\n  distinct()       # Remove exact duplicates across all columns\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nIf you know each row is unique based on a variable in the data frame, you can also use distinct() to remove duplicates for a specific variable. Make sure that this variable specification is actually one that you would not want duplicates of.\n\n\nRemoving Duplicates Based on a Variable\n\nDAT |&gt;           \n  distinct(Id)     #  Remove duplicates by variable; passes unique values for data frame\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 105\n\n\nBut this function simply returns the unique values in Id. To retain the variables, set .keep_all = TRUE. If you want to remove duplicates and assign the cleaned data frame to an object, you would likely want to keep all of your variables.\n\nDAT |&gt;             \n  distinct(Id, \n           .keep_all = T\n           )\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nNotice, however, this only removed the last instance or Id == 100. Which row to include is a judgment call. The first, the last, neither, the average? Is there a correct answer?"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases using ==",
    "text": "Filter Cases using ==\nFilter rows for which the Sex variable is equal to the string 'female':\n\nDAT |&gt;\n  filter(Sex == 'female')\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is not equal to the string 'female':\n\nDAT |&gt;\n  filter(Sex != 'female')\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nFilter rows for which the Sex variable is equal to the string 'female' AND Age is greater than the numeric 27:\n\nDAT |&gt;\n  filter(Sex == 'female' & Age &gt; 27) # this \"AND\" that\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is equal to the string 'female' OR Age is greater than the numeric 27:\n\nDAT |&gt;\n  filter(Sex == 'female' | Age &gt; 27) # this \"OR\" that\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nA cleaner method involves separate lines of code. Although cleaner, this will not allow the “OR” option because the data frame that is returned from the first filter() is passed to the second filter() and all cases other than \"female\" have already been removed from the data frame.\n\nDAT |&gt;\n  filter(Sex == 'female') |&gt;    # keep female (and add another pipe)\n  filter(Age &gt;= 27)             # keep only those equal to or older than 27\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by < and > or <= or >=",
    "text": "Filter by &lt; and &gt; or &lt;= or &gt;=\nKeep those less than:\n\nDAT |&gt; \n  filter(Age &lt; 40)   \n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 102   Male  27     yes\n4 100   male  25     yes\n\n\nKeep older than:\n\nDAT |&gt; \n  filter(Age &gt; 40)  \n\n   Id Sex Age Renting\n1 104 man  44      no\n\n\nKeep equal to or older than:\n\nDAT |&gt; \n  filter(Age &gt;= 40)  \n\n   Id     Sex Age Renting\n1 103    &lt;NA&gt;  40    &lt;NA&gt;\n2 104     man  44      no\n3 105 neither  40     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases by Conditional X or Y Using | Operator…",
    "text": "Filter Cases by Conditional X or Y Using | Operator…\nUsing the “OR” operator, |, cases can be included if “this” OR “that” condition.\nFilter numbers:\n\nDAT |&gt;\n  filter(Age == 25 | Age == 40)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 100    male  25     yes\n4 105 neither  40     yes\n\n\nFilter characters:\n\nDAT |&gt;\n  filter(Sex == 'male' | Sex == 'female')\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes\n\n\nAlthough dplyr::filter(sex %in% c('male', 'female')) would be easier.\nFilter rows of variables of both types:\n\nDAT |&gt;\n  filter(Sex == 'male' | Age == 27)  \n\n   Id  Sex Age Renting\n1 100 male  25     yes\n2 102 Male  27     yes\n3 100 male  25     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases Between Values with between()",
    "text": "Filter Cases Between Values with between()\nBetween ages 25 and 33:\n\nDAT |&gt;\n  filter(between(Age, 27, 33))\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n2 102   Male  27     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by range using the %in% operator (this is IN meaning in)",
    "text": "Filter by range using the %in% operator (this is IN meaning in)\nThough less flexible than using between(), %in% may be easier to remember:\n\nDAT |&gt;\n  filter(Age %in% 20:43)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nOne’s age is in the range from 20 through 43.\nIf a vector object is already defined (e.g., my_levels = c('male', 'female')), you can use that for filtering also. Such approaches are useful when data manipulation involves reusing a reference as it simplifies coding and reduces errors because the specification is defined only once.\n\nmy_levels = c('male', 'female')\n\nDAT |&gt;\n  filter(Sex %in% my_levels)\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by exclusion",
    "text": "Filter by exclusion\nWhen inclusion of variables is inappropriate, exclusion of them may be useful. The ! operator means “NOT” in R so you can use that to accomplish the opposite of the statement. For example, dplyr::filter(., !sex %in% c('male', NA)) will “filter the data frame to include rows in the sex column for which the value is NOT in the vector”.\nExclude rows in the Sex variable that are NA or 'male':\n\nDAT |&gt;\n  filter(!Sex %in% c('male', NA))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nExclude rows in the Sex variable that are Men or 'male':\n\nDAT |&gt;\n  filter(!Sex %in% c('male', 'Men'))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 103    &lt;NA&gt;  40    &lt;NA&gt;\n4 104     man  44      no\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "href": "modules/data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by conditional X and Y using & operator…",
    "text": "Filter by conditional X and Y using & operator…\nBy range:\n\nDAT |&gt;\n  filter(Id &gt;= 102 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 102    Male  27     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 105 neither  40     yes\n\n\n\nDAT |&gt;\n  filter(Age &gt;= 20 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nNote: Age 20:43 won’t work. Can you figure out why?"
  },
  {
    "objectID": "modules/considerations_in_data_visualization.html",
    "href": "modules/considerations_in_data_visualization.html",
    "title": "Considerations in data visualization",
    "section": "",
    "text": "The focus of this module is to raise considerations for creating data visualizations to tell a story about data. Anyone can code a bar plot, scatterplot, line plot or any other visualization whether simple or complex. Out of the box, {ggplot2} allows you to produce some reasonable but the library does not evaluate items like:\n\nthe appropriateness of your plot to the specific story you are trying to tell,\nthe appropriateness of the color scheme used for a client project, or\nthe appropriateness of the colors for your client’s internal team or their public audience. Function libraries also do not consider whether your plot takes on perceptual properties that may bias your readership.\n\nIssues arise when you accept the default performance of functions and produce plots that contain elements that are not appropriate to a specific audience or perceptually problematic to the general human audience. You should not consider a coded plot complete without considering its elements thoroughly. This module introduces some of these issues."
  },
  {
    "objectID": "modules/considerations_in_data_visualization.html#prior-to-class",
    "href": "modules/considerations_in_data_visualization.html#prior-to-class",
    "title": "Considerations in data visualization",
    "section": "Prior to class",
    "text": "Prior to class\nComplete the brief readings below. There is no coding video corresponding to this module.\n\nReadings\n\nThe goal should be to familiarize yourself and bring questions to class. The online readings are taken from Fundamentals of Data Visualization, a great book by Clause Wilke, a professor of molecular evolution at The University of Texas at Austin.\n\nWilke (2019). Fundamentals of Data Visualization. The principle of proportional ink\nWilke (2019). Fundamentals of Data Visualization. Common pitfalls of color use\nWilke (2019). Fundamentals of Data Visualization. Telling a story"
  },
  {
    "objectID": "modules/attentional_control.html",
    "href": "modules/attentional_control.html",
    "title": "Attentional control",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/attentional_control.html#readings",
    "href": "modules/attentional_control.html#readings",
    "title": "Attentional control",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Balance the data and the context\nWilke (2019). Fundamentals of Data Visualization. Use larger axis labels\nAjani et al. (2022). Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication"
  },
  {
    "objectID": "modules/attentional_control.html#external-functions",
    "href": "modules/attentional_control.html#external-functions",
    "title": "Attentional control",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\n#source(here::here(\"src\", \"my_functions.R\"))\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz24/main/src/functions/describe.R\")"
  },
  {
    "objectID": "modules/attentional_control.html#libraries",
    "href": "modules/attentional_control.html#libraries",
    "title": "Attentional control",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting\n{ggrepel} 0.9.5: for repelling labels from points and lines\n{geomtextpath} 0.1.4: for annotation of curved paths (also straight)\n{gghighlight} 0.4.1: for highlighting lines and points\n{ggtext} 0.1.2: for text on plots; markdown elements (viz, element_markdown)"
  },
  {
    "objectID": "modules/attentional_control.html#increase-the-size-of-axis-labels",
    "href": "modules/attentional_control.html#increase-the-size-of-axis-labels",
    "title": "Attentional control",
    "section": "Increase the size of axis labels",
    "text": "Increase the size of axis labels\nFor each axis.text.&lt;axis&gt;, you can adjust the element_text().\n\naxis.text.x = element_text(size = 12)\naxis.text.y = element_text(size = 12)\n\n\n(base_plot &lt;- DATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .8,\n             position = position_jitter(height = 0, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        )\n)\n\n\n\n\nNotice that this adjustment does not increase the legend text size too. This is a different element."
  },
  {
    "objectID": "modules/attentional_control.html#increase-the-size-of-the-legend-labels",
    "href": "modules/attentional_control.html#increase-the-size-of-the-legend-labels",
    "title": "Attentional control",
    "section": "Increase the size of the legend labels",
    "text": "Increase the size of the legend labels\n\nlegend.text = element_text(size = 12)\n\n\nbase_plot +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12),  # y-axis size\n        legend.text = element_text(size = 12)   # legend text size\n        )"
  },
  {
    "objectID": "modules/attentional_control.html#increase-the-size-of-the-legend-shapes",
    "href": "modules/attentional_control.html#increase-the-size-of-the-legend-shapes",
    "title": "Attentional control",
    "section": "Increase the size of the legend ‘shapes’",
    "text": "Increase the size of the legend ‘shapes’\nWe have already addressed how to make legend shape elements larger too. This adjustment is in the guides() and requires overriding aesthetics. We need to add a guides() layer. Importantly, you need to be careful to specify the aesthetic mapped, in this case col. If you mapped a variable to a discrete color, then you will need to change the size of the col aesthetics. If you mapped a variable to a shape, and you want to increase the size of the shapes, then you will need to change the size of the shape aesthetics.\n\nguides(&lt;aesthetic mapped&gt; = guide_legend(override.aes = list(size = 3)))\n\nIn this example, col was mapped and the goal is to change the size of the color ‘shape’ so the solution is:\n\nguides(col = guide_legend(override.aes = list(size = 3)))\n\nThere is no shape mapping, so changing the size of the shape will not work:\n\nguides(shape = guide_legend(override.aes = list(size = 3)))\n\n\nbase_plot +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12),  # y-axis size\n        legend.text = element_text(size = 12)   # legend text size\n        ) +\n  guides(col = guide_legend(override.aes = list(size = 3)))"
  },
  {
    "objectID": "modules/attentional_control.html#passing-objects-for-adjustments",
    "href": "modules/attentional_control.html#passing-objects-for-adjustments",
    "title": "Attentional control",
    "section": "Passing objects for adjustments",
    "text": "Passing objects for adjustments\nOf course, the points on the plot are small too, so you would want to adjust them if necessary. We can use some objects to make the process easier. If you want to apply the same approach to many or all plots you create, you might just prefer to create a custom theme().\n\npoint_size &lt;- 3\nfont_size  &lt;- 11\n\nbase_plot +\n  theme(\n        # the axis text in general\n        axis.text = element_text(size = font_size),     # both and ticks\n        # or specifically\n        #axis.text.x = element_text(size = font_size),  # x-axis size\n        #axis.text.y = element_text(size = font_size),  # y-axis size\n        \n        # the title label\n        axis.title = element_text(size = font_size + 3),  # bump it up relatively\n        \n        # the legend text\n        legend.title = element_text(size = font_size + 1),  # legend title, bump up if desired\n        legend.text = element_text(size = font_size)    # legend text size\n        ) +\n  guides(col = guide_legend(override.aes = list(size = point_size)))"
  },
  {
    "objectID": "modules/attentional_control.html#adding-reference-points",
    "href": "modules/attentional_control.html#adding-reference-points",
    "title": "Attentional control",
    "section": "Adding reference points",
    "text": "Adding reference points\nLet’s say you want to highlight a data point or location of interest. We can do so by specifying the point or region.\nThere are a few ways to address this. You can use stat_summary() to draw attention to a place on the plot, the mean of the variable mapped to y.\n\nbase_plot +\n  stat_summary(\n    fun = \"mean\",        # the summary function\n    geom = \"point\",      # the geom \n    #shape = 23,         # the geom_point shape if you wish to change it \n    size = 3,            # the color \n    #fill = \"grey\",      # fill color if your point has fill \n    col = \"grey20\",        # the color\n    alpha = .8\n    )\n\n\n\n\nWhereas stat_summary() applies the function to the groups, you may wish to highlight a single point. When this is the case, you will use different data than what you pass to the ggplot() object.\nThe best athlete.\n\n( best_2019 &lt;- DATA |&gt; filter(Year == 2019) |&gt;  slice_max(Score) )\n\n# A tibble: 1 × 7\n  Athlete        Rank Score Meet                               Date  Team   Year\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                              &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Sill, Michael     2  49.8 SCIAC Track & Field Conference Ch… Apr … Stag   2019\n\n\nWhen only x or y matters, you can specify that single point.\n\n( mean_y_2019 &lt;- DATA |&gt; filter(Year == 2019) |&gt;  pull(Score) |&gt; mean() )\n\n[1] 39.37329\n\n\nWhen x and y matter, you may wish to specify that point.\n\n( mean_xy_2019 &lt;- DATA |&gt; \n  filter(Year == 2019) |&gt;  \n  summarize(Rank = mean(Rank, na.rm = T),\n            Score = mean(Score, na.rm = T)\n  )\n)  \n\n# A tibble: 1 × 2\n   Rank Score\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2.54  39.4\n\n( team_mean_xy_2019 &lt;- DATA |&gt; \n  filter(Year == 2019) |&gt;  \n  group_by(Team) |&gt;\n  summarize(Rank = mean(Rank, na.rm = T),\n            Score = mean(Score, na.rm = T)\n  )\n) \n\n# A tibble: 2 × 3\n  Team    Rank Score\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Athena  2.42  32.4\n2 Stag    2.64  45.0"
  },
  {
    "objectID": "modules/attentional_control.html#adding-reference-line",
    "href": "modules/attentional_control.html#adding-reference-line",
    "title": "Attentional control",
    "section": "Adding reference line",
    "text": "Adding reference line\nLet’s plot a horizontal line using geom_hline() to direct attention for reference or comparison.\n\nbase_plot +\n  geom_hline(yintercept = mean_y_2019)\n\n\n\n\nLet’s add a label easily using {geomtextpath}:\n\nbase_plot +\n  geomtextpath::geom_texthline(yintercept = mean_y_2019,\n                               label = \"2019 average\",\n                               alpha = .5\n                               )\n\nWarning in geomtextpath::geom_texthline(yintercept = mean_y_2019, label = \"2019 average\", : All aesthetics have length 1, but the data has 85 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\nNotice, we are only specifying a place for all athletes rather than for Stags and Athenas separately."
  },
  {
    "objectID": "modules/attentional_control.html#adding-reference-point-with-annotation",
    "href": "modules/attentional_control.html#adding-reference-point-with-annotation",
    "title": "Attentional control",
    "section": "Adding reference point with annotation",
    "text": "Adding reference point with annotation\n\nannotate(geom = \"point\")\nUse annotate() to plot a point to highlight some element using geom = \"point\".\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  )\n\n\n\n\n\n\nannotate(geom = \"point\") and annotate(geom = \"text\")\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score - 1, \n           label = \"mean\",\n           size = 3\n  )\n\n\n\n\n\n\ngeom_curve() with arrow()\nDirect attention with annotation and an arrow.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score - 1, \n           label = \"mean\",\n           size = 3\n  ) +\n  geom_curve(x = mean_xy_2019$Rank,                 # where the curve begins\n             y = mean_xy_2019$Score,\n             xend = mean_xy_2019$Rank + .2,          # where the curve ends\n             yend = mean_xy_2019$Score + 2,\n             color = \"grey20\", \n             arrow = arrow(angle = 20,              # angle of the arrow\n                           length = unit(0.25,\"cm\"),\n                           ends = \"first\",          # \"last\", \"first\", or \"both\"\n                           type = \"closed\"          # \"open\" or \"closed\" triangle\n                           ),\n             curvature = 1                        # the amount of curvature (0 is a line, not a curve) \n             ) \n\n\n\n\nBut the arrow point is overlapping the mean point. Let’s back off. Also, if you won’t be getting new data, you can set the coordinates to static values. This plot reflects a series of edits.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = 2,\n           y = 19, \n           label = \"mean\",\n           size = 4\n  ) +\n  geom_curve(x = mean_xy_2019$Rank - .04,           # where the curve begins\n             y = mean_xy_2019$Score - 1,\n             xend = 2,                              # where the curve ends\n             yend = 20,\n             color = \"grey20\", \n             arrow = arrow(angle = 20,              # angle of the arrow\n                           length = unit(0.25,\"cm\"),\n                           ends = \"first\",          # \"last\", \"first\", or \"both\"\n                           type = \"closed\"          # \"open\" or \"closed\" triangle\n                           ),\n             curvature = 0.1                        # the amount of curvature (0 is a line, not a curve) \n             ) \n\n\n\n\n\n\ngeomtextpath::geom_textcurve()\nDirect attention with annotation along the line.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    xend = 2,\n    yend = 20,\n    curvature = .1,\n    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n    vjust = 0,\n    col = \"black\",\n    arrow = arrow(ends = \"first\"),\n    label = \"mean\"                                   # label required (this replaces annotate() layer)\n  )\n\n\n\n\nWarning: If your label is too long, fore example \"overall mean\", R will throw an error.\nError: Cannot create zero-length unit vector (\"unit\" subsetting)\n\n\nDefining an arrow()\nLet’s make an arrow to reuse. The default is ugly.\n\nmy_arrow &lt;- arrow(angle = 20,              \n                  length = unit(0.25,\"cm\"),\n                  ends = \"first\",          \n                  type = \"closed\"          \n                  )\n\nYou can change the font size to a smaller value, for example, size = 2.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    size = 2,\n    xend = 2,\n    yend = 20,\n    curvature = .1,\n    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n    vjust = 0,\n    col = \"black\",\n    arrow = my_arrow,\n    label = \"overall mean\"                                      # label required (this replaces annotate() layer)\n  )\n\n\n\n\nOK, too small. You can also change the length to the curve or line by changing xend and yend. Also, accepting the default justification serves you well enough, so let’s comment out.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey40\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 2\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    #size = 2,\n    xend = 1.5,\n    yend = 20,\n    curvature = 0,\n#    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n#    vjust = 0,\n    col = \"grey40\",\n    arrow = my_arrow,\n    fontface = \"bold\",\n    label = \"overall mean\"                                      # label required (this replaces annotate() layer)\n  )\n\n\n\n\n\n\ngeomtextpath::geom_textcurve() with a new data frame\nIn the previous example, we set the coordinates from outside of aes(). This was done to show you that you could control the coordinates manually. In this example, we will take a new data frame and set data = best_2019. We will map x and y and then set xmin and ymin either because they do not exist in the data frame or because we just don’t want to map them.\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_textcurve(\n    data = best_2019,                           # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    xend = 3.5,\n    yend = 60,\n    size = 3,\n    curvature = -.1,\n    arrow = my_arrow,\n    col = \"black\"\n  )\n\n\n\n\nNote: With {geomtextpath} text objects, if you receive the following error: Error: Cannot create zero-length unit vector (\"unit\" subsetting), this may reflect that your plot space in RStudio is too small to render the object correctly. Your code may not be in error. Simply increase the size of your plot space environment in RStudio.\n\n\ngeomtextpath::geom_labelcurve()\nSame thing using geomtextpath::geom_labelcurve().\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_labelcurve(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    xend = 3.5,\n    yend = 60,\n    size = 3,\n    curvature = -.1,\n    arrow = my_arrow,\n    col = \"black\",\n  )\n\n\n\n\nOne issue with geom_textcurve() and geom_labelcurve() is the difficulty controlling the size of the content and the length of the line.\n\n\ngeomtextpath::geom_textline()\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_textline(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    size = 3,\n    col = \"black\",\n  )\n\n\n\n\nBut the line is directly over the point. You can add values to x and y to move it. For example, aes(x = Score + 2, ...) but that might still look odd without an arrow. This adjustment is nevertheless made in the next example using geom_labelline().\n\n\ngeomtextpath::geom_labelline()\nIf you want to geomtextpath::geom_labelline():\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_labelline(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score + 5,\n                  label = paste(Year, \" Top Athlete\\n\", Score, \"m \", Athlete, sep = \"\"),\n                  ),\n    size = 4,\n#    fontface = \"bold\",\n    col = \"black\",\n  )"
  },
  {
    "objectID": "modules/attentional_control.html#drawing-attention-to-a-bar",
    "href": "modules/attentional_control.html#drawing-attention-to-a-bar",
    "title": "Attentional control",
    "section": "Drawing attention to a bar",
    "text": "Drawing attention to a bar\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  mutate(Rank_Color = case_when(\n    Rank == 1 ~ \"goldenrod\",\n    Rank &gt;  1 ~ \"grey60\",\n    TRUE ~ \"grey60\"\n    )) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = Rank_Color\n                       )\n         ) +\n  geom_col() +\n  scale_fill_identity()"
  },
  {
    "objectID": "modules/attentional_control.html#drawing-attention-to-a-bar-using-gghighlight",
    "href": "modules/attentional_control.html#drawing-attention-to-a-bar-using-gghighlight",
    "title": "Attentional control",
    "section": "Drawing attention to a bar using {gghighlight}",
    "text": "Drawing attention to a bar using {gghighlight}\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = factor(Rank)\n                       )\n         ) +\n  geom_col() +\n  gghighlight(Score &gt; 45, \n              unhighlighted_params = list(fill = \"black\")\n              )"
  },
  {
    "objectID": "modules/attentional_control.html#fading-out-bars-by-mapping-a-variable-to-alpha",
    "href": "modules/attentional_control.html#fading-out-bars-by-mapping-a-variable-to-alpha",
    "title": "Attentional control",
    "section": "Fading out bars by mapping a variable to alpha",
    "text": "Fading out bars by mapping a variable to alpha\nWe will just adjust alpha in the data frame by the conditional.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  mutate(\n    cutoff = 41,\n    Alpha = case_when(\n      Score &lt;= cutoff ~ .5,\n      TRUE ~ 1\n  )) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = factor(Rank),\n                       alpha = Alpha\n                       )\n         ) +\n  geom_col()"
  },
  {
    "objectID": "modules/attentional_control.html#highlighting-lines",
    "href": "modules/attentional_control.html#highlighting-lines",
    "title": "Attentional control",
    "section": "Highlighting lines",
    "text": "Highlighting lines\nYou can use geomtextpath::geom_labelline() to label lines. In this example, we label lines with athlete names. Specifically, we will group and obtain best scores for each athlete’s participating year then get the count for rows and filter for athletes who participated in all 4 years.\ngroup_by(Athlete, Rank) |&gt;\nsummarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\ngroup_by(Athlete) |&gt;\nmutate(Count = n()) |&gt;\nfilter(Count == 4) \n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  geom_point(size = 2) + \n  geom_line(linewidth = 1) +\n  geomtextpath::geom_labelline(\n    mapping = aes(label = stringr::str_replace(\n      Athlete, \"^(\\\\w+),\\\\s(\\\\w+)\", \"\\\\2 \\\\1\")\n    ))"
  },
  {
    "objectID": "modules/attentional_control.html#highlighting-with-gghighlight",
    "href": "modules/attentional_control.html#highlighting-with-gghighlight",
    "title": "Attentional control",
    "section": "Highlighting with {gghighlight}",
    "text": "Highlighting with {gghighlight}\nClearly, the legend is no longer needed so that could be removed. Also, the name labels are a bit of a mess. One approach is to use {gghighlight} and gghighlight::gghighlight() which by default will move the labels.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  geom_point(size = 2) + \n  geom_line(linewidth = 1) +\n  gghighlight::gghighlight()\n\nlabel_key: Athlete"
  },
  {
    "objectID": "modules/attentional_control.html#highlighting-specific-data-with-gghighlight",
    "href": "modules/attentional_control.html#highlighting-specific-data-with-gghighlight",
    "title": "Attentional control",
    "section": "Highlighting specific data with {gghighlight}",
    "text": "Highlighting specific data with {gghighlight}\ngghighlight::gghighlight() will take expressions for filtering the data. We can highlight subsets of the data based on a function we pass.\nFor example, mean(Mean_Score) &gt; 45 will highlight lines for which the condition is met.\n\ngghighlight::gghighlight(mean(Mean_Score) &gt; 45)\n\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Mean_Score = mean(Score), \n            Max_Score = max(Score),\n            .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  # add point plot\n  geom_point(size = 2) + \n  # add a line plot\n  geom_line(linewidth = 1) +\n  # highlight conditions met\n  gghighlight::gghighlight(mean(Mean_Score) &gt; 45) +\n  labs(title = \"My Title\",\n       subtitle = \"Out of the 5 athletes who participated all college years, only two maintained an average higher than 45 across meets each year\") +\n  theme(plot.title = element_markdown(face = \"bold\"),\n        plot.subtitle = element_markdown(face = \"italic\"),\n        )\n\nlabel_key: Athlete"
  },
  {
    "objectID": "modules/attentional_control.html#highlighting-a-region-using-annotate",
    "href": "modules/attentional_control.html#highlighting-a-region-using-annotate",
    "title": "Attentional control",
    "section": "Highlighting a region using annotate()",
    "text": "Highlighting a region using annotate()\nUsing geom = \"text\", you can annotate the plot with a rectangle to represent an area of interest. You can think of To draw a rectangle to highlight an area of interest in three useful ways.\n\nTo highlight a vertical band stretching the entire y-axis, beginning and ending at x-axis locations.\nTo highlight a horizontal band stretching the entire x-axis, beginning and ending y-axis locations.\nTo highlight a rectangle, beginning and ending x-axis and y-axis locations\n\nBonus: You can create more than one of any of the preceding.\n\nHighlighting a slice of the x-axis using annotate()\nFor this, we will specify:\n\nxmin: beginning point of x\nxmax: ending point of x\nymin: beginning point of y\n\nymax: ending point of y\nfill: the color inside the rectangle\nalpha: the alpha of the fill color inside the rectangle\ncol: the line border of the rectangle\nlinewidth: the line thickness of the border\nlinetype: the type of the line border\n\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  # make the rectangle\n  annotate(geom = \"rect\", \n           xmin = 2012.5,            # beginning point of x\n           xmax = 2013.5,            # ending point of x\n           ymin = -Inf,              # make the rectangle extend along y  \n           ymax = Inf,               # make the rectangle extend along y\n           fill = \"goldenrod\",       # the color inside the rectangle\n           alpha = 0.25,             # the alpha of the fill color inside the rectangle\n           col = \"black\",            # the line border of the rectangle\n           linewidth = .5,           # the line thickness of the border \n           linetype = \"solid\"        # the type of the line border\n           ) +\n  theme_classic()\n\n\n\n\n\n\nHighlighting a slice of the y-axis using annotate()\nSome elements of the rectangle are removed here and the annotate() layer is added before the points to remind you that layers build on top of each other. Even with transparency of the fill of the rectangle, adding the layer after previous geoms (points in this instance) will result in a visualization that creates the perception of the rectangle covering, and thus, adding color to, the points behind it. If you wish the highlighted region to fade into the background and allow the points to float on top of the rectangle, make sure that your layer order achieves that goal.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # make the rectangle\n  annotate(geom = \"rect\", \n           xmin = -Inf,           # beginning point of x\n           xmax = Inf,            # ending point of x\n           ymin = 55,             # make the rectangle extend along y  \n           ymax = 65,             # make the rectangle extend along y\n           fill = \"goldenrod\",    # the color inside the rectangle\n           alpha = 0.25           # the alpha of the fill color inside the rectangle\n           ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  theme_classic()\n\n\n\n\n\n\nHighlighting a slice of the y-axis using geom_rect()\nUsing annotate() along with geom = \"rect\". However, you can certainly use geom_rect() to build a rectangle.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # add the rectangle\n  geom_rect(xmin = -Inf, \n            xmax = Inf,\n            ymin = 55,         \n            ymax = 65,         \n            fill = \"goldenrod\", \n            alpha = .25,              # same alpha\n            ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  theme_classic()\n\n\n\n\nNotice the color differences. We will address this curiosity later.\n\n\nHighlighting a rectangle using annotate()\nWhen you have a rectangular area of interest, build an actual rectangle. We will also create a data summary based on a subset of athletes and years to obtain the 95% confidence interval for all performances during those years. There is no particular reason those this type of data but this could represent a significant time period.\n\nDATA_CI95 &lt;- DATA |&gt;\n  filter(Team == \"Stag\") |&gt;             # get stag only\n  filter(!is.na(Rank)) |&gt;\n  filter(Year %in% c(2016:2020)) |&gt;\n  summarize(xmin = min(Year),\n            xmax = max(Year),\n            ymin = mean(Score, na.rm = T) - (1.96 * sd(Score, na.rm = T)),\n            ymax = mean(Score, na.rm = T) + (1.96 * sd(Score, na.rm = T)),\n            )\n\n\nDATA |&gt;\n  filter(Team == \"Stag\") |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # build the rectangle based on the subset summary\n  annotate(geom = \"rect\",\n           xmin = DATA_CI95$xmin - .5, # add a buffer to highlight the jittered points\n           xmax = DATA_CI95$xmax + .5, # add a buffer to highlight the jittered points\n           ymin = DATA_CI95$ymin,         \n           ymax = DATA_CI95$ymax,         \n           fill = \"firebrick\", \n           alpha = .25,              \n           ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1))\n\n\n\n\nDuring this time period, you can see there are a few event performances (not athletes) outside this confidence section. However, in other years, there some performances that fall quite above that range.\n\n\nHighlighting two slices of the x-axis using annotate()\nBecause Year and Score are mapped already, we can simply create these two variables in the data frame. If they are not in the data frame, you will get an error and need to troubleshoot. Adding them is a simple solution. As long as the variable type created is the same as the variable in the other data frame, you will be OK. In this instance, we can just add a numeric value that is within the plot coordinates. The mean will ensure this.\n\n(DATA_topbottom &lt;- DATA |&gt;\n  filter(Team == \"Stag\") |&gt;             # get stag only\n  filter(!is.na(Rank)) |&gt;\n  mutate(Decile = ntile(Score, 10)) |&gt;\n  group_by(Decile) |&gt;\n  summarize(xmin = -Inf,\n            xmax = Inf,\n            ymin = min(Score, na.rm = T),\n            ymax = max(Score, na.rm = T),\n            Year = mean(Year, na.rm = T),   # a numeric value needs to be added \n            Score = mean(Score, na.rm = T)  # a numeric value needs to be added \n            ) |&gt; \n  ungroup() |&gt;\n  filter(Decile %in% c(1,10))   # keep data in the top and bottom decile\n)\n\n# A tibble: 2 × 7\n  Decile  xmin  xmax  ymin  ymax  Year Score\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  -Inf   Inf  5.32  33.9 2017.  29.7\n2     10  -Inf   Inf 51.0   61.6 2013.  55.0\n\n\nWe now have a data frame with two rows, one for the top decile and one for the bottom. Let’s add a geom_rect() and specify data = DATA_topbottom and then map the variables to the required aesthetics.\n\nDATA |&gt;\n  filter(Team == \"Stag\") |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # build the rectangle based on new data\n  geom_rect(data = DATA_topbottom,\n            mapping = aes(xmin = xmin,\n                          xmax = xmax,\n                          ymin = ymin,\n                          ymax = ymax, \n                          fill = factor(Decile)\n                          ),\n            alpha = .2,              \n           ) +\n  # add point plot\n  geom_point(mapping = aes(col = factor(Year)),\n             size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  coord_flip() + \n  labs(x = NULL) + \n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\nRemoving the legend and instead either direct labeling the deciles or using color in the title to clarify them will help communicate the intent of these bands without the legend taking up so much real estate. And of course, you could add a color variable to the data frame and scale_color_identity() the color for the 1st and 10th decile. If you are already using color for the points, then coloring them would be challenging. You could use filled shapes and add a black color ring around them or change the stroke. But using a rectangle might serve a useful purpose. Whatever you do to draw attention to plot elements, ensure that your audience understands your intent.\n\n\nComparing annotate() versus geom_rect()\nWhy introduce you to both approaches if they can achieve the same outcome? Well, notice the difference between the rectangle added with annotate() and geom_rect() when the alpha is the same. Although alpha = .25 in both some instances, geom_rect() draws a darker rectangle.\nWhy? Remember that geoms will iterate for each row in the data frame. Because the variables are mapped to aesthetics in geom_rect(), the rectangle is built over and over again. You can experience this with the time required to build the plot when there are many rows. If you want more control over alpha, you might consider annotate()."
  },
  {
    "objectID": "cheatsheets_and_tips/symbols.html",
    "href": "cheatsheets_and_tips/symbols.html",
    "title": "Symbols",
    "section": "",
    "text": "Symbol\nTerm\n\n\n\n\n&lt;-\nassignment operator\n\n\n()\n(round) brackets / parentheses\n\n\n[]\nsquare brackets\n\n\n{}\ncurly brackets\n\n\n&lt;&gt;\nchevrons/angled brackets\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n#\nhash/pound\n\n\n/\nforward slash\n\n\n\\\nbackslash\n\n\n-\ndash/hyphen/minus\n\n\n_\nunderscore\n\n\n*\nasterisk/star\n\n\n^\ncaret/power symbol\n\n\n~\ntilde/twiddle\n\n\n=\nequal sign\n\n\n==\ndouble equal sign (logical equivalence)\n\n\n.\nfull stop/period/point\n\n\n|&gt;\npipe (see also %&gt;% for {magrittr})\n\n\n&\nampersand/and (“and” operator)\n\n\n|\nvertical bar/pipe (“or” operator)\n\n\n!\nexclamation mark/bang (“not” operator)\n\n\n?\nquestion mark\n\n\n’\nsingle quote/apostrophe"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Nothing to see here"
  },
  {
    "objectID": "index.html#psyc-167-data-visualization",
    "href": "index.html#psyc-167-data-visualization",
    "title": "**Data Visualization**",
    "section": "PSYC 167: Data Visualization",
    "text": "PSYC 167: Data Visualization\nThis is the course website for PSYC 167: Data Visualization, taught by Prof. Gabriel I. Cook; 1 credit\nDescription\nData visualization is the science and art of creating graphical representations of information and data. Visual representations provide accessible ways to see patterns, trends, and outliers in data. Variables like position, size, and orientation can focus attention and guide perception but can also bias interpretation of data. Students will learn how well-designed visualizations can reduce bias and improve comprehension for data thereby facilitating data-driven decision-making. Students will explore techniques for creating effective visualizations based on principles from cognitive and perceptual psychology, art, and design. Students will gain hands-on experience coding real-world data visualizations for local offices, organizations, and industry participants.\nThe course is targeted toward students interested in using visualizations to communicate their own messages, and students interested in creating better visualization tools and systems, and students with expressed interest in cognition and cognitive biases related to data communication. Students will engage in discussions of the readings, complete programming and data analysis assignments, and prepare a final project involving storytelling with data visualizations."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html",
    "href": "modules/color_scales_and_palettes.html",
    "title": "Color scales and palettes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#readings",
    "href": "modules/color_scales_and_palettes.html#readings",
    "title": "Color scales and palettes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Color basics\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Color scales"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#external-functions",
    "href": "modules/color_scales_and_palettes.html#external-functions",
    "title": "Color scales and palettes",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#libraries",
    "href": "modules/color_scales_and_palettes.html#libraries",
    "title": "Color scales and palettes",
    "section": "Libraries",
    "text": "Libraries\n\n{colorblindr} 0.1.0: for simulations of color vision deficiencies to ggplot2 objects; post-hoc color editing\n{colorspace} 2.1.0: for manipulating and assessing colors and color palettes\n{cowplot} 1.1.3: for ggplot add-ons; object management\n{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{ggplot2} 3.5.1: for plotting\n{ggthemes} 5.1.0: for palettes and themes\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{patchwork} 1.2.0: for plotting on grids\n{RColorBrewer} 1.1.3: for color palettes"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#load-libraries",
    "href": "modules/color_scales_and_palettes.html#load-libraries",
    "title": "Color scales and palettes",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(colorspace)\nlibrary(cowplot)\nlibrary(ggthemes)  # for scale_color_colorblind()\nlibrary(colorblindr)\nlibrary(khroma)"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "href": "modules/color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "title": "Color scales and palettes",
    "section": "To distinguish categories (qualitative)",
    "text": "To distinguish categories (qualitative)\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, fill = Event)) +\n  geom_bar()"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "href": "modules/color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (sequential)",
    "text": "To represent numeric values (sequential)\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic()\n\n\n\n\nWhen no fill scale is defined, default is scale_fill_gradient(), which we can change to something else.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_fill_viridis_c()\n\n\n\n\nBut the function won’t change anything if we don’t use the proper scale_*_() function.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c(option = \"B\", begin = 0.15)"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "href": "modules/color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (diverging):",
    "text": "To represent numeric values (diverging):\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_gradient2()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging() \n\n\n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_distiller(type = \"div\")\n\n\n\n\nThere are other applications too but we cannot get into them all here."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "href": "modules/color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "title": "Color scales and palettes",
    "section": "Color Scales Built into {ggplot2}",
    "text": "Color Scales Built into {ggplot2}\nThere are colors built into {ggplot2}. The scale_*() functions will also following the naming conventions scale_color_*() or scale_fill_*(). When you have bars, remember that you are changing fill color and with solid circle points you are changing col so your go-to functions should adhere to those naming conventions (e.g., scale_fill_*() and scale_color_*()). Some examples include: scale_color_brewer() or scale_color_distiller() for discrete or continuous scales, respectively.\n{ggplot} functions:\n\nscale_color_hue(): color, data: discrete, palette: qualitative\nscale_fill_hue(): fill, data: discrete, palette: qualitative\nscale_color_gradient(): color, data: continuous, palette: sequential\nscale_color_gradient2(): color, data: continuous, palette: diverging\nscale_fill_viridis_c(): color, data: continuous, palette: sequential\nscale_fill_viridis_d(): fill, data: discrete, palette: sequential\nscale_color_brewer(): color, data: discrete , palette: qualitative, diverging, sequential\nscale_fill_brewer(): fill, data: discrete, palette: qualitative, diverging, sequential\nscale_color_distiller(): color, data: continuous, palette: qualitative, diverging, sequential"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#colorspace-color-palettes",
    "href": "modules/color_scales_and_palettes.html#colorspace-color-palettes",
    "title": "Color scales and palettes",
    "section": "{colorspace} Color Palettes",
    "text": "{colorspace} Color Palettes\n\ncolorspace::hcl_palettes(type = \"sequential\", plot = TRUE) # all sequential palettes\n\n\n\n\n\ncolorspace::hcl_palettes(type = \"diverging\", plot = TRUE, n = 9) # all diverging palettes\n\n\n\n\n\ncolorspace::divergingx_palettes(plot = TRUE, n = 9) # all divergingx palettes"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#example-plots",
    "href": "modules/color_scales_and_palettes.html#example-plots",
    "title": "Color scales and palettes",
    "section": "Example plots",
    "text": "Example plots\nWe can then specify the function according to our goal using: scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(). We can see an example with filling points.\nContinuous:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous()\n\n\n\n\nContinuous and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential()\n\n\n\n\nDiscrete and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = School)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_discrete_sequential()\n\n\n\n\nA specific palette added: palette = \"Inferno\"\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential(palette = \"Inferno\")\n\n\n\n\nContinuous and Diverging:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging()"
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#exploring-colorspace",
    "href": "modules/color_scales_and_palettes.html#exploring-colorspace",
    "title": "Color scales and palettes",
    "section": "Exploring {colorspace}",
    "text": "Exploring {colorspace}\nFor a dynamic exploration use colorspace::hcl_wizard(), which is a {shiny} app . When you are done exploring, click the “Return to R” box.\n\nColor Picker\n{colorspace} also has a color picker function, colorspace::hclcolorpicker() which will allow you to pick color and obtain the hexidecimal color codes. You can also obtain html color names and rgb codes for colors at websites like htmlcolorcodes.com. With recent updates to RStudio, color names written as character strings when typed in the console or in files will display the color. Hint: you must type the names in lowercase (e.g., “mediumseagreen. If the color is not known by its name, then you won’t see the background string color change."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#discrete-qualitative-scales",
    "href": "modules/color_scales_and_palettes.html#discrete-qualitative-scales",
    "title": "Color scales and palettes",
    "section": "Discrete, qualitative scales",
    "text": "Discrete, qualitative scales\nDiscrete, qualitative scales are sometimes best set manually.\nAn example using default color palette:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Distance, y = Time, color = School)) +\n  geom_point(position = position_jitter()) +\n  scale_color_hue()\n\n\n\n\nNow consider the following plot.\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, y = Time, fill = Event)) + \n  geom_col() \n\n\n\n\nTo set the color, add a layer:\nFor the hue, scale_&lt;datatype&gt;_hue() could be scale_colour_hue() or scale_fill_hue(). The two function are listed below.\nscale_colour_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"colour\"\n)\n\nscale_fill_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"fill\"\n)\nWhen you are trying to customize a plot for a client or find issue with the color palettes out-of-the-box, scale_color_manual() or scale_fill_manual() are likely your best friends. As you see in the functions, you need to pass some color values. This is a vector of color by name or hexidecimal code.\nscale_colour_manual(\n  ...,\n  values,\n  aesthetics = \"colour\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\n\nscale_fill_manual(\n  ...,\n  values,\n  aesthetics = \"fill\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\nBut you need to know how values are mapped to subgroups. How many subgroups are there and what are they?\n\nglimpse(SWIM) \n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\nunique(SWIM$Event)\n\n[1] \"Medley\"       \"Freestyle\"    \"IM\"           \"Butterfly\"    \"Breaststroke\"\n[6] \"Backstroke\"  \n\n\nMake note of the order.\nThe order of the colors in the vector passes to values will map to the order of the levels in the data frame. We can demonstrate this by changing the data frame arrangement.\nSorting by ascending or descending order changes the data frame.\n\nSWIM %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 Freestyle   \n3 IM          \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\nSWIM %&gt;% arrange(., desc(Event)) %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 IM          \n3 Freestyle   \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\n\nSo how you sort the data frame matters, right? No. \nIs this vector a factor? Note, you can also see this using glimpse().\n\nis.factor(SWIM$Event)\n\n[1] FALSE\n\n\n\nglimpse(SWIM)\n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\n\nWhat are the levels?\n\nlevels(SWIM$Event)\n\nNULL\n\n\nThe levels() function will only return levels if the vector is a factor.\nLet’s change the variable in the data frame:\n\nSWIM &lt;- SWIM %&gt;% mutate(., Event = factor(Event))\n\n\nlevels(SWIM$Event)\n\n[1] \"Backstroke\"   \"Breaststroke\" \"Butterfly\"    \"Freestyle\"    \"IM\"          \n[6] \"Medley\"      \n\nnum_events &lt;- length(levels(SWIM$Event))\n\n\nis.ordered(SWIM$Event)\n\n[1] FALSE\n\n\nSo it is not an ordered factor but it does have an order and that order will affect the plot.\nThe colors in the vector passed to values will map onto the order of the levels as displayed by levels().\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#reverse-the-using-rev",
    "href": "modules/color_scales_and_palettes.html#reverse-the-using-rev",
    "title": "Color scales and palettes",
    "section": "Reverse the using rev()",
    "text": "Reverse the using rev()\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = rev(Event))) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nSomething is wrong. Double check your data and labels."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "href": "modules/color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "title": "Color scales and palettes",
    "section": "mutate() to change the order of levels",
    "text": "mutate() to change the order of levels\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                      ))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nOK, so we see that the color changes because the order of the levels changed. They are reordered in the plot legend."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "href": "modules/color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "title": "Color scales and palettes",
    "section": "mutate() to make it an ordered factor",
    "text": "mutate() to make it an ordered factor\nThe order of the labels does not make a factor ordered. We need to do something special to accomplish that, which we will do here. However, the example is arbitrary here as there is not order or ranking to how I arrange them.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           ordered = T)\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "href": "modules/color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "title": "Color scales and palettes",
    "section": "Change the labels for the levels",
    "text": "Change the labels for the levels\nPass a vector of equal length with label names.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           labels = c(\"Free\", \"Breast\", \"Fly\",\n                                      \"Back\", \"IM\", \"Medley\"))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nColors didn’t change but labels did."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#pair-a-color-with-a-level",
    "href": "modules/color_scales_and_palettes.html#pair-a-color-with-a-level",
    "title": "Color scales and palettes",
    "section": "Pair a Color with a Level",
    "text": "Pair a Color with a Level\nI’m not going to get into why this approach is actually a vector but you can test it if you want.\n\nis.vector(c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n            Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n            IM = \"maroon\", Medley = \"gray\"))\n\n[1] TRUE\n\n\nPass a vector of names and color values.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n               Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n               IM = \"maroon\", Medley = \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/color_scales_and_palettes.html#pass-a-vector-of-colors",
    "href": "modules/color_scales_and_palettes.html#pass-a-vector-of-colors",
    "title": "Color scales and palettes",
    "section": "Pass a vector of colors",
    "text": "Pass a vector of colors\nChanging the colors inside the function can be annoying so you might just create a vector object to pass to values.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\")\n  \nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\nVectors containing additional name elements\nIf that vector contains names that are not in the variable vector, then the function will not break. Rather, colors will show for level in the data only. We are going to save this plot object to use later.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\",\n                  SomethingNew = \"blue\"\n                  )\n\n(SWIM_plot &lt;- SWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n)\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nVectors missing name elements\nBut when names in the data vector are not in the color vector, something interesting happens.\n\n(color_vector &lt;- color_vector[1:3])\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nFirst, and most obviously, the missing pair is dropped from the legend. So the data points are stripped from the plot too, right? Look closer. No! They are in a there but plotting as \"grey50\". This happens because the default setting na.value = \"grey50\".\nThere is also no warning, so double check your plots!\nMore dramatically, show only the first color element.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[1])\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nThis approach can be useful if you want to color only certain events by their name. The goal would be to determine which color corresponds to the Freestyle and plot only that. But remember, there are names in the vector and color values.\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nnames(color_vector)\n\n[1] \"Freestyle\"    \"Breaststroke\" \"Butterfly\"   \n\n\nWe need to find out the color position corresponding to the name position Using which() we can evaluate the names to determine which position is the Freestyle.\n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nWhat we get returned is position 1. Of course, you knew that but something might change and if it moves position based on a reordering, then hard coding won’t work.\nTo obtain the color associated with element position 1, use [] notation after the vector.\n\ncolor_vector[1] # hard coded solution\n\nFreestyle \n\"#E69F00\" \n\ncolor_vector[which(names(color_vector) == \"Freestyle\")] # flexible solution\n\nFreestyle \n\"#E69F00\" \n\n\nPutting it all together, pass that to values:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) == \"Freestyle\")]\n    )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAnd if you wanted more than one event, evaluate with %in% rather than ==. For example, names(color_vector) %in% c(\"Freestyle\", \"Butterfly\").\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) %in% c(\"Freestyle\", \"Butterfly\"))]\n    )\n\nWarning: Removed 15 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html",
    "href": "modules/coordinates_axes_and_position_scales.html",
    "title": "Coordinates, axes, and position scales",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#readings",
    "href": "modules/coordinates_axes_and_position_scales.html#readings",
    "title": "Coordinates, axes, and position scales",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Coordinate Systems / Axes\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Position scales and axes"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#external-functions",
    "href": "modules/coordinates_axes_and_position_scales.html#external-functions",
    "title": "Coordinates, axes, and position scales",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#libraries",
    "href": "modules/coordinates_axes_and_position_scales.html#libraries",
    "title": "Coordinates, axes, and position scales",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#load-libraries",
    "href": "modules/coordinates_axes_and_position_scales.html#load-libraries",
    "title": "Coordinates, axes, and position scales",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#the-cartesian-coordinate-system",
    "href": "modules/coordinates_axes_and_position_scales.html#the-cartesian-coordinate-system",
    "title": "Coordinates, axes, and position scales",
    "section": "The Cartesian Coordinate System",
    "text": "The Cartesian Coordinate System\nThe coordinate system described above is that Cartesian coordinate system, within which locations are specified by positions on the x and y axis corresponding to specific values determined by x and y as single values or specified by sets of values belonging to x and y. Because axes themselves are lines and represent continuous position scales, they stretch in real numbers beyond 0 in both directions, resulting in four quadrants of the coordinate system. Thus, x and y axes can contain both positive and negative real numbers. The visualization, however, needs axis limits in order to define the space along x and y for the data to appear. As you are familiar, many plots limit x and y axes to a value of 0 on the low end and some other value on the upper end. Data that exist outside of the define plot axis limits will not be depicted in the plot.\nA plot depicting values from x and y variables from the same unit system should be visualized such that the interval between values along two axes is equivalent. For example, if x and y both represent quantities, the number of pixels separating 1 and 3 on the x axis should be equivalent on the y axis. In other words, the same number of data units along the x or y axis should correspond to the same distance on those axes. Violations of this representation occur and present perceptual distortions of the data. In some instances, for example, when the limits of the x and y axes are the same, the plot should take form as a square rather than rectangle with either the x or the y axis longer than the other.\nWhen the variables are on different scales, however, either x or y axis could be stretched or compressed for a different perspective depending on the goal so storytelling. As long as one is not trying to bias their audience in a way to mislead them, a favorable aspect ratio could be one with good aesthetics. A plot with balance is always appealing. Something too wide or too tall may just appear odd. In general, an aspect ratio should be chosen that communicates important aspects of differences in position are noticeable.\nWhen plots (e.g., geom_()s) use statistical transformations (e.g., jittering), you should consider carefully the influence of the data position relative to the actual data. Fine tuned these transformations to ensure the the visualize data are most true to the actual data to reduce bias."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#coordinate-functions-coord_",
    "href": "modules/coordinates_axes_and_position_scales.html#coordinate-functions-coord_",
    "title": "Coordinates, axes, and position scales",
    "section": "Coordinate Functions: coord_*()",
    "text": "Coordinate Functions: coord_*()\nThere are a variety of coord_() layer functions for . By default, plots already have a coord_cartesian() layer. Also, the x-axis is oriented horizontally and the y-axis is oriented vertically. By tradition, predictor variables assume the x-axis orientation, whereas outcome variables assume the y-axis.\n\ncoord_flip()\ncoord_flip() is used to flip the Cartesian coordinate system such that the x and y axis swap positions. Flipping may facilitate plot perception, for example, when bar length rather than height either makes more sense or supports comparisons. Outcome variables that are natively perceived in terms of length rather than height may also benefit from plotting the outcome variable along the x axis.\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  group_by(Event) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Event, y = Time)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\ncoord_fixed()\nWhen ensuring the aspect ratio of the coordinate system is important, coord_fixed() will prove helpful.\nThe most important parameter of the function is ratio, which by default is set to ratio = 1. The ratio represents the aspect ratio, expressed as y / x. Thus, the number of units on the y-axis that are equivalent to one unit on the x-axis. Thus, ratio = 1 ensures that one unit on the x-axis equates to 1 unit on the y-axis.\nYou can easily modify this to a different value, for example, 1.5, 2 or 10 to make the y axis longer than the x axis by this ratio. If you wish to make the y axis shorted, use a value or fraction to be less than 1 (e.g., 1/5). In addition, xlim and ylim parameters can be set in this layer.\nTo illustrate, let’s set the two axis limits to begin and end at the same values using xlim() and ylim(). Both require a two element vector. In addition, the default ratio is ratio = 1.\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  #coord_equal()\n  coord_fixed(ratio = 1)\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nSetting ratio = 2:\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  coord_fixed(ratio = 2)\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nYou see that the plot is now lengthened 2:1 in favor of the y-axis.\nBut the function might not work exactly as you expect. For example, if you axis limits are not set to be the same, but rather x is twice that of y, then a ratio of 1 behaves perhaps a little different from what you might think.\n\nexpand_plot &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point()\n\nnoexpand_plot &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  # do not expand axis (no padding))\n  coord_cartesian(expand = FALSE)\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(expand_plot, noexpand_plot, ncol = 1))\n)\n\n\n\n\nBe careful:\n\nnoexpand_plot2 &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  # do not expand axis (no padding))\n  #coord_cartesian(expand = FALSE) +\n  #coord_cartesian(expand = FALSE,\n  #                xlim = c(0, 40),\n  #                ylim = c(0, 80)\n  #                ) +\n  coord_fixed(ratio = 1, \n              xlim = c(0, 40), \n              ylim = c(0, 80)\n              )\n  #scale_y_continuous(expand = c(0, 0))\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(expand_plot, \n                           noexpand_plot,\n                           noexpand_plot2,\n                           ncol = 1))\n)\n\n\n\n\n\n\ncoord_equal()\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  coord_equal()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#nonlinear-scales",
    "href": "modules/coordinates_axes_and_position_scales.html#nonlinear-scales",
    "title": "Coordinates, axes, and position scales",
    "section": "Nonlinear scales",
    "text": "Nonlinear scales\nIn many cases, you will be trying to visualize data that are linear such that the numeric values of the variable map on to the same positions in space. The interval between numeric values is the same as the interval in physical space for the printed plot. In other cases, the interval between values may not be linear. For example, data that are converted to logarithms, square roots, cubes, etc. have one distance representing the actual numeric values (linear) and another distance corresponding to the values on the transformed scale (ordinal).\nWilke discusses several issues related to linear and nonlinear scales is his chapter covering axes. In particular, he discusses instances for presenting data as logarithms, how to plot the, and\nlog-transformed data, we can get confused about whether the data were transformed using the natural logarithm or the logarithm to base 10. And it’s not uncommon for labeling to be ambiguous, e.g. “log(x)”, which doesn’t specify a base at all. I recommend that you always verify the base when working with log-transformed data. When plotting log-transformed data, always specify the base in the labeling of the axis."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#examples-of-plots-with-axis-problems",
    "href": "modules/coordinates_axes_and_position_scales.html#examples-of-plots-with-axis-problems",
    "title": "Coordinates, axes, and position scales",
    "section": "Examples of Plots with Axis Problems",
    "text": "Examples of Plots with Axis Problems\nAs we have seen with some plots out-of-the-box, the tick marks along either the x or y axis are not suitable for favorable perceptual experiences. The user can be particularly strained with the height of the bar cannot be mapped to a value on the y-axis or a position along the x-axis cannot be mapped well to the bin. These problems are seen in these two simple examples.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 20) +\n  labs(title = \"bins = 20\",  \n       tag = \"A\",\n       )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 60) +\n  labs(title = \"bins = 60\",  \n       tag = \"B\",\n       )\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))\n\n\n\n\nThe previous modules are replete with plots containing this problem that compromises your ability to interpret the plot. At the time we introduced those plots, ways to address this problem were not introduced. This module addresses scale and axis adjustments."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#position-scale-types",
    "href": "modules/coordinates_axes_and_position_scales.html#position-scale-types",
    "title": "Coordinates, axes, and position scales",
    "section": "Position Scale Types",
    "text": "Position Scale Types\nAlthough there are several types of scales, the two most common are scales for continuous data or discrete data. The focus will be on changing them.\nscale_*_continuous()\nscale_*_discrete()"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#position-scales-for-continuous-data-scale__continuous",
    "href": "modules/coordinates_axes_and_position_scales.html#position-scales-for-continuous-data-scale__continuous",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for continuous data: scale_*_continuous()",
    "text": "Position scales for continuous data: scale_*_continuous()\nThe continuous scale:\nscale_y_continuous(\n  name = waiver(),\n  breaks = waiver(),\n  minor_breaks = waiver(),\n  n.breaks = NULL,\n  labels = waiver(),\n  limits = NULL,\n  expand = waiver(),\n  oob = censor,\n  na.value = NA_real_,\n  trans = \"identity\",\n  guide = waiver(),\n  position = \"left\",\n  sec.axis = waiver()\n)\n\nAxis limits\nIn general, axis limits specify where the axis should start and where is should end (what’s rendered is a little more complicated though).\nNotice there are four plots (e.g., A, B, C, and D). Examine them for differences in their bars. Plot D bars look different from the others beyond the obvious y-axis difference. The data passed to the geom for that plot are not what appear on the plot. After the plot was rendered, the x-axis was adjusted by adjusting its limits.\nA layer was added to the plot to set the limits scale_x_continuous(limits = c(0, 300)). Although there was no filtering of Time from the data frame, the limits were adjusted and the x-axis appears like Plots A, B, and C. Because the limits were adjusted after the statistical transformation took place in the geom, what you see is incorrect for the data. Whereas this approach presents no perceptual issue for most geoms, this approach will result in a misrepresentation of data for histogram plots displaying proportions or percentages. If you wish to present percentages, adjust the data frame a priori.\n\n\nTick Marks\nYou can specify where ticks appear along an axis by passing break specifications to breaks. Breaks also need corresponding labels. We will address both together because a label needs to exist for each of the breaks.\nWe can add breaks as a vector but remember that labels = scales::percent is just changing the rendering of the plot, not the actual values from the statistical transformation. You will need to pass a vector of proportions.\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent\n                     )\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent\n                     ) \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWait! Not all ticks are there. This is because geom_histogram() made adjustments to the plot by default. You will need to make sure the limits accommodate the breaks.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent,\n                     limits = c(0, .30)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nBut notice also that only certain breaks were specified. Whether intentional or unintentional, there is a 10% jump from 20% to 30%. This looks odd but perhaps that was intentional.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent,\n                     limits = c(0, .30)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#breaks-as-a-sequence-using-seq",
    "href": "modules/coordinates_axes_and_position_scales.html#breaks-as-a-sequence-using-seq",
    "title": "Coordinates, axes, and position scales",
    "section": "Breaks as a sequence using seq()",
    "text": "Breaks as a sequence using seq()\nUsing seq() we can specify the starting point (from) the ending point (to) and the step by which to create the sequence.\nFor example, seq(from = 0, to = .3, by = .05) will return 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3. We could also make the breaks sequence from 0 to 1 but if we truncate the limits, then you just won’t see them anyway. Just don’t truncate the bottom.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = seq(0, 1, by = .05),\n                     labels = scales::percent,\n                     limits = c(0, .20)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#break-labels",
    "href": "modules/coordinates_axes_and_position_scales.html#break-labels",
    "title": "Coordinates, axes, and position scales",
    "section": "Break labels",
    "text": "Break labels\nYou see that a labels adjustment has been added to the y-axis. This should suggest to you that you could pass your own break labels to either axis.\nFor example, we can just add a couple labels on the x-axis. Keep in mind that specifying labels will override other labeling by default.\n  scale_x_continuous(\n    breaks = c(100, 200),\n    label = c(\"100m\", \"Wow\")\n    )\nAnd we can make the labelling more clear along the y-axis but making the sequence step smaller.\n  scale_y_continuous(breaks = seq(0, 1, by = .02),\n                     labels = scales::percent,\n                     limits = c(0, .2)\n                     )\nWhich gives us:\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = seq(0, 1, by = .02),\n                     labels = scales::percent,\n                     limits = c(0, .2)\n                     ) +\n  scale_x_continuous(breaks = c(100, 200),\n                     label = c(\"100m\", \"Wow\")\n                     ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#position-scales-for-discrete-data-scale__discrete",
    "href": "modules/coordinates_axes_and_position_scales.html#position-scales-for-discrete-data-scale__discrete",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for discrete data: scale_*_discrete()",
    "text": "Position scales for discrete data: scale_*_discrete()\nA geom_*() that plots data for a categorical variable, will have a discrete x-axis.\ndiscrete_scale(\n  aesthetics,\n  scale_name,\n  palette,\n  name = waiver(),\n  breaks = waiver(),\n  labels = waiver(),\n  limits = NULL,\n  expand = waiver(),\n  na.translate = TRUE,\n  na.value = NA,\n  drop = TRUE,\n  guide = \"legend\",\n  position = \"left\",\n  super = ScaleDiscrete\n)\n\n\nLimits and Breaks\nWhen adjusting discrete limits, the limits correspond to the levels.\nscale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\n\nWarning: Removed 72 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nIf you try to adjust a discrete axis using scale_*_continuous(), you will get the following error.\nError: Discrete value supplied to continuous scale\nAnd breaks operate the same way so we can specify as vector here too.\nbreaks = c(\"Freestyle\", \"Butterfly\")\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_x_discrete(breaks = c(\"Freestyle\", \"Butterfly\"))\n\n\n\n\nThen select a subset by level:\nscale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\nAlternatively, if you don’t want to reference a long function like scale_x_discrete(), there are shorthand functions for limits which you could just add as layers to the plot.\n\nxlim(): a two-element vector with the start and end values\nylim(): a two-element vector with the start and end values\n\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  ylim(0, 600) +\n  xlim(\"Backstroke\" , \"Freestyle\", \"Butterfly\")\n\nWarning: Removed 57 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n#scale_x_discrete(breaks = c(\"Freestyle\", \"Butterfly\"))\n\nYou can also expand plot limits to ensure you include a value. For more, see expand_limits()."
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#other-scale-functions",
    "href": "modules/coordinates_axes_and_position_scales.html#other-scale-functions",
    "title": "Coordinates, axes, and position scales",
    "section": "Other Scale Functions",
    "text": "Other Scale Functions\nThere are many other scale_*_() functions you could apply.\nscale_x_sqrt(...)\nscale_y_sqrt(...)"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#reverse-a-continuous-scale",
    "href": "modules/coordinates_axes_and_position_scales.html#reverse-a-continuous-scale",
    "title": "Coordinates, axes, and position scales",
    "section": "Reverse a Continuous Scale",
    "text": "Reverse a Continuous Scale\nscale_x_reverse()\nscale_y_reverse()\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_y_reverse()"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#convert-to-log-scale",
    "href": "modules/coordinates_axes_and_position_scales.html#convert-to-log-scale",
    "title": "Coordinates, axes, and position scales",
    "section": "Convert to Log Scale",
    "text": "Convert to Log Scale\nWhenever you perform operations, you should know what the returned values with be. The default logging function, log(), calculates the natural log. Use log10() or log(base = 10) to calculate base 10 logs.\nscale_x_log10(...)\nscale_y_log10(...)\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  labs(title = \"default\",\n       tag = \"A\",\n  ) + coord_flip()\n\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_y_log10() +\n  labs(title = \"scale_y_log10()\",\n       tag = \"B\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))\n\n\n\n\nAlthough the data have been transformed, one problem is that that the labels are not fixed to match the transformation.\nWe can set breaks and labels in scale_y_log10() as we have done earlier. This steps is failry complicated. Just as we fixed labels for percents with scales::percent, the {scales} library offers assistance here as well. We can use scales::trans_breaks() and pass some arguments.\n   breaks = scales::breaks_log(n = 6, base = 10)\n   labels = labels = scales::label_log(digits = 2)\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  # create breaks and labels corresponding to the breaks \n  scale_y_log10(\n   breaks = scales::breaks_log(n = 6, base = 10),\n  ) + \n  labs(title = \"scale_y_log10() \",\n       subtitle = \"with with scales::breaks_log() \",\n       tag = \"C\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  # create breaks and labels corresponding to the breaks \n  scale_y_log10(\n   breaks = scales::breaks_log(n = 6, base = 10),\n   labels = scales::label_log(digits = 2)\n  ) + \n  labs(title = \"scale_y_log10()  \",\n       subtitle = \"with breaks and exponentiated labels\",\n       tag = \"D\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\n\n \nplot(gridExtra::arrangeGrob(plot3, plot4, ncol = 1))\n\n\n\n\nBut they still might not look right. We can control our axis breaks by creating a sequence of values that we pass to scale_x_log10(breaks = ?). Starting at 10 seconds, we square to obtain 9 values.\n\n10 * 2^seq(from = 0, to = 9, by = 1)\n\n [1]   10   20   40   80  160  320  640 1280 2560 5120\n\n\nWe can create a starting point by creating a new data frame and defining an object to hold the fastest time and then plug that into seq().\n\nSWIM_with_min &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  filter(Event == \"Freestyle\") %&gt;%\n  #filter(Distance == 200) %&gt;%\n  mutate(Distance = factor(Distance)) \n\nminTime &lt;- min(SWIM_with_min$Time)\nmaxTime &lt;- max(SWIM_with_min$Time)\n\n(plot5 &lt;- SWIM_with_min %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Distance)) +\n  geom_point(position = position_jitter()) +\n  # create breaks starting at 10 and then doubling\n  scale_y_log10(\n   breaks = minTime * 2^seq(from = 0, to = 9, by = 1),\n   #labels = scales::log_breaks(10)# label_log(digits = 2)\n  ) + \n  labs(title = \"scale_y_log10() with breaks sequence\",\n       subtitle = paste0(\"adjusted to fastest time of: \", minTime, \"s\"),\n       tag = \"E\",\n       y = \"log10(Time)\",\n       x = \"\"\n  ) \n)"
  },
  {
    "objectID": "modules/coordinates_axes_and_position_scales.html#position-scales-for-datetime-data",
    "href": "modules/coordinates_axes_and_position_scales.html#position-scales-for-datetime-data",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for date/time data",
    "text": "Position scales for date/time data\nThere area also scales for dealing with date and times. These can be used also in conjunction with breaks_pretty().\nscale_*_date()\nscale_*_time()"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html",
    "href": "modules/data_subsets_and_summaries.html",
    "title": "Data subsets and summaries",
    "section": "",
    "text": "This module demonstrates how to use {dplyr} to subset data, mutate variables, and summarize variables in data frames. Many data summaries involve creating group-level statistics so we will also cover grouping across variables. {lubridate} will be used to handle time vectors. Other functions covered with examples include openxlsx::read.xlsx(), readRDS() , saveRDS() , across(), relocate(), arrange(), and list() (for passing a list object to summarize()). Some elements are advanced topics related to preparing data in order to be summarized."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#supplemental-readings",
    "href": "modules/data_subsets_and_summaries.html#supplemental-readings",
    "title": "Data subsets and summaries",
    "section": "Supplemental Readings",
    "text": "Supplemental Readings\n\nData Transformation"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#task",
    "href": "modules/data_subsets_and_summaries.html#task",
    "title": "Data subsets and summaries",
    "section": "Task",
    "text": "Task\nWatch associated video(s) and review module content as necessary for exercises, homework, or projects."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#libraries",
    "href": "modules/data_subsets_and_summaries.html#libraries",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{lubridate} 1.9.3: for handling date and time vectors\n{openxlsx} 4.2.5.2: for reading .xlsx worksheets"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#external-functions",
    "href": "modules/data_subsets_and_summaries.html#external-functions",
    "title": "Data subsets and summaries",
    "section": "External Functions",
    "text": "External Functions\nProvided:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#libraries-1",
    "href": "modules/data_subsets_and_summaries.html#libraries-1",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(lubridate)"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#reading-.csv-files",
    "href": "modules/data_subsets_and_summaries.html#reading-.csv-files",
    "title": "Data subsets and summaries",
    "section": "Reading .csv files",
    "text": "Reading .csv files\nThis example is a walk through using the raw data file.\nWe will use here() to build and pass the file string as the argument to file and assign to an object named DAT. If column names are not in the file, modify the header argument. You could use dplyr::read_csv() also if you desire.\n\nDAT &lt;- read.csv(file = here::here(\"data\", \"raw\", \"cms-top-all-time-2023-swim.csv\"))"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#reading-.xlsx-files",
    "href": "modules/data_subsets_and_summaries.html#reading-.xlsx-files",
    "title": "Data subsets and summaries",
    "section": "Reading .xlsx files",
    "text": "Reading .xlsx files\nThis example is a walk through using the raw data file.\n\nWe will use here() to build and pass the file string to the xlxsFile argument and also pass sheet = \"swim\" so the swim worksheet is read from the file. If {openxlsx} is not loaded, call the function with reference to the library and assign to an object named DAT.\n\nDAT &lt;- openxlsx::read.xlsx(\n  xlsxFile = here::here(\"data\", \"raw\", \"cms-top-all-time-2023-swim.xlsx\"),\n  sheet = \"swim\"\n  )"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#looking-at-data",
    "href": "modules/data_subsets_and_summaries.html#looking-at-data",
    "title": "Data subsets and summaries",
    "section": "Looking at Data",
    "text": "Looking at Data\nIf data wrangling and cleaning skills are not needed, jump to summarizing. In order to prepare a data frame for summarizing, however, you need to ensure it is cleaned and saved.\nView its contents:\n\nhead(DAT)    # or view_html(DAT)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nWe have several variables: time, name, year, event, team. Some appear to be numeric and some are characters. Passing the data frame to dplyr::glimpse() will provide more detail (see also str()).\n\ndplyr::glimpse(DAT) # or DAT |&gt; dplyr::glimpse()\n\nRows: 440\nColumns: 5\n$ time  &lt;chr&gt; \"23.29\", \"23.31\", \"23.49\", \"23.71\", \"23.76\", \"23.77\", \"23.77\", \"…\n$ name  &lt;chr&gt; \"Jocelyn Crawford\", \"Ava Sealander\", \"Kelly Ngo\", \"Helen Liu\", \"…\n$ year  &lt;chr&gt; \"2019\", \"2022\", \"2016\", \"2014\", \"2014\", \"2020\", \"2020\", \"2010\", …\n$ event &lt;chr&gt; \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\"…\n$ team  &lt;chr&gt; \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Ath…\n\n\nHmm, looks like there are &lt;chr&gt; and &lt;dbl&gt; variables and some numbers are in quotes. Objects in quotes are strings. So we need to clean up the file before we can even get a summary. Other than looking at the structure of data frame using glimpse() or str(), you can examine vectors individually.\nWhen vectors are in data frames, you can reference them using the $ notation: my_dataframe$my_variable. Passing this to is.numeric() will also tell you whether the vector is numeric by returning either TRUE or FALSE.\n\nis.numeric(DAT$time)\n\n[1] FALSE\n\n\nOK, so this variable is definitely not numeric. Looking at the file, we need to convert at least one variable that should be numbers from character to numeric."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#creating-a-new-variable",
    "href": "modules/data_subsets_and_summaries.html#creating-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Creating a new variable",
    "text": "Creating a new variable\nWe will pass the data frame into mutate() and then specify a name-value variable pair. In order to keep the print out manageable, we will also use the slice() function.\nmutate(data_frame, \n       new_variable_name = variable\n       )\nCreate new variables that are set to a constant number or string:\n\nDAT |&gt;\n  slice(1:5) |&gt;   # rows 1 through 5\n  mutate(newvar1 = 9999) |&gt;\n  mutate(newvar2 = \"Student\") \n\n   time             name year   event   team newvar1 newvar2\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena    9999 Student\n2 23.31    Ava Sealander 2022 50 FREE Athena    9999 Student\n3 23.49        Kelly Ngo 2016 50 FREE Athena    9999 Student\n4 23.71        Helen Liu 2014 50 FREE Athena    9999 Student\n5 23.76      Michele Kee 2014 50 FREE Athena    9999 Student\n\n\nYou can see that each row in the data frame will take on the paired value."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#modifying-a-new-variable",
    "href": "modules/data_subsets_and_summaries.html#modifying-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Modifying a new variable",
    "text": "Modifying a new variable\nNew variables are modified using the same name-value pairing approach. When you modify a variable, you are taking an existing variable to setting it to another value.\n\nSet an existing variable equal to a constant\nJust use an existing variable name (left of = in name-value pair).\n\nDAT |&gt;\n  slice(1:5) |&gt;         # rows 1 through 5\n  mutate(time = 1) |&gt;\n  mutate(name = \"0\") \n\n  time name year   event   team\n1    1    0 2019 50 FREE Athena\n2    1    0 2022 50 FREE Athena\n3    1    0 2016 50 FREE Athena\n4    1    0 2014 50 FREE Athena\n5    1    0 2014 50 FREE Athena\n\n\nOK, that’s not very helpful. We just replaced our existing variables with nothing useful. You can see that name is still a &lt;chr&gt; type.\n\n\nSet an existing variable equal to another value\nAs long as {dplyr} can result the character elements of the vector, as.numeric() will convert the character strings to numbers. For example:\n\nas.numeric(c(\"1\", \"3.2\", \"6.99\"))\n\n[1] 1.00 3.20 6.99\n\n\nWe can illustrate in a data frame by creating character value that will serve as the constant, and use as.numeric() just to illustrate this example.\n\nDAT |&gt;\n  slice(1:5) |&gt;            # rows 1 through 5\n  mutate(name = as.numeric(\"0\")) \n\n   time name year   event   team\n1 23.29    0 2019 50 FREE Athena\n2 23.31    0 2022 50 FREE Athena\n3 23.49    0 2016 50 FREE Athena\n4 23.71    0 2014 50 FREE Athena\n5 23.76    0 2014 50 FREE Athena\n\n\nAnd now name is a &lt;dbl&gt;, which is a type of numeric. We can see this by selecting columns from the data frame where() the variable is.numeric().\n\nDAT |&gt;\n  slice(1:5) |&gt;   # rows 1 through 5\n  mutate(name = as.numeric(\"0\")) |&gt;\n  select(where(is.numeric))\n\n  name\n1    0\n2    0\n3    0\n4    0\n5    0\n\n\nBut if we try to convert time to numeric this way, you will see that the complex numbers will be converted to NAs, or missing.\n\nas.numeric(DAT$time)\n\nWarning: NAs introduced by coercion\n\n\n  [1] 23.29 23.31 23.49 23.71 23.76 23.77 23.77 23.87 23.93 24.02 51.05 51.24\n [13] 51.41 51.56 51.56 51.88 52.05 52.05 52.14 52.17    NA    NA    NA    NA\n [25]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [37]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [49]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [61] 55.66 55.67 55.91 56.11 56.74 56.83 57.18 57.36 57.47 57.56    NA    NA\n [73]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [85]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [97]    NA    NA    NA    NA 54.76 54.92 54.93 55.23 55.74 56.04 56.27 56.42\n[109] 56.47 56.56    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[121]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA 22.69 22.92\n[133] 22.93 22.95 23.27 23.31 23.33 23.38 23.45 23.47 50.65 50.67 50.92 51.19\n[145] 51.27 51.28 51.29 51.37 51.45 51.56    NA    NA    NA    NA    NA    NA\n[157]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[169]    NA    NA 25.94 26.22 26.28 26.57 26.82 26.90 27.14 27.14 27.16 27.17\n[181] 28.33 28.96 29.05 29.06 29.09 29.09 29.24 29.26 29.46 29.55 24.05 24.28\n[193] 24.58 24.59 24.65 24.85 25.05 25.08 25.24 25.34 54.65 54.81 54.91 55.11\n[205] 55.13 55.25 55.27 55.45 55.62 56.21    NA    NA    NA    NA    NA    NA\n[217]    NA    NA    NA    NA 19.98 20.21 20.22 20.36 20.51 20.65 20.69 20.71\n[229] 20.79 20.82 44.06 44.21 44.73 44.94 45.24 45.31 45.32 45.45 45.50 45.50\n[241]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[253]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[265]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[277]    NA    NA    NA    NA 46.99 47.57 49.32 49.97 50.03 50.29 50.35 50.41\n[289] 50.51 50.59    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[301] 54.88 55.80 55.92 56.03 56.27 56.35 56.36 56.45 56.49 56.49    NA    NA\n[313]    NA    NA    NA    NA    NA    NA    NA    NA 47.45 47.56 47.80 48.74\n[325] 48.91 49.26 49.31 49.34 49.68 49.74    NA    NA    NA    NA    NA    NA\n[337]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[349]    NA    NA 19.47 19.63 19.96 20.08 20.10 20.14 20.18 20.22 20.25 20.28\n[361] 43.28 43.69 43.74 44.43 44.57 44.59 44.81 44.81 44.83 44.87    NA    NA\n[373]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[385]    NA    NA    NA    NA    NA    NA 22.32 22.50 22.84 23.00 23.24 23.45\n[397] 23.72 23.74 23.85 23.87 24.73 24.81 24.88 25.10 25.20 25.47 25.55 25.63\n[409] 26.01 26.05 20.60 21.38 21.48 21.58 21.60 21.81 21.83 22.00 22.06 22.07\n[421] 47.01 47.72 48.39 48.50 48.54 48.82 49.00 49.45 49.52 49.60 54.52 55.15\n[433] 55.21 55.47 55.62 56.04 56.13 56.19 56.35 56.48\n\n\nThe problem we have is that the data are not in a clean form. In this data frame, some elements of time are composed of numbers, decimals, and colons (e.g., x.xx, xx:xx.xx, etc.). which all make up elements that would be numbers.\n\n\nConverting variables that are time related using {lubridate}\n{lubridate} is a library for dealing with dates and times. It is also part of the tidyverse} ecosystem. If it is not loaded, called the function by referencing the library name.\nThe period_to_seconds() function will convert periods to seconds depending on the period format. We need to pass to it an object that equates to a period of seconds.\nFor time, the format is: hour minute second (e.g., hms). And there is a hms() function to handle this. Let’s see how it works before modifying the data frame. Load the library if it is not loaded.\nWe will pass a single character string and convert it to hms with hms() and then convert that to seconds using period_to_seconds(). Because 60 minutes and 1 hour is the same number of seconds, we should end up with the same values. We can also use ms() to convert the format into minutes and seconds and pass to period_to_seconds(). Following the examples, we will apply to the vector in the data frame.\nperiod_to_seconds(lubridate::ms())\nperiod_to_seconds(lubridate::hms())\nSixty minutes and one hour to hms:\n\nhms(\"00:60:00\")\n\n[1] \"60M 0S\"\n\nhms(\"01:00:00\")\n\n[1] \"1H 0M 0S\"\n\n\nOne day to hms:\n\nhms(\"24:00:00\")\n\n[1] \"24H 0M 0S\"\n\n\nSixty minutes and one hour to hms to seconds:\n\nperiod_to_seconds(hms(\"00:60:00\"))\n\n[1] 3600\n\nperiod_to_seconds(hms(\"01:00:00\"))\n\n[1] 3600\n\n\nOK, good. So let’s see if we can convert time. Because hms() is passed into period_to_seconds(), we first need to verify that hms() can handle it.\n\nhms(DAT$time)\n\nWarning in .parse_hms(..., order = \"HMS\", quiet = quiet): Some strings failed\nto parse\n\n\n  [1] NA            NA            NA            NA            NA           \n  [6] NA            NA            NA            NA            NA           \n [11] NA            NA            NA            NA            NA           \n [16] NA            NA            NA            NA            NA           \n [21] \"1H 50M 30S\"  \"1H 51M 89S\"  \"1H 52M 40S\"  \"1H 52M 55S\"  \"1H 52M 57S\" \n [26] \"1H 52M 67S\"  \"1H 52M 80S\"  \"1H 52M 83S\"  \"1H 52M 88S\"  \"1H 52M 89S\" \n [31] \"4H 57M 37S\"  \"4H 59M 22S\"  \"4H 59M 78S\"  \"5H 0M 6S\"    \"5H 0M 21S\"  \n [36] \"5H 0M 47S\"   \"5H 1M 17S\"   \"5H 1M 99S\"   \"5H 2M 16S\"   \"5H 2M 23S\"  \n [41] \"10H 14M 33S\" \"10H 15M 40S\" \"10H 22M 59S\" \"10H 22M 84S\" \"10H 24M 14S\"\n [46] \"10H 24M 82S\" \"10H 26M 34S\" \"10H 26M 89S\" \"10H 33M 15S\" \"10H 36M 60S\"\n [51] \"16H 58M 48S\" \"17H 3M 21S\"  \"17H 6M 78S\"  \"17H 9M 9S\"   \"17H 9M 26S\" \n [56] \"17H 12M 18S\" \"17H 12M 46S\" \"17H 13M 58S\" \"17H 21M 98S\" \"17H 24M 49S\"\n [61] NA            NA            NA            NA            NA           \n [66] NA            NA            NA            NA            NA           \n [71] \"1H 59M 91S\"  \"2H 2M 10S\"   \"2H 3M 73S\"   \"2H 3M 85S\"   \"2H 3M 92S\"  \n [76] \"2H 5M 10S\"   \"2H 5M 56S\"   \"2H 5M 71S\"   \"2H 5M 76S\"   \"2H 6M 13S\"  \n [81] \"1H 1M 84S\"   \"1H 3M 28S\"   \"1H 3M 51S\"   \"1H 3M 91S\"   \"1H 4M 16S\"  \n [86] \"1H 4M 19S\"   \"1H 4M 65S\"   \"1H 4M 66S\"   \"1H 4M 77S\"   \"1H 4M 94S\"  \n [91] \"2H 14M 83S\"  \"2H 15M 62S\"  \"2H 18M 99S\"  \"2H 19M 6S\"   \"2H 19M 78S\" \n [96] \"2H 20M 1S\"   \"2H 21M 17S\"  \"2H 21M 77S\"  \"2H 22M 34S\"  \"2H 22M 83S\" \n[101] NA            NA            NA            NA            NA           \n[106] NA            NA            NA            NA            NA           \n[111] \"2H 1M 84S\"   \"2H 2M 58S\"   \"2H 3M 80S\"   \"2H 4M 5S\"    \"2H 4M 42S\"  \n[116] \"2H 4M 81S\"   \"2H 6M 40S\"   \"2H 7M 12S\"   \"2H 7M 33S\"   \"2H 7M 42S\"  \n[121] \"2H 0M 69S\"   \"2H 3M 59S\"   \"2H 3M 79S\"   \"2H 4M 74S\"   \"2H 5M 41S\"  \n[126] \"2H 6M 82S\"   \"2H 7M 12S\"   \"2H 7M 14S\"   \"2H 7M 81S\"   \"2H 7M 94S\"  \n[131] NA            NA            NA            NA            NA           \n[136] NA            NA            NA            NA            NA           \n[141] NA            NA            NA            NA            NA           \n[146] NA            NA            NA            NA            NA           \n[151] \"1H 50M 91S\"  \"1H 50M 98S\"  \"1H 51M 39S\"  \"1H 51M 41S\"  \"1H 51M 56S\" \n[156] \"1H 51M 64S\"  \"1H 51M 95S\"  \"1H 52M 53S\"  \"1H 52M 78S\"  \"1H 53M 4S\"  \n[161] \"4H 15M 73S\"  \"4H 27M 18S\"  \"4H 30M 33S\"  \"4H 30M 77S\"  \"4H 31M 96S\" \n[166] \"4H 32M 45S\"  \"4H 32M 57S\"  \"4H 32M 68S\"  \"4H 34M 16S\"  \"4H 34M 27S\" \n[171] NA            NA            NA            NA            NA           \n[176] NA            NA            NA            NA            NA           \n[181] NA            NA            NA            NA            NA           \n[186] NA            NA            NA            NA            NA           \n[191] NA            NA            NA            NA            NA           \n[196] NA            NA            NA            NA            NA           \n[201] NA            NA            NA            NA            NA           \n[206] NA            NA            NA            NA            NA           \n[211] \"1H 1M 10S\"   \"1H 2M 88S\"   \"1H 2M 89S\"   \"1H 3M 67S\"   \"1H 4M 10S\"  \n[216] \"1H 4M 16S\"   \"1H 4M 24S\"   \"1H 4M 26S\"   \"1H 4M 35S\"   \"1H 4M 43S\"  \n[221] NA            NA            NA            NA            NA           \n[226] NA            NA            NA            NA            NA           \n[231] NA            NA            NA            NA            NA           \n[236] NA            NA            NA            NA            NA           \n[241] \"1H 38M 35S\"  \"1H 38M 88S\"  \"1H 39M 7S\"   \"1H 39M 35S\"  \"1H 39M 63S\" \n[246] \"1H 39M 80S\"  \"1H 39M 82S\"  \"1H 40M 30S\"  \"1H 40M 31S\"  \"1H 40M 50S\" \n[251] \"4H 25M 67S\"  \"4H 28M 11S\"  \"4H 28M 89S\"  \"4H 29M 32S\"  \"4H 31M 64S\" \n[256] \"4H 32M 52S\"  \"4H 32M 65S\"  \"4H 32M 94S\"  \"4H 32M 98S\"  \"4H 34M 70S\" \n[261] \"9H 14M 11S\"  \"9H 24M 43S\"  \"9H 35M 78S\"  \"9H 36M 64S\"  \"9H 39M 27S\" \n[266] \"9H 40M 2S\"   \"9H 41M 48S\"  \"9H 45M 72S\"  \"9H 46M 63S\"  \"9H 47M 9S\"  \n[271] \"15H 17M 24S\" \"15H 32M 19S\" \"15H 45M 57S\" \"15H 47M 40S\" \"15H 52M 94S\"\n[276] \"15H 53M 75S\" \"15H 56M 57S\" \"15H 57M 89S\" \"16H 2M 45S\"  \"16H 3M 38S\" \n[281] NA            NA            NA            NA            NA           \n[286] NA            NA            NA            NA            NA           \n[291] \"1H 45M 5S\"   \"1H 45M 67S\"  \"1H 46M 51S\"  \"1H 48M 84S\"  \"1H 49M 1S\"  \n[296] \"1H 49M 38S\"  \"1H 50M 32S\"  \"1H 50M 43S\"  \"1H 51M 7S\"   \"1H 51M 57S\" \n[301] NA            NA            NA            NA            NA           \n[306] NA            NA            NA            NA            NA           \n[311] \"1H 59M 90S\"  \"2H 1M 18S\"   \"2H 1M 45S\"   \"2H 1M 60S\"   \"2H 1M 66S\"  \n[316] \"2H 1M 77S\"   \"2H 1M 78S\"   \"2H 2M 89S\"   \"2H 3M 19S\"   \"2H 3M 23S\"  \n[321] NA            NA            NA            NA            NA           \n[326] NA            NA            NA            NA            NA           \n[331] \"1H 43M 96S\"  \"1H 48M 70S\"  \"1H 49M 24S\"  \"1H 49M 95S\"  \"1H 49M 96S\" \n[336] \"1H 50M 34S\"  \"1H 50M 47S\"  \"1H 50M 49S\"  \"1H 50M 51S\"  \"1H 50M 76S\" \n[341] \"1H 46M 97S\"  \"1H 48M 74S\"  \"1H 49M 74S\"  \"1H 50M 51S\"  \"1H 50M 78S\" \n[346] \"1H 51M 11S\"  \"1H 51M 24S\"  \"1H 51M 48S\"  \"1H 51M 82S\"  \"1H 51M 83S\" \n[351] NA            NA            NA            NA            NA           \n[356] NA            NA            NA            NA            NA           \n[361] NA            NA            NA            NA            NA           \n[366] NA            NA            NA            NA            NA           \n[371] \"1H 37M 98S\"  \"1H 38M 49S\"  \"1H 39M 9S\"   \"1H 39M 19S\"  \"1H 39M 66S\" \n[376] \"1H 40M 21S\"  \"1H 40M 22S\"  \"1H 40M 44S\"  \"1H 40M 70S\"  \"1H 40M 70S\" \n[381] \"3H 55M 61S\"  \"3H 56M 68S\"  \"3H 56M 88S\"  \"3H 59M 2S\"   \"3H 59M 13S\" \n[386] \"3H 59M 17S\"  \"4H 0M 63S\"   \"4H 1M 14S\"   \"4H 2M 38S\"   \"4H 2M 99S\"  \n[391] NA            NA            NA            NA            NA           \n[396] NA            NA            NA            NA            NA           \n[401] NA            NA            NA            NA            NA           \n[406] NA            NA            NA            NA            NA           \n[411] NA            NA            NA            NA            NA           \n[416] NA            NA            NA            NA            NA           \n[421] NA            NA            NA            NA            NA           \n[426] NA            NA            NA            NA            NA           \n[431] NA            NA            NA            NA            NA           \n[436] NA            NA            NA            NA            NA           \n\n\nYikes! Note the warning and look at the output. Some strings failed and turned to NA. Looking and the time vector again, we see that contains both values like 1:52.83 and 23.87. If there is only one :, we should be able to use ms().\n\nms(DAT$time)\n\n  [1] \"23M 29S\"    \"23M 31S\"    \"23M 49S\"    \"23M 71S\"    \"23M 76S\"   \n  [6] \"23M 77S\"    \"23M 77S\"    \"23M 87S\"    \"23M 93S\"    \"24M 2S\"    \n [11] \"51M 5S\"     \"51M 24S\"    \"51M 41S\"    \"51M 56S\"    \"51M 56S\"   \n [16] \"51M 88S\"    \"52M 5S\"     \"52M 5S\"     \"52M 14S\"    \"52M 17S\"   \n [21] \"1M 50.3S\"   \"1M 51.89S\"  \"1M 52.4S\"   \"1M 52.55S\"  \"1M 52.57S\" \n [26] \"1M 52.67S\"  \"1M 52.8S\"   \"1M 52.83S\"  \"1M 52.88S\"  \"1M 52.89S\" \n [31] \"4M 57.37S\"  \"4M 59.22S\"  \"4M 59.78S\"  \"5M 0.06S\"   \"5M 0.21S\"  \n [36] \"5M 0.47S\"   \"5M 1.17S\"   \"5M 1.99S\"   \"5M 2.16S\"   \"5M 2.23S\"  \n [41] \"10M 14.33S\" \"10M 15.4S\"  \"10M 22.59S\" \"10M 22.84S\" \"10M 24.14S\"\n [46] \"10M 24.82S\" \"10M 26.34S\" \"10M 26.89S\" \"10M 33.15S\" \"10M 36.6S\" \n [51] \"16M 58.48S\" \"17M 3.21S\"  \"17M 6.78S\"  \"17M 9.09S\"  \"17M 9.26S\" \n [56] \"17M 12.18S\" \"17M 12.46S\" \"17M 13.58S\" \"17M 21.98S\" \"17M 24.49S\"\n [61] \"55M 66S\"    \"55M 67S\"    \"55M 91S\"    \"56M 11S\"    \"56M 74S\"   \n [66] \"56M 83S\"    \"57M 18S\"    \"57M 36S\"    \"57M 47S\"    \"57M 56S\"   \n [71] \"1M 59.91S\"  \"2M 2.1S\"    \"2M 3.73S\"   \"2M 3.85S\"   \"2M 3.92S\"  \n [76] \"2M 5.1S\"    \"2M 5.56S\"   \"2M 5.71S\"   \"2M 5.76S\"   \"2M 6.13S\"  \n [81] \"1M 1.84S\"   \"1M 3.28S\"   \"1M 3.51S\"   \"1M 3.91S\"   \"1M 4.16S\"  \n [86] \"1M 4.19S\"   \"1M 4.65S\"   \"1M 4.66S\"   \"1M 4.77S\"   \"1M 4.94S\"  \n [91] \"2M 14.83S\"  \"2M 15.62S\"  \"2M 18.99S\"  \"2M 19.06S\"  \"2M 19.78S\" \n [96] \"2M 20.01S\"  \"2M 21.17S\"  \"2M 21.77S\"  \"2M 22.34S\"  \"2M 22.83S\" \n[101] \"54M 76S\"    \"54M 92S\"    \"54M 93S\"    \"55M 23S\"    \"55M 74S\"   \n[106] \"56M 4S\"     \"56M 27S\"    \"56M 42S\"    \"56M 47S\"    \"56M 56S\"   \n[111] \"2M 1.84S\"   \"2M 2.58S\"   \"2M 3.8S\"    \"2M 4.05S\"   \"2M 4.42S\"  \n[116] \"2M 4.81S\"   \"2M 6.4S\"    \"2M 7.12S\"   \"2M 7.33S\"   \"2M 7.42S\"  \n[121] \"2M 0.69S\"   \"2M 3.59S\"   \"2M 3.79S\"   \"2M 4.74S\"   \"2M 5.41S\"  \n[126] \"2M 6.82S\"   \"2M 7.12S\"   \"2M 7.14S\"   \"2M 7.81S\"   \"2M 7.94S\"  \n[131] \"22M 69S\"    \"22M 92S\"    \"22M 93S\"    \"22M 95S\"    \"23M 27S\"   \n[136] \"23M 31S\"    \"23M 33S\"    \"23M 38S\"    \"23M 45S\"    \"23M 47S\"   \n[141] \"50M 65S\"    \"50M 67S\"    \"50M 92S\"    \"51M 19S\"    \"51M 27S\"   \n[146] \"51M 28S\"    \"51M 29S\"    \"51M 37S\"    \"51M 45S\"    \"51M 56S\"   \n[151] \"1M 50.91S\"  \"1M 50.98S\"  \"1M 51.39S\"  \"1M 51.41S\"  \"1M 51.56S\" \n[156] \"1M 51.64S\"  \"1M 51.95S\"  \"1M 52.53S\"  \"1M 52.78S\"  \"1M 53.04S\" \n[161] \"4M 15.73S\"  \"4M 27.18S\"  \"4M 30.33S\"  \"4M 30.77S\"  \"4M 31.96S\" \n[166] \"4M 32.45S\"  \"4M 32.57S\"  \"4M 32.68S\"  \"4M 34.16S\"  \"4M 34.27S\" \n[171] \"25M 94S\"    \"26M 22S\"    \"26M 28S\"    \"26M 57S\"    \"26M 82S\"   \n[176] \"26M 90S\"    \"27M 14S\"    \"27M 14S\"    \"27M 16S\"    \"27M 17S\"   \n[181] \"28M 33S\"    \"28M 96S\"    \"29M 5S\"     \"29M 6S\"     \"29M 9S\"    \n[186] \"29M 9S\"     \"29M 24S\"    \"29M 26S\"    \"29M 46S\"    \"29M 55S\"   \n[191] \"24M 5S\"     \"24M 28S\"    \"24M 58S\"    \"24M 59S\"    \"24M 65S\"   \n[196] \"24M 85S\"    \"25M 5S\"     \"25M 8S\"     \"25M 24S\"    \"25M 34S\"   \n[201] \"54M 65S\"    \"54M 81S\"    \"54M 91S\"    \"55M 11S\"    \"55M 13S\"   \n[206] \"55M 25S\"    \"55M 27S\"    \"55M 45S\"    \"55M 62S\"    \"56M 21S\"   \n[211] \"1M 1.1S\"    \"1M 2.88S\"   \"1M 2.89S\"   \"1M 3.67S\"   \"1M 4.1S\"   \n[216] \"1M 4.16S\"   \"1M 4.24S\"   \"1M 4.26S\"   \"1M 4.35S\"   \"1M 4.43S\"  \n[221] \"19M 98S\"    \"20M 21S\"    \"20M 22S\"    \"20M 36S\"    \"20M 51S\"   \n[226] \"20M 65S\"    \"20M 69S\"    \"20M 71S\"    \"20M 79S\"    \"20M 82S\"   \n[231] \"44M 6S\"     \"44M 21S\"    \"44M 73S\"    \"44M 94S\"    \"45M 24S\"   \n[236] \"45M 31S\"    \"45M 32S\"    \"45M 45S\"    \"45M 50S\"    \"45M 50S\"   \n[241] \"1M 38.35S\"  \"1M 38.88S\"  \"1M 39.07S\"  \"1M 39.35S\"  \"1M 39.63S\" \n[246] \"1M 39.8S\"   \"1M 39.82S\"  \"1M 40.3S\"   \"1M 40.31S\"  \"1M 40.5S\"  \n[251] \"4M 25.67S\"  \"4M 28.11S\"  \"4M 28.89S\"  \"4M 29.32S\"  \"4M 31.64S\" \n[256] \"4M 32.52S\"  \"4M 32.65S\"  \"4M 32.94S\"  \"4M 32.98S\"  \"4M 34.7S\"  \n[261] \"9M 14.11S\"  \"9M 24.43S\"  \"9M 35.78S\"  \"9M 36.64S\"  \"9M 39.27S\" \n[266] \"9M 40.02S\"  \"9M 41.48S\"  \"9M 45.72S\"  \"9M 46.63S\"  \"9M 47.09S\" \n[271] \"15M 17.24S\" \"15M 32.19S\" \"15M 45.57S\" \"15M 47.4S\"  \"15M 52.94S\"\n[276] \"15M 53.75S\" \"15M 56.57S\" \"15M 57.89S\" \"16M 2.45S\"  \"16M 3.38S\" \n[281] \"46M 99S\"    \"47M 57S\"    \"49M 32S\"    \"49M 97S\"    \"50M 3S\"    \n[286] \"50M 29S\"    \"50M 35S\"    \"50M 41S\"    \"50M 51S\"    \"50M 59S\"   \n[291] \"1M 45.05S\"  \"1M 45.67S\"  \"1M 46.51S\"  \"1M 48.84S\"  \"1M 49.01S\" \n[296] \"1M 49.38S\"  \"1M 50.32S\"  \"1M 50.43S\"  \"1M 51.07S\"  \"1M 51.57S\" \n[301] \"54M 88S\"    \"55M 80S\"    \"55M 92S\"    \"56M 3S\"     \"56M 27S\"   \n[306] \"56M 35S\"    \"56M 36S\"    \"56M 45S\"    \"56M 49S\"    \"56M 49S\"   \n[311] \"1M 59.9S\"   \"2M 1.18S\"   \"2M 1.45S\"   \"2M 1.6S\"    \"2M 1.66S\"  \n[316] \"2M 1.77S\"   \"2M 1.78S\"   \"2M 2.89S\"   \"2M 3.19S\"   \"2M 3.23S\"  \n[321] \"47M 45S\"    \"47M 56S\"    \"47M 80S\"    \"48M 74S\"    \"48M 91S\"   \n[326] \"49M 26S\"    \"49M 31S\"    \"49M 34S\"    \"49M 68S\"    \"49M 74S\"   \n[331] \"1M 43.96S\"  \"1M 48.7S\"   \"1M 49.24S\"  \"1M 49.95S\"  \"1M 49.96S\" \n[336] \"1M 50.34S\"  \"1M 50.47S\"  \"1M 50.49S\"  \"1M 50.51S\"  \"1M 50.76S\" \n[341] \"1M 46.97S\"  \"1M 48.74S\"  \"1M 49.74S\"  \"1M 50.51S\"  \"1M 50.78S\" \n[346] \"1M 51.11S\"  \"1M 51.24S\"  \"1M 51.48S\"  \"1M 51.82S\"  \"1M 51.83S\" \n[351] \"19M 47S\"    \"19M 63S\"    \"19M 96S\"    \"20M 8S\"     \"20M 10S\"   \n[356] \"20M 14S\"    \"20M 18S\"    \"20M 22S\"    \"20M 25S\"    \"20M 28S\"   \n[361] \"43M 28S\"    \"43M 69S\"    \"43M 74S\"    \"44M 43S\"    \"44M 57S\"   \n[366] \"44M 59S\"    \"44M 81S\"    \"44M 81S\"    \"44M 83S\"    \"44M 87S\"   \n[371] \"1M 37.98S\"  \"1M 38.49S\"  \"1M 39.09S\"  \"1M 39.19S\"  \"1M 39.66S\" \n[376] \"1M 40.21S\"  \"1M 40.22S\"  \"1M 40.44S\"  \"1M 40.7S\"   \"1M 40.7S\"  \n[381] \"3M 55.61S\"  \"3M 56.68S\"  \"3M 56.88S\"  \"3M 59.02S\"  \"3M 59.13S\" \n[386] \"3M 59.17S\"  \"4M 0.63S\"   \"4M 1.14S\"   \"4M 2.38S\"   \"4M 2.99S\"  \n[391] \"22M 32S\"    \"22M 50S\"    \"22M 84S\"    \"23M 0S\"     \"23M 24S\"   \n[396] \"23M 45S\"    \"23M 72S\"    \"23M 74S\"    \"23M 85S\"    \"23M 87S\"   \n[401] \"24M 73S\"    \"24M 81S\"    \"24M 88S\"    \"25M 10S\"    \"25M 20S\"   \n[406] \"25M 47S\"    \"25M 55S\"    \"25M 63S\"    \"26M 1S\"     \"26M 5S\"    \n[411] \"20M 60S\"    \"21M 38S\"    \"21M 48S\"    \"21M 58S\"    \"21M 60S\"   \n[416] \"21M 81S\"    \"21M 83S\"    \"22M 0S\"     \"22M 6S\"     \"22M 7S\"    \n[421] \"47M 1S\"     \"47M 72S\"    \"48M 39S\"    \"48M 50S\"    \"48M 54S\"   \n[426] \"48M 82S\"    \"49M 0S\"     \"49M 45S\"    \"49M 52S\"    \"49M 60S\"   \n[431] \"54M 52S\"    \"55M 15S\"    \"55M 21S\"    \"55M 47S\"    \"55M 62S\"   \n[436] \"56M 4S\"     \"56M 13S\"    \"56M 19S\"    \"56M 35S\"    \"56M 48S\"   \n\n\nGreat! All elements are in the form of \"xxM XXs\". But does {lubridate} also convert seconds to a numeric value when using period_to_seconds()? If loaded, we can also remove the name of the library when calling the functions.\n\nis.numeric(period_to_seconds(ms(DAT$time)))\n\n[1] TRUE\n\n\nSo let’s go ahead and modify the character vector named time to a numeric vector representing seconds.\n\nperiod_to_seconds(ms(DAT$time))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\n\n\nPerfect! Let’s mutate() that variable in the data frame.\n\nDAT |&gt;\n  slice(1:5) |&gt;   # rows 1 through 5\n  mutate(time = period_to_seconds(ms(time)))  \n\n  time             name year   event   team\n1 1409 Jocelyn Crawford 2019 50 FREE Athena\n2 1411    Ava Sealander 2022 50 FREE Athena\n3 1429        Kelly Ngo 2016 50 FREE Athena\n4 1451        Helen Liu 2014 50 FREE Athena\n5 1456      Michele Kee 2014 50 FREE Athena\n\n\nLet’s look at DAT now and see those seconds. You can look at the entire data frame if you wish rather than its head().\n\nhead(DAT)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nThe data frame has not changed. The final step is to assign assign the returned data frame to an object. Remove the slice() so we get the entire data frame.\n\nDAT &lt;- DAT |&gt;\n  mutate(time = period_to_seconds(ms(time)))  \n\nNow let’s write this to /data/processed as a .Rds file using saveRDS().\n\nhere::here(\"data\", \"processed\", \"cms-top-all-time-2023-swim.Rds\")\n\n[1] \"C:/Users/gcook/Sync/git/dataviz/dataviz24/data/processed/cms-top-all-time-2023-swim.Rds\"\n\n\nLooks good. Pass the data frame and a file name arguments to object and file, respectively.\n\nsaveRDS(object = DAT, \n        file = here::here(\"data\", \"processed\", \"cms-top-all-time-2023-swim.Rds\")\n        )\n\nVerify your file it the directory.\n\n\nReading Processed Data\nOnce you have modified a data frame and saved in a processed directory, you will want to read it for other project tasks. Although the DAT object is available in this case, it will not be available in other scripts. This example demonstrates reading the processed file from /data/processed and assigning to an object. Because this file is a .Rds file, we will use readRDS() to read it.\n\nDAT &lt;- readRDS(file = here::here(\"data\", \"processed\", \"cms-top-all-time-2023-swim.Rds\"))\n\nNOTE: Clearly, the DAT object is the same as it was before reading it but you typically will not have objects available in .R scripts unless the script defines it. The main exception is when a .R script reads another script file (aka source()) that defines the object."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "href": "modules/data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "title": "Data subsets and summaries",
    "section": "Summarize across by numeric variables:",
    "text": "Summarize across by numeric variables:\n\nDAT |&gt;\n  summarise(across(.cols = where(is.numeric),\n                   .fns  = ~mean(.x, na.rm = TRUE)\n                   )\n            )\n\n      time\n1 1309.388\n\n\nWell, that’s now actually impressive because there is only one numeric variable. What if we had more that were piped to summarize()?\n\nDAT |&gt;\n  mutate(num1 = time,\n         num2 = time,\n         num3 = time\n         ) |&gt;\n  summarise(across(.cols = where(is.numeric), \n                   .fns  = ~mean(.x, na.rm = TRUE)\n                   )\n            )\n\n      time     num1     num2     num3\n1 1309.388 1309.388 1309.388 1309.388\n\n\nThat was easy.\nBecause across() is so powerful, let’s just add another variable to the data frame for using in examples. You might also wish to reorder the position of variables in the data frame so that they are grouped in some way. We can use dplyr::relocate() to accomplish this. We will move the time column to the position .before one of the new variables using relocate(time, .before = min).\nDoing so will also show you some ways to create variables.\n\nDAT &lt;- DAT |&gt;\n  mutate(sec = time,      # will be redundant with time but named accurately\n         min  = time/60,\n         hour = time/(60*60)\n         ) |&gt;\n  relocate(time, .before = sec)\n\nTake a look:\n\nhead(DAT)\n\n              name year   event   team time  sec      min      hour\n1 Jocelyn Crawford 2019 50 FREE Athena 1409 1409 23.48333 0.3913889\n2    Ava Sealander 2022 50 FREE Athena 1411 1411 23.51667 0.3919444\n3        Kelly Ngo 2016 50 FREE Athena 1429 1429 23.81667 0.3969444\n4        Helen Liu 2014 50 FREE Athena 1451 1451 24.18333 0.4030556\n5      Michele Kee 2014 50 FREE Athena 1456 1456 24.26667 0.4044444\n6 Natalia Orbach-M 2020 50 FREE Athena 1457 1457 24.28333 0.4047222\n\n\nVariable names created with across() is controlled using the .names argument. The default is equivalent to .names = {.col}, which means that the name(s) are inherited from the .cols argument; the names are a stand-in for the name specification. If you wish to have control over the names, you can pass a string that that either appends (e.g.,\"{.col}suffix\") or prepends (e.g.,\"prefix{.col}\") a string to each column name. This string looks odd because it’s a special glue specification that glues together with a string with an object. We will use this concept later when using the {glue} library.\nWhen modifying .names, include a character like \"_\" (e.g.,\"{.col}_suffix\") so that the column names and the appended text are separated, making the name easily legible. If you summarize to create means, a good suggestion is something like (e.g.,\"{.col}_mean\" or (e.g.,\"{.col}_mn\")) so that you know the variable is a mean. If you prefer the function name first, you can use a prefix (e.g.,\"mean_{.col}\").\n\nDAT |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\", \"hour\"), \n                   .fns  = ~mean(.x, na.rm = TRUE),\n                   .names = \"{.col}_mean\"\n                   )\n            )\n\n  sec_mean min_mean hour_mean\n1 1309.388 21.82313 0.3637189\n\n\nYou can see how all variables in the summary end in \"_mean\".\nYou can also glue the function and the column names together by passing .names = \"{.col}_{.fn}\".\n\nDAT |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\", \"hour\"), \n                   .fns  = ~mean(.x, na.rm = TRUE),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            )\n\n     sec_1    min_1    hour_1\n1 1309.388 21.82313 0.3637189\n\n\nYou you will see there is a number that is appended to the variable name. This is because there is only one function passed to .fns. You can pass more using a special object called a list (see ?list). Unlike vectors, elements of lists need not be the same kind. Elements of lists can combinations of characters, numbers, data frames, functions, etc."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "href": "modules/data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "title": "Data subsets and summaries",
    "section": "Passing multiple functions from a list() in across()",
    "text": "Passing multiple functions from a list() in across()\nPassing functions as a list requires a little fancy coding. We will pass two functions as a list so that we can calculate both the mean() and the sd() on the variables passed to across().\nA list is a special object (e.g., container) for which its elements can be different types of objects. Whereas elements of vectors can be only character or only numeric, elements of lists can hold different object. One element can be a numeric vector, another element a data frame, another element a character vector, etc. Many functions used in R will actually return lists for which elements contain different types of objects.\nOK back to two or more functions. If you pass a list() with arguments for the mean and the sd (e.g., list(mean, sd), you can summarize by both. If you want to prevent errors (yes you do) and want to keep the summaries separate (probably so), you can modify .names to pass both the column and the function (e.g., \"{.col}_{.fn}\"). The underscore is not needed here; it only helps with readability of the variables so that you don’t end up with variable names like var1mean but instead var1_mean.\nLet’s pass the summary procedures as a list to include measures of mean and standard deviation for the variables.\n\nDAT |&gt;\n  summarise(across(.cols  = c(\"sec\", \"min\", \"hour\"), \n                   .fns   = list(mean, sd),\n                   .names = \"{.col}_{.fn}\")\n            )\n\n     sec_1    sec_2    min_1    min_2    hour_1    hour_2\n1 1309.388 1225.964 21.82313 20.43274 0.3637189 0.3405456\n\n\nWell those are not exactly the names we want but it illustrates how names are created. Because we have two summary functions for each column variable passed to across(), they are enumerated according to the order in the list (e.g., mean then standard deviation).\n\nFixing .names when passing lists to .cols in across()\nEnumeration is not helpful for remembering variable names. There are different ways to do fix this problem, some of which may be better under certain scenarios. You have to determine what approach is best but I’ll lay out some limitations. If you pass only the functions into the list, then when you pass {.fn} to .names, the variable names in the returned data frame will take on a numeric value representing the order/element position of the functions as you entered them in the list. In this coding instance, means would be named with\"_1\" and standard deviation names with \"_2\". This approach, however, leads to confusing variable names because you have to remember which is 1 and which is 2 and of course explain this to anyone with whom you share the data. Let’s take a look.\nA better approach could be to assign the mean and sd functions their own names in the list() function call. By doing so, the name is appended and the new variable is named meaningfully.\nLet’s modify what we pass to .fns by passing a list containing 3 functions (e.g., mean(), sd(), and length()) and give each there name. I know this part is confusing because the () are dropped inside the list. This is just how R works. Don’t blame the messenger.\n\nDAT |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\", \"hour\"), \n                   .fns  = list(mean = mean, \n                                sd = sd,\n                                n = length\n                                ),\n                   .names = \"{.col}_{.fn}\")\n            )\n\n  sec_mean   sec_sd sec_n min_mean   min_sd min_n hour_mean   hour_sd hour_n\n1 1309.388 1225.964   440 21.82313 20.43274   440 0.3637189 0.3405456    440\n\n\nImportantly, however, certain functions like mean() will operate in ways you might not expect. One one hand, it does what we expect when all elements can be used to calculate the mean.\n\nmean(DAT$time)\n\n[1] 1309.388\n\n\nOn the other hand, if there is a missing value, it does not computer the mean but instead something else. Let’s add an NA to the vector using c() to see what happens.\n\nmean(c(DAT$time, NA))\n\n[1] NA\n\n\n\nUnderstanding NAs when passing lists to .cols in across()\nThe mean() function returns NA rather than a mean. If there is just one NA, mean() returns NA. By design this is actually good.\nLet’s also try sd() for the standard deviation of a vector:\n\nsd(c(DAT$time, NA))\n\n[1] NA\n\n\nThe median of a vector, median():\n\nmedian(c(DAT$time, NA))\n\n[1] NA\n\n\nThe length of a vector, length():\n\nlength(c(DAT$time, NA))\n\n[1] 441\n\n\nWell, that’s interesting. By default length() will return the number of elements of the vector including NAs but by default mean() will not return the mean of a vector with NAs because na.rm = FALSE by default. If you wish to calculate the mean by removing the NAs, pass na.rm = TRUE.\n\nmean(c(DAT$time, NA), na.rm = T)\n\n[1] 1309.388\n\n\nMake note, however, that the length of this vector without NAs is shorter than the length with NAs. We can test this hypothesis on a vector with and without the NA by using na.omit() to omit any of them. Using our vector we added an NA, let’s omit it.\n\nna.omit(c(DAT$time, NA))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\nattr(,\"na.action\")\n[1] 441\nattr(,\"class\")\n[1] \"omit\"\n\n\nAnd then get the length when NAs are omitted:\n\nlength(na.omit(c(DAT$time, NA)))\n\n[1] 440\n\n\nThis behavior is important because if you want to obtain the mean of a variable with NAs and the sample size using length(), your sample size will be inaccurate.\nIn order to see these operations on a data frame and in the context of dplyr::summarize(), let’s modify the data frame to make the values for sec and min in row be NA. The data frame will then contain some missing values. We can use dplyr::case_when() for the conditional rather than if.else() or if_else().\nDoes this look right?\n\nDAT |&gt;\n  mutate(across(.cols = c(sec, min),        # for these columns\n                .fns = ~case_when(\n                  row_number() == 1 ~ NA,   # make this one NA\n                  row_number() != 1 ~ .x    # keep it original \n                  )\n                )\n         ) |&gt;\n  head()\n\n              name year   event   team time  sec      min      hour\n1 Jocelyn Crawford 2019 50 FREE Athena 1409   NA       NA 0.3913889\n2    Ava Sealander 2022 50 FREE Athena 1411 1411 23.51667 0.3919444\n3        Kelly Ngo 2016 50 FREE Athena 1429 1429 23.81667 0.3969444\n4        Helen Liu 2014 50 FREE Athena 1451 1451 24.18333 0.4030556\n5      Michele Kee 2014 50 FREE Athena 1456 1456 24.26667 0.4044444\n6 Natalia Orbach-M 2020 50 FREE Athena 1457 1457 24.28333 0.4047222\n\n\nYes, row one has NA values, so let’s clobber DAT with this new version. Remove the pipe to head() of course.\n\nDAT &lt;-\n  DAT |&gt;\n  mutate(across(.cols = c(sec, min),        # for these columns\n                .fns = ~case_when(\n                  row_number() == 1 ~ NA,   # make this one NA\n                  row_number() != 1 ~ .x    # keep it original \n                  )\n                )\n         )\n\n\n\nComparing some functionality when passing lists to .cols in across()\nWhen functions do not contain arguments for dealing with NAs, there is na.omit(), a function that takes an object and removes NAs. You can just pass the variable to na.omit() and then wrap it in the metric function of interest. Also, because na.rm = T cannot be used for length(), na.omit() offers consistency across all functions and as a result, I believe, less confusion.\nUnfortunately, accomplishing this task can be rather tricky and requires some new syntax. This requires usage of what’s called a “lambda” technique. You will want to incorporate ~ and .x into your code. The ~ is used to indicate that you are supplying a lambda function and use of .x is to indicate where the variable in across() is used. Using this type of syntax, we can pass functions to the .fns argument that operate across a set of variables. The ?across() documentation calls this “a {purrr}-style lambda” in the arguments section. This approach can be a little bit confusing, so I’m going to show you an example, and then walk through it step by step. You can always create code snippets so you don’t have to rely on memory write complicated code like this.\nAnyway, we will precede the function with ~ and reference the vector using .x. Let’s do this and change the .fns argument slightly.\nHere is a general example:\nname = ~function(na.omit(.x))\nWe will summarize only time and sec because those variables are identical except for the row we added. We will also add dplyr::n() to see what’s going on with that function.\n\nDAT |&gt;\n  summarise(across(.cols = c(\"time\", \"sec\"), \n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                len  = ~length(na.omit(.x)),\n                                n    = ~dplyr::n()\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n  time_mean time_len time_n sec_mean sec_len sec_n\n1  1309.388      440    440 1309.161     439   440\n\n\nSo what happened? The means and lengths for time and sec are not the same. Means differ because they are calculated by different values depending on the presence of NAs. But notice that the n’s are the same based on dplyr::n(). How can the means and differ if the n’s are the same?\nSo what’s the point of all of this? Well, you need to be careful not to apply functions and assume they are doing what you believe you are doing. You always need to be smarter than the code you use. Also, there is no single answer for dealing with data. Sometimes one approach will be appropriate and in other instances another approach will be. You as the data scientist need to know that there are different methods so that you an decide where to apply those different methods."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "href": "modules/data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize by Groups Using group_by()",
    "text": "Summarize by Groups Using group_by()\n\nIdentifying how to group\nWhen you have subgroups in your data, you will often want to create summary statistics by those group levels. A typical grouping approach is by some categorical or factor variable present in a data frame. Using glympse(), we can view all variables to see what might be of interest.\n\nglimpse(DAT)\n\nRows: 440\nColumns: 8\n$ name  &lt;chr&gt; \"Jocelyn Crawford\", \"Ava Sealander\", \"Kelly Ngo\", \"Helen Liu\", \"…\n$ year  &lt;chr&gt; \"2019\", \"2022\", \"2016\", \"2014\", \"2014\", \"2020\", \"2020\", \"2010\", …\n$ event &lt;chr&gt; \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\"…\n$ team  &lt;chr&gt; \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Ath…\n$ time  &lt;dbl&gt; 1409.00, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1…\n$ sec   &lt;dbl&gt; NA, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1467.0…\n$ min   &lt;dbl&gt; NA, 23.516667, 23.816667, 24.183333, 24.266667, 24.283333, 24.28…\n$ hour  &lt;dbl&gt; 0.39138889, 0.39194444, 0.39694444, 0.40305556, 0.40444444, 0.40…\n\n\nLooks like some factor variables we can group by include name, year, event, and team."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "href": "modules/data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize A (one) Specific Variable by Groups Using group_by()",
    "text": "Summarize A (one) Specific Variable by Groups Using group_by()\n\nA single summary metric\nPerhaps you only want to obtain the mean() or the sum() or the sd() for a variable. If so, this is easiest.\n\nGrouping by one variable:\nThe data contain the top records for swimming events. You might be curious what year was the best of all time or what swimmer (e.g., name) has attained the most records of all time. There are different ways to accomplish this goal.\nOne approach that might be the most straight forward to new programmers is to mutate a constant count variable on each row which can be used to sum the counts for different groups.\n\nDAT |&gt;\n  mutate(count = 1) |&gt;         # mutate a new variable where all rows get a 1\n  group_by(name) |&gt;            # group by the swimmer name\n  summarise(count = sum(count)) # sum the count and assign it the name count\n\n# A tibble: 141 × 2\n   name            count\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 A Breazeale         8\n 2 A Roeseler          2\n 3 Aaron Lutzker       6\n 4 Abel Sapirstein     1\n 5 Alec Vercruysse     4\n 6 Alex Mendoza        2\n 7 Alex Poltash        6\n 8 Allyson Yao         3\n 9 Amy Fuller          1\n10 Andrew Cox          4\n# ℹ 131 more rows\n\n\nBy default, the data frame is arranged by the grouping variable (e.g., name). We can change the order of the rows by count using arrange() but this function by default sorts in an ascending manner. If you want a descending sorting, pass count to desc() to arrange the data frame in this way. We can also assign it to an object.\n\nNAME_count &lt;- DAT |&gt;\n  mutate(count = 1) |&gt;\n  group_by(name) |&gt;\n  summarise(count = sum(count)) |&gt;\n  arrange(desc(count))\n\n\nNAME_count\n\n# A tibble: 141 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Michele Kee      11\n 2 Augusta Lewis    10\n 3 Matt Williams    10\n 4 Kelly Ngo         9\n 5 A Breazeale       8\n 6 Ava Sealander     8\n 7 Gary Simon        8\n 8 Marco Conati      8\n 9 Nic Tekieli       7\n10 Aaron Lutzker     6\n# ℹ 131 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee for a total of 11. Kudos to Michele!\n\nYEAR_count &lt;- DAT |&gt;\n  mutate(count = 1) |&gt;\n  group_by(year) |&gt;\n  summarise(count = sum(count)) |&gt;\n  arrange(desc(count))\n\n\nYEAR_count\n\n# A tibble: 32 × 2\n   year  count\n   &lt;chr&gt; &lt;dbl&gt;\n 1 2022     81\n 2 2023     59\n 3 2020     41\n 4 2017     38\n 5 2014     27\n 6 2013     22\n 7 2019     22\n 8 2015     20\n 9 2016     17\n10 2018     16\n# ℹ 22 more rows\n\n\nWe can see that the year with the most best are by 2022 for a total of 81. Hooray for 2022!\n\n\nGrouping by two or more variables:\nWe can also summarize both the teams as well in order to see the top swimmer by team. If you want to summarize more than one variable, pass them both in group_by():\n\nTEAM_NAME_count &lt;- DAT |&gt;\n  mutate(count = 1) |&gt;\n  group_by(team, name) |&gt;\n  summarise(count = sum(count)) |&gt;\n  arrange(desc(count))\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n\nTEAM_NAME_count\n\n# A tibble: 141 × 3\n# Groups:   team [2]\n   team   name          count\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;\n 1 Athena Michele Kee      11\n 2 Athena Augusta Lewis    10\n 3 Stag   Matt Williams    10\n 4 Athena Kelly Ngo         9\n 5 Athena Ava Sealander     8\n 6 Stag   A Breazeale       8\n 7 Stag   Gary Simon        8\n 8 Stag   Marco Conati      8\n 9 Stag   Nic Tekieli       7\n10 Athena Ella Blake        6\n# ℹ 131 more rows\n\n\n\n\nFiltering rows and then grouping by one variable:\nFor Athenas:\n\nATHENA_NAME_count &lt;- DAT |&gt;\n  mutate(count = 1) |&gt;\n  filter(team == \"Athena\") |&gt;\n  group_by(name) |&gt;\n  summarise(count = sum(count)) |&gt;\n  arrange(desc(count))\n\n\nATHENA_NAME_count\n\n# A tibble: 66 × 2\n   name               count\n   &lt;chr&gt;              &lt;dbl&gt;\n 1 Michele Kee           11\n 2 Augusta Lewis         10\n 3 Kelly Ngo              9\n 4 Ava Sealander          8\n 5 Ella Blake             6\n 6 Jamee Mitchum          6\n 7 Katie Bilotti          6\n 8 Mackenzie Mayfield     6\n 9 Annika Jessen          5\n10 Jocelyn Crawford       5\n# ℹ 56 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee with a total of 11. Nice work Michele!\nAnd for Stags:\n\nSTAG_NAME_count &lt;- DAT |&gt;\n  mutate(count = 1) |&gt;\n  filter(team == \"Stag\") |&gt;\n  group_by(name) |&gt;\n  summarise(count = sum(count)) |&gt;\n  arrange(desc(count))\n\n\nSTAG_NAME_count\n\n# A tibble: 75 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Matt Williams    10\n 2 A Breazeale       8\n 3 Gary Simon        8\n 4 Marco Conati      8\n 5 Nic Tekieli       7\n 6 Aaron Lutzker     6\n 7 Alex Poltash      6\n 8 Blake Weber       6\n 9 Sam Willett       5\n10 Tom Harrison      5\n# ℹ 65 more rows\n\n\nWe can see that the top counts of all time are by Matt Williams with 10. Go Matt!\nTo wrap up this example, sometimes working with separate data frames using filter() can provide more useful or manageable summaries.Perhaps you only want to obtain the mean() or the sum() or the sd() for a single variable. If so, this approach may be easiest.\nIf you are curious, here is a story covering “How CMS teams became the Stags and Athenas”.\n\n\n\nMultiple summary metrics\nSometimes you need more than one summary statistic, for example, the mean() and the sd(). This is a little more complex to code.\nNote: In these code blocks, some arguments may be removed for readability.\n\nGrouping by one variable:\n\nDAT |&gt;\n  group_by(event) |&gt;\n  summarise(sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\nWe can also write the summary functions as a list inside across() along with passing .names = \"{.col}_{.fn}\" if you want the variables named automatically. This approach is more complex but is more flexible.\nWhen you want to summarize across multiple variables using a list of functions, you will want to make sure your .fns argument passes a function using a {purrr}-style lambda (e.g.,~) for that the function is applied across the variables. You will also want to edit .names = \"{.col}_{.fn}\" so that the naming is done automatically rather than hard coding the names.\n\nDAT |&gt;\n  group_by(event) |&gt;\n  summarise(across(.cols = \"sec\",\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                median = ~median(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT |&gt;\n  group_by(event, team) |&gt;\n  summarise(sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows\n\n\nOr pass the list:\n\nDAT |&gt;\n  group_by(event, team) |&gt;\n  summarise(across(.cols = \"sec\",\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                median = ~median(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "href": "modules/data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables by Groups Using group_by()",
    "text": "Summarizing Multiple Variables by Groups Using group_by()\nSo far, we have shown how to summarize a single variable either with or without grouping by levels of another variable. Summaries, however, are often done for multiple variables in data frame. For example, you might want to obtain the mean() for multiple variables or obtain the mean() and the max() (or some other summary statistic) for multiple variables. The following examples prepare you for such tasks.\n\nA single summary metric\n\nGrouping by one variable:\n\nDAT |&gt;\n  group_by(event) |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\"),\n                   .fns = ~mean(.x, na.rm = T),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_1 min_1\n   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            3209. 53.5 \n 2 100 BREAST          1725. 28.8 \n 3 100 BRST-Relay Spl. 1710. 28.5 \n 4 100 FLY             3158. 52.6 \n 5 100 FLY-Relay Spl.  3135. 52.2 \n 6 100 FREE            2917. 48.6 \n 7 100 FREE-Relay Spl. 2888. 48.1 \n 8 1000 FREE            601. 10.0 \n 9 1650 FREE            990. 16.5 \n10 200 BACK             116.  1.94\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT |&gt;\n  group_by(event, team) |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\"),\n                   .fns = ~mean(.x, na.rm = T),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team    sec_1 min_1\n   &lt;chr&gt;               &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            Athena 3421.  57.0 \n 2 100 BACK            Stag   2996.  49.9 \n 3 100 BREAST          Athena   64.0  1.07\n 4 100 BREAST          Stag   3386.  56.4 \n 5 100 BRST-Relay Spl. Athena   63.6  1.06\n 6 100 BRST-Relay Spl. Stag   3356.  55.9 \n 7 100 FLY             Athena 3365.  56.1 \n 8 100 FLY             Stag   2950.  49.2 \n 9 100 FLY-Relay Spl.  Athena 3332.  55.5 \n10 100 FLY-Relay Spl.  Stag   2938.  49.0 \n# ℹ 34 more rows\n\n\n\n\n\nMultiple summary metrics\nAnd if you need to summarize using multiple metrics, then pass the list into .fns:\n\nGrouping by one variable:\n\nDAT |&gt;\n  group_by(event) |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\"),\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                median = ~median(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n# A tibble: 22 × 5\n   event               sec_mean sec_median min_mean min_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.    53.5       53.5 \n 2 100 BREAST             1725.      1696.    28.8       28.3 \n 3 100 BRST-Relay Spl.    1710.      1678.    28.5       28.0 \n 4 100 FLY                3158.      3165     52.6       52.8 \n 5 100 FLY-Relay Spl.     3135.      3152.    52.2       52.5 \n 6 100 FREE               2917.      2908.    48.6       48.5 \n 7 100 FREE-Relay Spl.    2888.      2896     48.1       48.3 \n 8 1000 FREE               601.       601.    10.0       10.0 \n 9 1650 FREE               990.       991.    16.5       16.5 \n10 200 BACK                116.       116.     1.94       1.93\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT |&gt;\n  group_by(event, team) |&gt;\n  summarise(across(.cols = c(\"sec\", \"min\"),\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                median = ~median(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   event [22]\n   event               team   sec_mean sec_median min_mean min_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436      57.0       57.3 \n 2 100 BACK            Stag     2996.      3032      49.9       50.5 \n 3 100 BREAST          Athena     64.0       64.2     1.07       1.07\n 4 100 BREAST          Stag     3386.      3394.     56.4       56.6 \n 5 100 BRST-Relay Spl. Athena     63.6       64.1     1.06       1.07\n 6 100 BRST-Relay Spl. Stag     3356.      3363      55.9       56.0 \n 7 100 FLY             Athena   3365.      3369      56.1       56.2 \n 8 100 FLY             Stag     2950.      2968.     49.2       49.5 \n 9 100 FLY-Relay Spl.  Athena   3332.      3326      55.5       55.4 \n10 100 FLY-Relay Spl.  Stag     2938.      2937      49.0       49.0 \n# ℹ 34 more rows\n\n\nDepends on the order in group_by(), so change the order:\n\nDAT |&gt;\n  group_by(team, event) |&gt;\n  summarise(across(.cols = \"sec\",\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                n = ~length(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK              3421.     10\n 2 Athena 100 BREAST              64.0    10\n 3 Athena 100 BRST-Relay Spl.     63.6    10\n 4 Athena 100 FLY               3365.     10\n 5 Athena 100 FLY-Relay Spl.    3332.     10\n 6 Athena 100 FREE              3115.     10\n 7 Athena 100 FREE-Relay Spl.   3088.     10\n 8 Athena 1000 FREE              625.     10\n 9 Athena 1650 FREE             1031.     10\n10 Athena 200 BACK               124.     10\n# ℹ 34 more rows\n\n\nNotice the change in the order of the column variables. But remember, you can change the order later using select() and/or relocate()."
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "href": "modules/data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables With Reference by Name`",
    "text": "Summarizing Multiple Variables With Reference by Name`\n\nVariables that are numeric\nYou can also pass variables that are a certain type, like numeric.\n\nDAT |&gt;\n  group_by(team, event) |&gt;\n  summarise(across(.cols = where(is.numeric), \n                   .fns = ~mean(.x, na.rm = TRUE), \n                   .names = \"{.col}\")\n            )\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event                 time    sec   min   hour\n   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Athena 100 BACK            3421.  3421.  57.0  0.950 \n 2 Athena 100 BREAST            64.0   64.0  1.07 0.0178\n 3 Athena 100 BRST-Relay Spl.   63.6   63.6  1.06 0.0177\n 4 Athena 100 FLY             3365.  3365.  56.1  0.935 \n 5 Athena 100 FLY-Relay Spl.  3332.  3332.  55.5  0.926 \n 6 Athena 100 FREE            3115.  3115.  51.9  0.865 \n 7 Athena 100 FREE-Relay Spl. 3088.  3088.  51.5  0.858 \n 8 Athena 1000 FREE            625.   625.  10.4  0.174 \n 9 Athena 1650 FREE           1031.  1031.  17.2  0.286 \n10 Athena 200 BACK             124.   124.   2.07 0.0345\n# ℹ 34 more rows\n\n\n\n\nVariables by pattern match\nThis approach is fun, especially if you have already named variables in ways that make selection really useful. This data frame is constrained a bit so the examples may be silly.\n\nUsing starts_with()\n\nDAT |&gt;\n  group_by(team, event) |&gt;\n  summarise(across(.cols = starts_with(\"t\"),\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                n = ~length(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               time_mean time_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;\n 1 Athena 100 BACK               3421.      10\n 2 Athena 100 BREAST               64.0     10\n 3 Athena 100 BRST-Relay Spl.      63.6     10\n 4 Athena 100 FLY                3365.      10\n 5 Athena 100 FLY-Relay Spl.     3332.      10\n 6 Athena 100 FREE               3115.      10\n 7 Athena 100 FREE-Relay Spl.    3088.      10\n 8 Athena 1000 FREE               625.      10\n 9 Athena 1650 FREE              1031.      10\n10 Athena 200 BACK                124.      10\n# ℹ 34 more rows\n\n\n\n\nUsing & for complex selection\nYou obviously cannot calculate numeric metrics for character variables. But how might you select variables that contain a certain character pattern but are also numeric? You cannot nest these functions (e.g., where(is.numeric(contains(\"pattern\")))). You can, however, pass the functions separately.\n\nDAT |&gt;\n  group_by(team, event) |&gt;\n  summarise(across(.cols = contains(\"e\") & where(is.numeric),\n                   .fns  = list(mean = ~mean(na.omit(.x)),\n                                n = ~length(na.omit(.x))\n                                ),\n                   .names = \"{.col}_{.fn}\"\n                   )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event               time_mean time_n sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK               3421.      10   3421.     10\n 2 Athena 100 BREAST               64.0     10     64.0    10\n 3 Athena 100 BRST-Relay Spl.      63.6     10     63.6    10\n 4 Athena 100 FLY                3365.      10   3365.     10\n 5 Athena 100 FLY-Relay Spl.     3332.      10   3332.     10\n 6 Athena 100 FREE               3115.      10   3115.     10\n 7 Athena 100 FREE-Relay Spl.    3088.      10   3088.     10\n 8 Athena 1000 FREE               625.      10    625.     10\n 9 Athena 1650 FREE              1031.      10   1031.     10\n10 Athena 200 BACK                124.      10    124.     10\n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/data_subsets_and_summaries.html#a-functional-approach",
    "href": "modules/data_subsets_and_summaries.html#a-functional-approach",
    "title": "Data subsets and summaries",
    "section": "A Functional Approach",
    "text": "A Functional Approach\nYou can also throw your summaries into functions if you wish. We will create a new object that is a function object. We need to give it a name and we need to define arguments to make the function operate. We will want to make sure we have numeric variables.\n\nsummarizer &lt;- function(data, \n                       cols = NULL, \n                       ...\n                       ) {\n  data |&gt;\n    group_by(...) |&gt;\n    summarise(across(.cols = {{cols}} & where(is.numeric),\n                     .fns = list(\n                       mean = ~mean(.x, na.rm = TRUE),\n                       sd   = ~sd(.x, na.rm = TRUE)\n                       ), \n                     .names = \"{col}_{fn}\")\n              )\n}\n\nTest the function:\nWithout grouping:\n\nsummarizer(DAT, cols = contains(\"e\"))\n\n# A tibble: 1 × 4\n  time_mean time_sd sec_mean sec_sd\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     1309.   1226.    1309.  1227.\n\n\nWith grouping:\n\nsummarizer(DAT, cols = c(min, hour), event)\n\n# A tibble: 22 × 5\n   event               min_mean min_sd hour_mean hour_sd\n   &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 100 BACK               53.5   3.76     0.891  0.0626 \n 2 100 BREAST             28.8  28.4      0.479  0.473  \n 3 100 BRST-Relay Spl.    28.5  28.1      0.475  0.469  \n 4 100 FLY                52.6   3.63     0.877  0.0605 \n 5 100 FLY-Relay Spl.     52.2   3.44     0.871  0.0573 \n 6 100 FREE               48.6   3.43     0.810  0.0571 \n 7 100 FREE-Relay Spl.    48.1   3.46     0.802  0.0576 \n 8 1000 FREE              10.0   0.432    0.167  0.00719\n 9 1650 FREE              16.5   0.728    0.275  0.0121 \n10 200 BACK                1.94  0.136    0.0324 0.00227\n# ℹ 12 more rows\n\n\nAnd of course, when you really get excited, you could add functions so that you can perform different metrics. When you are done, you can save your favorite function to a file you can source()."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "",
    "text": "Complete the Corresponding Canvas Video.\n\nOptional Readings about {ggplot}:\n\nWilke (2019). Fundamentals of Data Visualization. Introduction to Vizualization\nWilke (2019). Fundamentals of Data Visualization. Aesthetic Mapping\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Introduction\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Understanding the Grammar\n\nOptional (more on the grammar):\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Build a plot layer by layer"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#readings",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#readings",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "",
    "text": "Complete the Corresponding Canvas Video.\n\nOptional Readings about {ggplot}:\n\nWilke (2019). Fundamentals of Data Visualization. Introduction to Vizualization\nWilke (2019). Fundamentals of Data Visualization. Aesthetic Mapping\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Introduction\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Understanding the Grammar\n\nOptional (more on the grammar):\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Build a plot layer by layer"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#external-functions",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#external-functions",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "External Functions",
    "text": "External Functions\nProvided:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "{ggplot} Plot Composition",
    "text": "{ggplot} Plot Composition\nThere are five mapping components:\n\nLayer containing geometric elements and statistical transformations:\n\n\nData a tidy data frame, most typically in long/narrow format\nMapping defining how vector variables are visualized (e.g., aesthetics like shape, color, position, hue, etc.)\nStatistical Transformation (stat) representing some summarizing of data (e.g., sums, fitted curves, etc.)\nGeometric object (geom) controlling the type of visualization\nPosition Adjustment (position) controlling where visual elements are positioned\n\n\nScales that map values in the data space to values in aesthetic space\nA Coordinate System for mapping coordinates to the plane of a graphic\nA Facet for arranging the data into a grid; plotting subsets of data\nA Theme controlling the niceties of the plot, like font, background, grids, axes, typeface etc.\n\nThe grammar does not:\n\nMake suggestions about what graphics to use\nDescribe interactivity with a graphic; {ggplot2} graphics are static images, though they can be animated"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Initializing the Plot Object",
    "text": "Initializing the Plot Object\nIf you don’t pass a data frame to data, what happens?\n\nggplot()\n\n\n\n\nA plot object is created but it contains no data. The default is some rectangle in space. You will need to specify data to use for the the plot and add an argument to data."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Passing the Data to ggplot()",
    "text": "Passing the Data to ggplot()\nYou cannot have a plot without data, so we need some data in a tidy format. We can read in a data set or create one.\n\nSWIM &lt;- read.csv(here::here(\"data\",  \"processed\", \"cleaned-cms-top-all-time-2023-swim.csv\"))\n\n\nLet’s also quickly change the variable names to titlecase() so that the first letter is capitalized. Why? When variables appear in plots, you may wish for them to be plot ready. In many instances, you will want them looking a certain way. Changing them before passing them to ggplot() will be most ideal.\n\ntools::toTitleCase(names(SWIM))\n\n[1] \"Time\"  \"Name\"  \"Year\"  \"Event\" \"Team\" \n\n\nWe can also see that elements in the Year variable are not quite right.\n\nunique(SWIM$year) |&gt;\n  sort()\n\n [1] \"13/14\" \"1982\"  \"1983\"  \"1985\"  \"1986\"  \"1987\"  \"1988\"  \"1995\"  \"1996\" \n[10] \"1997\"  \"1998\"  \"1999\"  \"2000\"  \"2001\"  \"2002\"  \"2004\"  \"2005\"  \"2006\" \n[19] \"2009\"  \"2010\"  \"2011\"  \"2012\"  \"2013\"  \"2014\"  \"2015\"  \"2016\"  \"2017\" \n[28] \"2018\"  \"2019\"  \"2020\"  \"2022\"  \"2023\" \n\n\nTo rename variables with {dplyr}, use rename_with() and pass a function to .fn. The function will be tools::toTitleCase without the parentheses. While we are at it, let’s fix the incorrect year.\n\nSWIM &lt;- \n  SWIM |&gt;\n  rename_with(.fn = tools::toTitleCase) |&gt;\n  mutate(Year = case_when(\n    Year == \"13/14\" ~ \"2013\", \n    TRUE ~ Year\n    ))\n\nLooks right now.\n\nSWIM |&gt;\n  pull(Year) |&gt;\n  unique() |&gt;\n  sort()\n\n [1] \"1982\" \"1983\" \"1985\" \"1986\" \"1987\" \"1988\" \"1995\" \"1996\" \"1997\" \"1998\"\n[11] \"1999\" \"2000\" \"2001\" \"2002\" \"2004\" \"2005\" \"2006\" \"2009\" \"2010\" \"2011\"\n[21] \"2012\" \"2013\" \"2014\" \"2015\" \"2016\" \"2017\" \"2018\" \"2019\" \"2020\" \"2022\"\n[31] \"2023\"\n\n\nNow that you have data, pass this data frame to data.\n\nggplot(data = SWIM)\n\n\n\n\nOK, so still nothing. That’s because we haven’t told ggplot() what visual properties or aesthetics to include in the plot. Importantly, you do not have to provide this information in a base layer. {ggplot2} is flexible insofar as you can pass data in different places depending what data you want to use and at which layer on how you will use it.\nIf you set data = SWIM, the subsequent layers of the plot will inherit that data frame if you do not pass the argument in a different layer. However, you are not limited to passing only one data set. You might wish to plot the aesthetics of one data frame in one layer and then add another layer of aesthetics taken from a different data frame. TLDR; you can pass data, or not pass data, in the initialization of the base layer."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Scaling/Scale Transformation",
    "text": "Scaling/Scale Transformation\n\nSWIM |&gt; \n  head()\n\n  Time             Name Year   Event   Team\n1 1409 Jocelyn Crawford 2019 50 FREE Athena\n2 1411    Ava Sealander 2022 50 FREE Athena\n3 1429        Kelly Ngo 2016 50 FREE Athena\n4 1451        Helen Liu 2014 50 FREE Athena\n5 1456      Michele Kee 2014 50 FREE Athena\n6 1457 Natalia Orbach-M 2020 50 FREE Athena\n\n\nLooking at the data, we have a tidy file composed of columns and rows. Looking at the data frame, you see the “identity” of each case. This term is important to {ggplot}. By identity we mean variables are a numeric value, character, or factor as they are represented in the data passed to ggplot(). What you see in the data frame is the identity of the variable. Of course, we can change the identity of a variable in some way by transforming the values to z scores, log values, or each average them together to take their count and then plot any of those data. But those transformations do not represent true identities as they appear in a data set.\nIn order to take the data units in the data frame so that they can be represented as physical units on a plot (e.g., points, bars, lines, etc.), there needs to be some scaling transformation. The plot function needs to understand how many pixels high and wide to create a plot and the plot needs to know the limits of the axes for example. Similarly, the plot function needs to know what shapes to present, how many, etc. By default, the statistical transformation is an “identity” transformation, or one that just takes the values and plots them as their appear in the data (their identity). More on this when we start plotting."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Choosing a Coordinate System",
    "text": "Choosing a Coordinate System\nAll we have now is the base layer that is taking on some coordinates. For example, where are the points plotted on the plot? The system can follow the Cartesian coordinate system or a Polar coordinate system. An example of this will follow later. For now, the default is chosen for you. What might you think it is?"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Adding Aesthetic Mappings",
    "text": "Adding Aesthetic Mappings\nIf you wanted your plot geometry (the geom_*() you add later) to inherit properties of the initialized base layer, you could pass aesthetics to the mapping argument mapping = aes() in the ggplot() function. Notice that the argument that we pass to mapping is another function, aes().\nFor example:\n\nggplot(data = SWIM, \n       mapping = aes()\n       )\n\n\n\n\nBut this still does not present anything you can see. You might have guessed that the reason you do not see anything is because nothing was passed to aes(). Here is where you map data to aesthetics by specifying the variable information and passing them to aes(). Looking at ?aes, we see that aes() maps how properties of the data connect to, or map, onto with the features of the visualization (e.g., axis position, color, size, etc.). The aesthetics are the visual properties of the visualization, so they are essential to map by passing arguments to aes().\nHow many and what variables do pass? Looking at ?aes, you see that x and y are needed.\nBecause we passed data = SWIM in ggplot(), we can reference the variables by their column names without specifying the data frame.\nIf x = Year and y = Time:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       )\n\n\n\n\nOK, now we can see something. Although this is progress, what is visible is rather empty and ugly. We can see that the aesthetic layer now applied to the plot scales the data to present Year along the x-axis with a range from lowest to highest value from that vector. Similarly, the mapping presents Time along the y-axis with a range from lowest to highest value in the vector. Also, the aesthetics include the variable name as a the label for the x and y axes. Of course, you can change these details later in a layer as well. More on that later.\nYou might have been tempted to pass the variable names a quoted strings (e.g., “A” and “B) but if you do that, you’ll get something different.\n\nggplot(data = SWIM, \n       mapping = aes(x = \"Year\", y = \"Time\")\n       )\n\n\n\n\nIf we want to plot the data as they are in the data frame, we would apply the ‘identity’ transformation. Again, by identity, we just need to instruct ggplot() to use the data values in the data frame. If you wanted to plot the means, frequency count, or something else, we would need to tell ggplot() how to transform the data. We are not at that point yet though."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Adding Plot Geometries",
    "text": "Adding Plot Geometries\nWe do not yet have any geometries, or geoms, added. All geom functions will take the form geom_*(). As you will see, geoms can take many forms, including, points, lines, bars, text, etc. If we want the values in Year and Time to be plotted as x and y coordinates representing points on the plot, we can add a point geometry using geom_point().\nBy adding a layer, {ggplot2} really means add, as in +. We will take the initialize plot object that contains some data along with some mapping of variables to x an y coordinates and add to it a geometry. Combined, these functions will display data which adheres to some statistical transformation at some position along some scale an in some theme.\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\n\n\n\nAt some point, you will want to assign the plot to an object. When you do, the plot will not actually render for you to view.\n\nmy_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\nThen:\n\nmy_first_plot\n\n\n\n\nPro Tip: You would need to call the plot to render it as illustrated above … unless you wrap it in ().\n\n(my_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point())\n\n\n\n\nYou now have a data visualization! The points geometry, geom_point(), inherits the aesthetic mapping from above and plots them as points."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "How and Where to Map Aesthetics?",
    "text": "How and Where to Map Aesthetics?\nYou might be wondering how you map these aesthetic properties so that when you attempt to do so, you don’t get a bunch of errors. There are two places you can map aesthetics:\nEither in the initialized plot object:\n\nggplot(data = data, mapping = aes(x, y)) + geom_point()\n\nOr in the geometry:\n\nggplot() +geom_point(data = data, mapping = aes(x, y))\n\nWe can map aesthetics in the initialized plot object by also assigning this to an object named base_plot just so we can reference it as need.\nWhen we do this mapping:\n\nbase_plot &lt;- ggplot(data = SWIM, \n                    mapping = aes(Year, Time)\n                    )\n\nThe aesthetics are inherited by the geometries that follow, which then do not require any mapping of their own…\n\nmap + \n  geom_point() + \n  geom_line()\n\nNULL\n\n\nBut when aesthetics are NOT mapped in initialized plot:\n\nbase_plot &lt;- ggplot() \n\nThere are no aesthetics to be inherited by the plot geometry functions because they are not passed to the ggplot() object. In this case they must be mapped as arguments the geometries themselves.\nPlot points:\n\nbase_plot + \n  geom_point(data = SWIM, \n             mapping = aes(Year, Time)) \n\n\n\n\nPlot a line:\n\nbase_plot + \n  geom_line(data = SWIM, \n            mapping = aes(x = Year, y = Time))\n\n\n\n\nIn a later section, we will differentiate between setting and mapping aesthetic attributes."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Mapping a variable as-is from the data frame`",
    "text": "Mapping a variable as-is from the data frame`\nggplot() defines the data as well as variables in aes(). You can easily map the x or y variable to the geom_*().\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(mapping = aes(color = Year))"
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Mapping a variable that differs from what’s in the data frame",
    "text": "Mapping a variable that differs from what’s in the data frame\nYou can also change a variable type in the scope of the plot without modifying it in the data frame. Let’s change Year to numeric to see what happens:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(mapping = aes(color = as.numeric(Year)))\n\n\n\n\nSimilarly, if we had a numeric variable and wanted to make a factor():\n\nSWIM &lt;- SWIM |&gt;\n  mutate(Year2 = as.numeric(Year))\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = as.factor(Year2)))\n\n\n\n\nOr make a character:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = as.character(Year2)))\n\n\n\n\nYou may have noticed that when mapped variables are numeric, the aesthetics are applied continuously and when they are character (e.g., categorical, factors), they are applied discretely. Here is a good example of mapping variable Year not as itself but by changing it to a as.numeric() or changing numeric variables to either a factor() or a character vector. You might notice that the content in the legend is messy now. Fixing this is something we will work on as we progress."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Mapping a variable that is not defined in the aes() mapping of ggplot()",
    "text": "Mapping a variable that is not defined in the aes() mapping of ggplot()\nSometimes you may wish to map a variable that is not defined in ggplot(). We can map a variable that is neither x nor y:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = Team))\n\n\n\n\nThis is no problem because Team exists in the SWIM data passed to data in the ggplot() object."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "Setting and Mapping Combinations",
    "text": "Setting and Mapping Combinations\nWe can also combine setting aesthetics and mapping them as long as the mapping takes place outside inside aes() and the setting takes place outside.\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(color = \"maroon\", \n             mapping = aes(shape = Team)\n             )\n\n\n\n\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(color = \"blue\", \n             mapping = aes(size = Time)\n             )\n\n\n\n\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(shape = 21, \n             mapping = aes(color = Event)\n             )\n\n\n\n\nImportantly, just as you cannot pass constant values as aesthetics in aes(), you cannot pass a variable to an aesthetic in the geom_*() outside of aes().\nFor example, passing color = Team outside of aes() in this instance will throw an error.\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n     geom_point(color = Team)\n\nError: object 'Team' not found\nIn summary, when you want to set an aesthetic to a constant value, do so in the geom_*() function, otherwise pass an aesthetic to aes() inside the geometry function. Color options can be discovered using colors(). Linetype has fewer options. To make the color more or less transparent, adjust alpha transparency (from 0 = invisible to 1).\n\nggplot(SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point() +\n  geom_line(linetype = \"dashed\",\n            color = \"red\",\n            alpha = .3\n            )"
  },
  {
    "objectID": "modules/index.html",
    "href": "modules/index.html",
    "title": "Modules",
    "section": "",
    "text": "This course consists of various content modules that introduce students to data visualization techniques using R. Techniques, however, should not be applied haphazardly but instead with respect to the biological and cognitive limitations of the user. The general principles of data visualization taught can be applied to programming languages other than R (e.g., Python, D3, etc.)."
  },
  {
    "objectID": "modules/index.html#module-structure",
    "href": "modules/index.html#module-structure",
    "title": "Modules",
    "section": "Module structure",
    "text": "Module structure\nIn general, modules will contain readings, additional resources, and weekly assignments.\nThe modules will be updated across the semester as needed. There are more modules on this course site because some modules provide other useful information. The names of the modules listed in the syllabus, however, do match the names in the module listing."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html",
    "href": "modules/multi_panel_plots_faceting.html",
    "title": "Multi-panel plots: Faceting",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#readings",
    "href": "modules/multi_panel_plots_faceting.html#readings",
    "title": "Multi-panel plots: Faceting",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Multi-panel figures\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Faceting"
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#external-functions",
    "href": "modules/multi_panel_plots_faceting.html#external-functions",
    "title": "Multi-panel plots: Faceting",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#libraries",
    "href": "modules/multi_panel_plots_faceting.html#libraries",
    "title": "Multi-panel plots: Faceting",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{forcats} 1.0.0: for creating and ordering factors\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting"
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#creating-facets-using-facet_wrap",
    "href": "modules/multi_panel_plots_faceting.html#creating-facets-using-facet_wrap",
    "title": "Multi-panel plots: Faceting",
    "section": "Creating facets using facet_wrap()",
    "text": "Creating facets using facet_wrap()\nWe see an overall pattern in the data. We can see a pattern for the Team subgroups across Rank.\nWe can add a facet_wrap() layer in order to plot the teams separately.\n\nbase_plot +\n  facet_wrap(facets = ~Team)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWe can add a facet_wrap() layer in order to plot separately per year.\n\nbase_plot +\n  facet_wrap(facets = ~Year)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#creating-facets-using-facet_wrapfacets-vars",
    "href": "modules/multi_panel_plots_faceting.html#creating-facets-using-facet_wrapfacets-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "Creating facets using facet_wrap(facets = vars())",
    "text": "Creating facets using facet_wrap(facets = vars())\nUse vars() instead of ~ to specify the variable.\n\nbase_plot +\n  facet_wrap(facets = vars(Year))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nPassing two variables to vars() will create subplots for each.\n\nbase_plot +\n  facet_wrap(facets = vars(Year, Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#controlling-columns",
    "href": "modules/multi_panel_plots_faceting.html#controlling-columns",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling columns",
    "text": "Controlling columns\nControl the number of columns by setting ncol.\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#controlling-direction-of-arrangement",
    "href": "modules/multi_panel_plots_faceting.html#controlling-direction-of-arrangement",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling direction of arrangement",
    "text": "Controlling direction of arrangement\nChange the direction using dir. By default, dir = \"h for a horizontal arrangement. The faceted variable changes from left to right, and top to bottom. Change to dir = \"v\".\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThe faceted variable now changes from top to bottom, left to right. The arrangement may depend on your goals or how your audience will make comparisons."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#controlling-the-scales",
    "href": "modules/multi_panel_plots_faceting.html#controlling-the-scales",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling the scales",
    "text": "Controlling the scales\nSpeaking of comparisons being made, when the range of values for variables varies by facet level, you may wish to constrain the scales or allow them to vary. By default, scales = \"fixed\" but you can change to move freely for x, y, or both x and y. Scales\nscales = \"fixed\": fix both x and y scales (default) scales = \"free_x\": x can vary freely, fix y scales = \"free_y\": y can vary freely, fix x scales = \"free\": x and y can vary freely\n\nAllow scales = free_y:\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\",\n             scales = \"free_y\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nAllow both scales = free:\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\",\n             scales = \"free\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nIn this instance, comparing position of points is quite complicated. The view has to evaluate the axes, extract out the values, and then compare. Subtle patterns may be easier to see, however."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#change-the-order-by-ordering-the-factor",
    "href": "modules/multi_panel_plots_faceting.html#change-the-order-by-ordering-the-factor",
    "title": "Multi-panel plots: Faceting",
    "section": "Change the order by ordering the factor()",
    "text": "Change the order by ordering the factor()\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#change-the-order-by-ordering-of-the-data-using-forcatsfct_reorder",
    "href": "modules/multi_panel_plots_faceting.html#change-the-order-by-ordering-of-the-data-using-forcatsfct_reorder",
    "title": "Multi-panel plots: Faceting",
    "section": "Change the order by ordering of the data using forcats::fct_reorder()",
    "text": "Change the order by ordering of the data using forcats::fct_reorder()\nWe can use forcats::fct_reorder() for reordering as we have done before for single plots. When the levels of a factor occur more than once, fct_reorder() applies a summary function, which by default is median() and the sorting order is from lowest to highest value. W\n\nOrder by the default behavior\nWe can add the arguments so they are visible.\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = median,  # the default function\n                                     .desc = FALSE   # the default sorting behavior\n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nOrder by the mean() and sort from highest to lowest\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = median,  # the default function\n                                     .desc = FALSE   # the default sorting behavior\n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nOrder by a function\nWe can pass a function that determines the difference between the mean() and the median(). If we can about the difference being positive or negative, the order of these computations will matter. If we want to order based on the size of the difference between the two metrics, we can take the absolute value of the difference using abs().\n\nabs(med(x) - mean(x)): a difference between median and mean\nmean(x, trim = 0.1): the mean that is based on trimming the outlying 10%\nmax(x) - min(x)): the range\n\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = function(x) { abs(median(x) - mean(x)) },  # a custom function for the range\n                                     .desc = T       # from largest value to the smallest \n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team)) +\n  labs(title = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nImportantly, the ordering of the panels in the facet plot always communicates information that is not visible or easily extracted from the visualization. By default, this ordering is by character or number. The facet with the largest mean may appear in facet position 1 or 12 (think random) but your goal may not be to communicate that difference across facets. A systematic ordering of the panels, however, using fct_reorder() represents a decision (whether conscious or not) to order the panels based on some method other than the default alphabetical or numeric order. This consequence is because both fct_reorder() and fct_reorder2() apply a function by with to order the data based on some variable and they then apply a sorting method based on that function. When you consciously apply fct_reorder(), you are doing so for a specific reason. Thus, you would want to communicate that information either in the plot title, subtitle, caption, or in a written report. Keep in mind that the ordering of panels reflects data compared across panels in the data visualization."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#repositioning-the-label-strip",
    "href": "modules/multi_panel_plots_faceting.html#repositioning-the-label-strip",
    "title": "Multi-panel plots: Faceting",
    "section": "Repositioning the label strip",
    "text": "Repositioning the label strip\nBy default, the facet label will be on the top of the plot because strip.position = \"top\" but you can set to \"top\", \"bottom\", \"left\", or \"right\".\nLet’s set strip.position = \"left\":\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team),\n             strip.position = \"left\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nLet’s set strip.position = \"bottom\":\nAlthough this repositioning is handled by theme(), theme(strip.placement = \"outside\")\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team),\n             strip.position = \"bottom\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#facet_gridrows-vars",
    "href": "modules/multi_panel_plots_faceting.html#facet_gridrows-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "facet_grid(rows = vars())",
    "text": "facet_grid(rows = vars())\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(rows = vars(Team))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBe careful what you facet as you might create something you don’t intend.\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(rows = vars(Rank))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#facet_gridcols-vars",
    "href": "modules/multi_panel_plots_faceting.html#facet_gridcols-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "facet_grid(cols = vars())",
    "text": "facet_grid(cols = vars())\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(cols = vars(Team))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "modules/multi_panel_plots_faceting.html#rows-and-columns-facet_gridcols-vars",
    "href": "modules/multi_panel_plots_faceting.html#rows-and-columns-facet_gridcols-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "Rows and columns facet_grid(cols = vars())",
    "text": "Rows and columns facet_grid(cols = vars())\nIf your variables allow, you can combine the two.\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", show_col_types = F)\n\nSWIM |&gt;\n  filter(Distance &gt; 50 & Distance &lt; 500) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Event),\n             cols = vars(Distance)\n             )\n\n\n\n\nOr by a character vector variable.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team)\n             )\n\n\n\n\nClearly, we need to clean up the axes for this plot. You can allow scales to vary as was done using facet_wrap() or you can adjust the scales.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team),\n             scales = \"free\"\n             )"
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html",
    "href": "modules/project_management/setting_up_git_and_github.html",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nCreate GitHub repository named \"dataviz-exercises\" from a template repository\nCheck that Git is setup in RStudio\nConfigure Git for R, within R/RStudio (a familiar context)\n\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using your PAT)\n\n\nWarning: Do not try to create an RStudio version control project from a repo before completing these steps.\nFollow steps below to complete."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#overview",
    "href": "modules/project_management/setting_up_git_and_github.html#overview",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nCreate GitHub repository named \"dataviz-exercises\" from a template repository\nCheck that Git is setup in RStudio\nConfigure Git for R, within R/RStudio (a familiar context)\n\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using your PAT)\n\n\nWarning: Do not try to create an RStudio version control project from a repo before completing these steps.\nFollow steps below to complete."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#libraries-used",
    "href": "modules/project_management/setting_up_git_and_github.html#libraries-used",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.3: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials"
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#creating-a-github-account",
    "href": "modules/project_management/setting_up_git_and_github.html#creating-a-github-account",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Creating a GitHub Account",
    "text": "Creating a GitHub Account\n\nGo to GitHub and create a free GitHub account. Make note of your username and your associated e-mail as you will need those for configuring Git with R.\n\nConsider this brief 15-minute TryGit Tutorial.\n\nStay logged in so that you can complete a later step.\nSend your PM your GitHub username once you are assigned to a team project. Your PM will send those to me and I will add you as a collaborator to a private repo."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "href": "modules/project_management/setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Checking Git Setup in RStudio",
    "text": "Checking Git Setup in RStudio\nYou will need to tell RStudio where to find the Git program as this may not be recognize automatically.\n\nFind the path to the Git program executable that was installed in an earlier step.\n\nIn the Terminal within RStudio (not the R console), type: where git on Windows and which git on Mac/Linux to find the path to the program. If there are more than one paths listed, just make note of one of them.\nIf for some reason you don’t see a path listed using that approach, type: Sys.which(\"git\") in your R console. The path here will likely be truncated so you will have to try to fill in the gaps when performing the step to set the path. See me for help.\n\nIn RStudio, go to Tools &gt; Global Options and click on left side bar menu item Git/SVN.\nSelect the option at the top to Enable version control interface for RStudio projects if it is not selected.\nSet the path to the Git executable if it is not already there. Browse to the path to where Git.exe installed on your computer. Windows Users should make note that this path should be a path containing Git.exe and not a path containing git-bash.exe.\nClick Apply and then click OK."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#creating-a-repository-on-github-using-a-template",
    "href": "modules/project_management/setting_up_git_and_github.html#creating-a-repository-on-github-using-a-template",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Creating a Repository on GitHub Using a Template",
    "text": "Creating a Repository on GitHub Using a Template\nYou will need to create a personal repository for class exercises. You can create it by building the directory structure for it yourself. This, however, may lead to errors. Creating a project from a template will ensure all students have they same repository with the same directory structure.\n\nOnce logged into your GitHub account, go to this template repository.\nOn the top right, you will see an option to create a Use this template. Click it an select “Create a new repository”.\nName the repository dataviz-exercises and provide a description like “for data viz class exercises and homework”.\n\n\n\n\n\n\n\nSelect the option to make the repository Private, check to add a README file, and add a .gitignore file by scrolling to find R:\n\n\n\n\n\n\n\nClick Create Repository\nWatch the course video if you have not already so that you know how to unpack the files for the repository as well as checking that Git is configured for RStudio.\n\nNote: Git manages files only, not directories. Directories will not populate in a repository unless they contain files. You will not see empty directories. For this reason, you may see empty files in the directory structure."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#configuring-git-and-github-for-rstudio",
    "href": "modules/project_management/setting_up_git_and_github.html#configuring-git-and-github-for-rstudio",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Configuring Git and GitHub for RStudio",
    "text": "Configuring Git and GitHub for RStudio\nThere are two ways you can set up, either using R (console) or the command line (terminal). My recommendation is to use R because that is where you are likely most familiar, if even a small degree. We will use functions from the {usethis} library to help you. This library should be installed already as part of the class setup. If you get an error stating that the library is not installed when executing the steps below, just type install.packages(\"usethis\", dep = TRUE) at your R console.\nThe {usethis} library will make connecting your R project to your github account simple. You will use usethis::use_git_config() to configure your GitHub account with Git on your computer; if you did not create, see earlier step. In the below example, you will see that we need to provide two character strings as arguments to the function. The strings are used to set your user.name and your user.email (the e-mail attached to your GitHub account). Double check your GitHub e-mail and username. Make sure that the username and e-mail are correct. You may need to check your e-mail in GitHub’s e-mail account settings.\nEdit the following code to include your username and email and then execute your modified R code:\nusethis::use_git_config(user.name = \"github_username\", \n                        user.email = \"github_email@gitrdone.com\"\n                        )\nDone!\nNote:: This function does not return anything so if you are waiting for some exciting feedback, you will not see any."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "href": "modules/project_management/setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Creating a Personal Access Token (PAT) for GitHub",
    "text": "Creating a Personal Access Token (PAT) for GitHub\nBefore completing this step, log into your GitHub account to facilitate the communication between RStudio and GitHub.\nYou will need a personal access token (PAT) for making remote changes to GitHub. A first step then is to create a PAT using usethis::create_github_token(). Second, you will register your PAT with the Git credential manager used by your computers operating system using gitcreds::gitcreds_set(). Keep in mind that if you use a different computer (e.g., you get a new one), you’ll need to register the PAT on that computer following the same steps described here.\nTo create your personal access token (PAT), type the following at your R console: \nusethis::create_github_token()\nAfter executing the code, you will be taken to your GitHub account (if you remained logged in). Go to the bottom of the page and click generate token. You should add a description for it so that you can understand its use case. For example, describe it based the computer you are using it on, “my computer make and model”. You may also describe it based on a project you are working on, “token-for-project-xyz”. If you do not add a description, you will likely become overwhelmed and/or confused when you have multiple tokens. When you need to regenerate or delete a token that expires, you will not be able to determine what they are for if you do not add a description.\nAfter creating your token, Copy it to your computer’s clipboard and save it someplace safe. Do not share your token with anyone because anyone who has it can access your public or private GitHub repositories.\nWarning: Your PAT will expire after some duration, usually 30 days unless you change it. For this project, I suggest you change the expiration to a date after the semester ends to ensure you don’t have to go through this process again during the semester. Getting a new PAT is not difficult, however. If your PAT will soon expire, GitHub will send you an e-mail alerting you also. You can regenerate a PAT from a link in your e-mail, so make sure your associated e-mail is one you check."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "href": "modules/project_management/setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Setting your Git Credentials (using PAT)",
    "text": "Setting your Git Credentials (using PAT)\nNow that you have a PAT, we now need to set those credentials for RStudio to communicate with your GitHub account.\nExecute the following R code to set your credentials:\ngitcreds::gitcreds_set()\nYou may see a set of number options with corresponding descriptions. If you see them, enter the number corresponding to the option that makes the most sense for what you are trying to accomplish, for example, something like “set or replace your credentials”.\nWhen should then see a prompt like ? Enter new password or token. At this point, paste your PAT here and press return/enter. Then remove the PAT from your clipboard so that you don’t paste them someplace.\nYou can check that your credentials are stored by typing the following R code in the console:\ngh::gh_whoami()\n\nUpdating your Personal Access Token (PAT)\nAt some point, even if you set your PAT to expire after the semester, it will expire and you will need to update it. When it’s about to expire (you will receive an e-mail), or if it has expired, you can repeat the steps to obtain a new toke and set your credentials in R as you did above using:\nusethis::create_github_token()\n\ngitcreds::gitcreds_set()\nAlternatively, you can go to https://github.com/settings/tokens while logged into your GitHub account and regenerate the token and change the expiration date. Then, copy the PAT to the clipboard and set your credentials again using:\ngitcreds::gitcreds_set()"
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#summary",
    "href": "modules/project_management/setting_up_git_and_github.html#summary",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Summary",
    "text": "Summary\nYou have now created your GitHub account, installed and/or set up Git with RStudio and ensured Git is installed, created a repository (from a template), created a new PAT, and set you credentials. The next step will be to connect the remote GitHub repository with your RStudio setup by creating a Git Version Control RStudio project."
  },
  {
    "objectID": "modules/project_management/setting_up_git_and_github.html#optional-resources",
    "href": "modules/project_management/setting_up_git_and_github.html#optional-resources",
    "title": "Project Management 01: Setting Up Git and GitHub for R",
    "section": "Optional Resources",
    "text": "Optional Resources\nIf you find yourself working on complicated projects, you might benefit from using a Git client or need to troubleshoot events. Although you won’t need to do this for this course, I’m providing some resources for your future. Feel free to come back to this course site to review content as I don’t intend to remove anything.\n\nGit Client: Git clients work like the RStudio Gui option described above but likely much better. If you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface.\n\nGitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\nGitHub Desktop is another common option. Install, connect your GitHub account and select your repo to add, and voilà. You can stage, commit, and push from there.\n\nTroubleshooting: happygitwithr is a resource for troubleshooting Git issues specifically with R."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html",
    "href": "modules/spatial_position_and_adjustment.html",
    "title": "Spatial position and adjustment",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#readings",
    "href": "modules/spatial_position_and_adjustment.html#readings",
    "title": "Spatial position and adjustment",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Overlapping points\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Overplotting"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#external-functions",
    "href": "modules/spatial_position_and_adjustment.html#external-functions",
    "title": "Spatial position and adjustment",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#libraries",
    "href": "modules/spatial_position_and_adjustment.html#libraries",
    "title": "Spatial position and adjustment",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#load-libraries",
    "href": "modules/spatial_position_and_adjustment.html#load-libraries",
    "title": "Spatial position and adjustment",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#default-point-position",
    "href": "modules/spatial_position_and_adjustment.html#default-point-position",
    "title": "Spatial position and adjustment",
    "section": "Default Point Position",
    "text": "Default Point Position\nWe will use the SWIM data from 2023 to manipulate point position. To illustrate the effect best, we will also trim out some long times/events.\nFirst, we should remind ourselves that the default setting for points plotting using geom_point() is the “identity” for the x and y mappings.\nThe default position argument is position = \"identity\":*\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"identity\")"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#adjusting-point-position",
    "href": "modules/spatial_position_and_adjustment.html#adjusting-point-position",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Position",
    "text": "Adjusting Point Position\nThere are two main ways of adjusting the spatial position for point plots. One solution is to adjust the position argument within geom_point() and the other is to use a sister function geom_jitter(). However, you adjust your data, you must acknowledge that you are the creator of the graphic and that are are making the decision to change those point positioning. The adjustment will influence how users perceive, attend to, and interpret the visualization you produce and distribute. You must consider the degree of the adjustment and weigh the costs and benefits of “massaging” the data visualized. You also much assume responsibility and accountability for doing so.\n\ngeom_point(position = \"jitter\")\ngeom_jitter()\n\n\nChanging the position argument of geom_point()\nUsing gome_point(), we can pass position = \"jitter\" instead of position = \"identity\":\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"jitter\")\n\n\n\n\n\n\nUsing geom_jitter()\nWe can use geom_jitter() to jitter the points for us. The default argument for position adjustment in this function is position = \"jitter\". For more details, you can read the documentation of geom_jitter().\nUsing geom_jitter() rather than geom_point():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter()\n\n\n\n\n\nCustomizing jitter spread\nGiven position = \"jitter\" applies a stochastic function to reposition points along both x and y axes, one should not be surprised that to see functions contain arguments allowing for more control over movement along each axis (e.g., height and width).\nIn general, smaller values passed to these arguments will result in less dispersion of the points from their original positions. For both arguments, a jittering of points is applied in both positive and negative directions, so the total spread is twice the value specified in the argument. For example, passing width = 1 will jitter points having an “identity” position of x along that x axis, ranging from x - 1 to x + 1. You should also be mindful of the scales because an adjustment of 1 on some scales will be minimal and an adjustment of .3 on other scales may be quite dramatic. For example, on these scales, you really wont perceive much change if you used .3.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter(height = 5, \n              width  = 10\n              )\n\n\n\n\nDespite setting these arguments to values, keep in mind that they do not control all points in exactly the same manner each time. The function still has some random component to it, so you will not be able to reproduce the plot with any consistency. We will address the topic of plot replication versus reproduction later.\n\n\n\nChanging the position of a categorical variable\nAnother limitation that you see in this example is the limited movement of the points. They are fairly locked along the Distance variable. Part of the reason is that these values are discrete, or categorical rather than continuous so the movement is very constrained relative to what you might normally see in a numeric by numeric scatterplot.\nLet’s change Distance to a character (e.g,. is.character()) or a factor (e.g., factor(), as.factor(), etc.) on the fly inside ggplot():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou will immediately notice that the x axis has changed. Disregard the label change as that is a simple fix with xlab(\"Distance\") and is irrelevant to this current discussion. Importantly, factorizing the variable will make visible all levels of the factor variable present in the data. For example, you now see 50 which was not displayed before. This outcome illustrates the difference in default scale_*() functions for numeric and categorical data but we will address scale manipulations later. You will also notice that the interval between factor levels is equivalent along the x axis despite them not being numerically equal by nature. That behavior is a trade off by default which you can fix should you consider the perceptual implications of this approach problematic.\nThe main point here is to illustrate position manipulation. Let’s use geom_jitter() for comparison.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter() \n\n\n\n\nBy default, you see sufficient movement in points, which may be too much or too little jitter depending on the data. We can adjust the height and width of the jitter here too but notice the value change when the variable is a factor.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 2,\n              height = 0\n              )\n\n\n\n\nLet’s pass larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 5,\n              height = 0\n              )\n\n\n\n\nAnd larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 10,\n              height = 0\n              )\n\n\n\n\nThe more you jitter, the more the data take a position different from their “identity”. The adjustment is obviously more misleading when made on Time variable. Let’s dial the movement down a bit using a decimal value:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = .3,\n              height = 0\n              )\n\n\n\n\nYou will see that the height position did not change but the width did. Note that for categorical data (e.g., characters and factors), a width adjustment of 0.5 will jitter points in a way that makes them difficult if not impossible to determine the category level they belong to. In other words, the points from the levels of Distance overlap even though they should not. The last plot is the only one of those above that jitters in a way that still allows you to the the groups from which the data belong.\nAs a final note, be mindful of jitter adjustments applied by default. If you have a discrete variable, jitter along the corresponding axis and leave the other at 0. If both x and y are numeric/continuous, jitter only enough to fix your problem without altering the data more than necessary because otherwise you are lying with data visualizations whether intentionally or unintentionally so.\n\n\nReproducing Plots\nYou can observe the behavior of the functions used above by replicating the function calls. By doing so, you will see that the position of the points changed across those calls. Although we can replicate a procedure to address overplotting, we can not do so in a way that makes the position reproducible across multiple function calls because of the stochastic function applied to do so.\nBy reproduction, we mean that you return the same plot for every single call of the same code. Reproduction minimizes the confusion that occurs when your visualization changes when presented to your audience (including you) on different occasions.\n\nSetting a seed in geom_point()\nIn order to reproduce point position instead of replicating something very similar, use position_jitter() along with the seed argument. The seed determines the calculation of the jitter, so setting it will result in returning the same plot every single call.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15)\n             )\n\n\n\n\nFor this reason, I recommend using geom_point() over geom_jitter()."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#adjusting-point-transparency",
    "href": "modules/spatial_position_and_adjustment.html#adjusting-point-transparency",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Transparency",
    "text": "Adjusting Point Transparency\nWhen points are opaque, your only option is to change their position. But changing position means changing the data from identity to something else. This may not be your first line of attack.\nNow that we have set a seed or reproduction, we can also adjust the transparency of the points by passing values from 0 to 1 to the alpha argument. In conjunction with position adjustments, alpha adjustments will facilitate the perception of two points (compared with one) with minimal position adjustment.\nBy default points are opaque, alpha = 1:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 1)\n\n\n\n\nAnd can be made invisible by passing alpha = 0:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 0)\n\n\n\n\nValues in between can be used to find the correct balance between points being too transparent, too dark, and too difficult to see when multiple points take the same position. Of course, with this data example, the identity of all points are the same at each level of the event by nature. As a result, you see a lot of variation that is not really present in the data.\nToo light to perceive?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .2)\n\n\n\n\nToo dark to discriminate?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4)\n\n\n\n\nKeep in mind also that alpha transparency will interact with point color, so there is never a particular rule of thumb."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#adding-group-level-data",
    "href": "modules/spatial_position_and_adjustment.html#adding-group-level-data",
    "title": "Spatial position and adjustment",
    "section": "Adding Group Level Data",
    "text": "Adding Group Level Data\nOne problem with all the points is the inability to either see or process all of the points in the plot. Extracting out mean Time for the Distance variable is quite the cognitive task.\nRemember that {ggplot} allows for adding layers to plots. We have shown how to add a geom_point() and a geom_bar() to the same plot using the same data. But we could also add the a geom that presents a new data frame. For example, we could obtain the mean Time for each Distance and pass that data frame as a separate geom_point() layer.\nLet’s first get the summarized data frame:\n\nMEAN_TIMES_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., Time = mean(Time))\n\nWe see the association at the group level too.\n\nMEAN_TIMES_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nTime\n\n\n\n\n50\n23.59429\n\n\n100\n55.19567\n\n\n200\n121.51304\n\n\n400\n268.98667\n\n\n500\n305.51333\n\n\n\n\n\nNow let’s add that layer and make the points “tomato” colored:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4) +\n  geom_point(data = MEAN_TIMES_BY_DIST,\n             mapping = aes(x = Distance, Time),\n             col = \"tomato\", \n             size = 4, \n             alpha = .7)\n\n\n\n\nWe could do the same thing for the counts:\n\nCOUNTS_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., \n            Count = dplyr::n(),\n            Time = mean(Time)\n            )\n\nWe now have a data frame that contains the mean Time and the Count for events. We can add a geom_point() layer that plots the mean Time as a point that varies in size corresponding to the Count.\n\nCOUNTS_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nCount\nTime\n\n\n\n\n50\n14\n23.59429\n\n\n100\n67\n55.19567\n\n\n200\n79\n121.51304\n\n\n400\n3\n268.98667\n\n\n500\n6\n305.51333\n\n\n\n\n\nUsing some new aesthetics for geom_point(), we illustrate the addition of the plot here.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .4) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = .65) +\n  theme_minimal()\n\n\n\n\nRemember that plot layer matters. Different orders of layers will render different plots.\nLet’s change the geom layer order and change alpha for each geom:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = 1) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .3) +\n  theme_minimal()"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#adjusting-point-size",
    "href": "modules/spatial_position_and_adjustment.html#adjusting-point-size",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Size",
    "text": "Adjusting Point Size\nAnother option to overcome overplotting is to create what is known as a counts chart. Wherever there is more point overlap, the size of the circle gets bigger. Some people use a geom_count() for this approach. The default statistical transformation for geom_count() is stat = \"sum\", which sums up the count of the points in order to plot points of sizes relative to their counts. Although presenting larger points does not really fall perfectly under the topic of position adjustment, larger points do in fact take up more space on the plot, so in a way they are an adjustment of a point’s spatial position. When using geom_count(), however, you have to tinker a little when you also want to jitter points because by default position = \"jitter\" will also cause your sized points jitter, which is confusing. If size of points can be used, you may find adding a second geom_point() that uses summarized data to be a more intuitive solution."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "href": "modules/spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a stacked bar plot",
    "text": "Creating a stacked bar plot\nLet’s add the School variable to the plot using aes(fill = School) to the geom_*() layer:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event)\n         ) +\n  geom_bar(aes(fill = School))\n\n\n\n\nWe can also have the aesthetic inherited from ggplot() if aes(fill = School) is defined as part of ggplot():\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nThe bars take on different representations as you can see. You can also plot the counts with a different aesthetic combination.\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nNotice that with stacked bars, you encode the count as the length of the colored rectangle. For the user to compare counts for comparisons, they can use the height position for the first stack only because the bars are on an aligned scale. The other bars in the stack do not have the same starting an ending points. These bars on on an unaligned scale, which makes the decoding task more difficult for the user. In addition to this alignment issue, the bars may also encourage decoding of area, which is also a challenging cognitive task that leads to perceptual errors. For discussion of more of these perceptual issues, see Cleveland & McGill (1984). Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.\nWhen you want to facilitate comparisons of bars, you might want to change their positions by creating a grouped bar plot."
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#stacking-with-position-fill",
    "href": "modules/spatial_position_and_adjustment.html#stacking-with-position-fill",
    "title": "Spatial position and adjustment",
    "section": "Stacking with position = \"fill\"",
    "text": "Stacking with position = \"fill\"\nA problem with stacking is that the counts are raw and are not conditionalized on all the\nUsing position = \"fill\" will stretch the bars so that the counts are relative to the distribution.\n\nplot1 &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event)\n         ) +\n  geom_bar() \n\nplot2 &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event\n                       )\n         ) +\n  geom_bar(position = \"fill\", ) \n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "href": "modules/spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a grouped bar plot",
    "text": "Creating a grouped bar plot\nStacking is not always the desired outcome. We often want to see the bars for the subgroups. We will need to override the default position. Dodging is a general way to correct for overlapping objects, whether points, bars, box plots, etc. You can practice using it with geom_point() but we will use it here for bars. Specifically, we will override the default position argument, position = \"stacked\" and make is position = \"dodge\" so that the bar positions dodge each other.\nDodging a geom_*() like bars, points, or rectangles, will preserve their vertical position while also adjusting their horizontal position.\nBesides the examples illustrated below, you can find more examples in the tidyverse documentation.\ngeom_bar(position = \"dodge\")\n\nposition = \"dodge\"\nposition = \"dodge2\": adds padding to bars\nposition = position_dodge(): with padding control etc.\nposition = position_dodge2(): with padding control etc.\n\nDefault behavior of position_dodge():\n\nd1_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge(), show.legend = F)\n\nYou will need a grouping variable specified in the global or local geom_*() for position_dodge() whereas this is not a requirement for position_dodge2(). Moreover, position_dodge2() differs from position_dodge() insofar as it does not need a grouping variable in a layer and works with bars and rectangles. It it likely your go-to function for positioning box plots because you can adjust their widths.\nDefault behavior of position_dodge2():\n\nd2_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge2(), show.legend = F)\n\nAdding a padding to position_dodge2():\n\nd3_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = \n             position_dodge2(padding = .5), \n           show.legend = F)"
  },
  {
    "objectID": "modules/spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "href": "modules/spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "title": "Spatial position and adjustment",
    "section": "Plotting a Grid Grob (Graphic Object)",
    "text": "Plotting a Grid Grob (Graphic Object)\nWe can take the three objects and arrange them in a grid using gridExtra::arrangeGrob(). We can specify the number of colons and or rows as well. In this case, we can plot them all as a single column and they will appear in the order the plots are added in arrangeGrob().\n\nplot(gridExtra::arrangeGrob(d1_plot, \n                            d2_plot,\n                            d3_plot,\n                            ncol = 1)\n     )"
  },
  {
    "objectID": "modules/themes.html",
    "href": "modules/themes.html",
    "title": "Bonus: Figure design & themes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/themes.html#readings",
    "href": "modules/themes.html#readings",
    "title": "Bonus: Figure design & themes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Themes(https://ggplot2-book.org/themes)\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Extensions(https://ggplot2-book.org/extensions)"
  },
  {
    "objectID": "modules/themes.html#external-functions",
    "href": "modules/themes.html#external-functions",
    "title": "Bonus: Figure design & themes",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/themes.html#libraries",
    "href": "modules/themes.html#libraries",
    "title": "Bonus: Figure design & themes",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting\n{monochromeR} 0.2.0: for color palettes\n{cowplot} 1.1.3: for color palettes\n{see} 0.8.4: for theme types"
  },
  {
    "objectID": "modules/themes.html#cowplottheme_minimal_vgrid",
    "href": "modules/themes.html#cowplottheme_minimal_vgrid",
    "title": "Bonus: Figure design & themes",
    "section": "cowplot::theme_minimal_vgrid()",
    "text": "cowplot::theme_minimal_vgrid()\n\nplot + cowplot::theme_minimal_vgrid()"
  },
  {
    "objectID": "modules/themes.html#theme_classic",
    "href": "modules/themes.html#theme_classic",
    "title": "Bonus: Figure design & themes",
    "section": "theme_classic()",
    "text": "theme_classic()\n\nplot + theme_classic()"
  },
  {
    "objectID": "modules/themes.html#theme_minimal",
    "href": "modules/themes.html#theme_minimal",
    "title": "Bonus: Figure design & themes",
    "section": "theme_minimal()",
    "text": "theme_minimal()\n\nplot + theme_minimal()"
  },
  {
    "objectID": "modules/themes.html#seetheme_modern",
    "href": "modules/themes.html#seetheme_modern",
    "title": "Bonus: Figure design & themes",
    "section": "see::theme_modern()",
    "text": "see::theme_modern()\n\nplot + see::theme_modern()"
  },
  {
    "objectID": "modules/themes.html#setting-a-theme-with-theme_set",
    "href": "modules/themes.html#setting-a-theme-with-theme_set",
    "title": "Bonus: Figure design & themes",
    "section": "Setting a theme with theme_set()",
    "text": "Setting a theme with theme_set()\n\nplot\n\n\n\n\n\ntheme_set(theme_minimal())\n\nplot"
  },
  {
    "objectID": "modules/themes.html#an-example",
    "href": "modules/themes.html#an-example",
    "title": "Bonus: Figure design & themes",
    "section": "An example",
    "text": "An example\n\nknitr::include_graphics(here::here(\"images\", \"theme_elements.png\"))"
  },
  {
    "objectID": "modules/themes.html#getting-a-theme-with-themeget",
    "href": "modules/themes.html#getting-a-theme-with-themeget",
    "title": "Bonus: Figure design & themes",
    "section": "Getting a theme with theme(get)",
    "text": "Getting a theme with theme(get)\nIf you want to see how the current active theme components are set, use theme_get(). This default theme is theme_grey(). Whenever you restart R, this default theme will load. You can load a different theme but you will need to add code to do this so that you ensure the same operation once R reloads.\n\nthe_theme &lt;- theme_get()\n\nAssigning the theme to an object, we can see the components as elements of the names() vector. We will not print all of the components of the theme here because there are 136 of them.\nYou can see the 136 theme components by passing the theme object to names(). You can see there are far many more than what Wang provided in his illustration. You can, however, see the first 10 using names(the_theme)[1:10].\n\nnames(the_theme)[1:10]\n\n [1] \"line\"                \"rect\"                \"text\"               \n [4] \"title\"               \"aspect.ratio\"        \"axis.title\"         \n [7] \"axis.title.x\"        \"axis.title.x.top\"    \"axis.title.x.bottom\"\n[10] \"axis.title.y\""
  },
  {
    "objectID": "modules/themes.html#creating-a-custom-theme-from-another-theme",
    "href": "modules/themes.html#creating-a-custom-theme-from-another-theme",
    "title": "Bonus: Figure design & themes",
    "section": "Creating a custom theme from another theme`",
    "text": "Creating a custom theme from another theme`\nTo set new theme components use theme_set(). Modifying a theme is not too difficult. You will need to remember that changes to a theme will need to be loaded at the top of your R Markdown file so that the theme is applied to all plots. If you are working with collaborators, consider putting your theme in file names something like /src/theme.R (or add it to a library call file). Then, source the code where you load libraries. All team members can source the same file and modifications to the theme will occur everywhere.\nModify the default theme using theme_set() and passing it a theme object. You can add a new layer to plots but calling the theme when you load your libraries is likely a more foolproof approach.\nIn this example, src/theme.R defines two new themes. theme_classic_167() is based on theme_classic() and theme_minimal_167() is based on theme_minimal(). Both functions can take two arguments for adjusting the base font size and family (font type). You should try to set the font family to match the font of your document or website within which your visualization will appear.\n\nbase_size = 14\nbase_family = \"Book Antiqua\"\n\nAs part of the function, you will also see the addition of the ... argument in the third position. This special argument indicates a variable number of arguments to pass to other functions. Use the ... argument when you want to extend a function without being so verbose that you list the exhaustive list of arguments in your function. Besides, even if you do list them all by name, their names may change or new arguments will be added to other function, thus causing your function (which relies upon the other function) to break.\nYou will add ... in two places, which you will see in src/theme.R, ... appears:\n\nIn the definition: function(base_size = 14, base_family = \"Book Antiqua\", ...)\nOn the last line of ggplot2::theme(&lt;other arguments&gt;, ...)\n\nLoad the new theme function.\n\nsource(here::here(\"src\", \"theme.R\"))"
  },
  {
    "objectID": "modules/themes.html#theme_167_classic",
    "href": "modules/themes.html#theme_167_classic",
    "title": "Bonus: Figure design & themes",
    "section": "theme_167_classic()",
    "text": "theme_167_classic()\n\nplot + theme_167_classic()\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database"
  },
  {
    "objectID": "modules/themes.html#theme_167_minimal",
    "href": "modules/themes.html#theme_167_minimal",
    "title": "Bonus: Figure design & themes",
    "section": "theme_167_minimal()",
    "text": "theme_167_minimal()\n\nplot + theme_167_minimal()\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html",
    "href": "modules/visualizing_more_distributions.html",
    "title": "Visualizing more distributions",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#readings",
    "href": "modules/visualizing_more_distributions.html#readings",
    "title": "Visualizing more distributions",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing distributions: Visualizing many distributions at once"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#external-functions",
    "href": "modules/visualizing_more_distributions.html#external-functions",
    "title": "Visualizing more distributions",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/functions/view_html.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#libraries",
    "href": "modules/visualizing_more_distributions.html#libraries",
    "title": "Visualizing more distributions",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.5.1: for plotting\n{ggridges} 0.5.6: for plotting ridgeline plots\n{ggforce} 0.4.2: for plotting sina plots"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#load-libraries",
    "href": "modules/visualizing_more_distributions.html#load-libraries",
    "title": "Visualizing more distributions",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(ggridges)"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#five-number-summary",
    "href": "modules/visualizing_more_distributions.html#five-number-summary",
    "title": "Visualizing more distributions",
    "section": "Five-Number Summary",
    "text": "Five-Number Summary\nTukey wanted box plots to visualize high-level summary information as a Five-number Summary.\n\nminimum point: 0th percentile point excluding any outliers\nfirst quartile: 25th percentile\nsecond quartile 50th percentile (median)\nthird quartile: 75th percentile\nmaximum point: 100th percentile point excluding any outliers\n\nDepending on the box plot created, the whiskers may terminate a the upper and lower extremes in order to visualize minimum and maximum values of the data. Alternatively, the whisker may frame out 1.5 times the interquartile range."
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#distributional-information",
    "href": "modules/visualizing_more_distributions.html#distributional-information",
    "title": "Visualizing more distributions",
    "section": "Distributional Information",
    "text": "Distributional Information\n\nBox plot Density\nIf you know how to examine box plots, information about the distribution’s density is also visually present, making helpful identifying whether distributions are skewed negatively or positively and are leptokurtic or platykurtic. When the bottom whisker is long and the top is short, you will have a distribution with a long lower tail, making is skewed negatively. When the opposite is true, the distribution will be skewed positively.\n\n\nInterquartile range (IQR)\nSimilarly, the interquartile range (IQR) can be extracted as it represents the distance between the upper and lower quartiles. The box itself frames out the IQR.\n\n\nExamples\nBox plots can be used to visualize the distribution for a single set of data or, like strip charts and violin plots, for displaying distributions of a variable across many categorical groups. As with violin plots, you will have to be mindful of your data structure and convert numeric variables to categorical as seen here.\n\nnumeric_plot &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Distance, \n                     y = Time, \n                     group = 1    # need to set group to avoid error\n                     )\n       ) +\n  geom_boxplot() +\n  labs(tag = \"A\", title = \"Distance as Numeric\")\n\nfactor_plot1 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = factor(Distance), y = Time)) +\n  geom_boxplot(fill = \"grey80\") +\n  labs(tag = \"B\", title = \"Distance as a Factor\\nGray is a Primariy Color\")\n\nfactor_plot2 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Distance, y = Time)) +\n  geom_boxplot(mapping = aes(fill = factor(Distance))) + \n  theme(legend.position = \"bottom\") +\n  labs(tag = \"C\", title = \"Label and Color are Redundant (Unnecessary)\")\n\nfactor_plot3 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Event, y = Time)) +\n  geom_boxplot(mapping = aes(fill = Event)) + \n  theme(legend.position = \"bottom\") +\n  labs(tag = \"D\", title = \"Label and Color are Redundant (Unnecessary)\")\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(numeric_plot, factor_plot1, \n                              factor_plot2, factor_plot3, \n                              ncol = 2)\n       )\n)\n\n\n\n\nAnd of course, the colors, lines, and other aesthetics are customization."
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#geom_density_ridges-vs.-geom_density_ridges2",
    "href": "modules/visualizing_more_distributions.html#geom_density_ridges-vs.-geom_density_ridges2",
    "title": "Visualizing more distributions",
    "section": "geom_density_ridges() vs. geom_density_ridges2()",
    "text": "geom_density_ridges() vs. geom_density_ridges2()\nYou will notice that with geom_density_ridges(), the line of the density plots simply outlines the density and that there is not a solid line across the x-axis. geom_density_ridges2() uses closed polygons so the line will be visible along the x-axis or the bottom of each density estimation plot. What looks better to you?\nAlso, those tails of your plot are kind of distracting when they do not communicate useful information. You may wish to cut the trailing tails by passing a value to rel_min_height to cut the trailing tails. There is no built-in algorithm to adjust this for you, so adjust as necessary.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges() +\n  ggtitle(\"geom_density_ridges()\")\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2() +\n  ggtitle(\"geom_density_ridges2()\")\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(rel_min_height = 0.005) +\n  ggtitle(\"geom_density_ridges2()\\nrel_min_height = 0.005\")\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(rel_min_height = 0.00000001) +\n  ggtitle(\"geom_density_ridges2()\\nrel_min_height = 0.00000001\")\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n)"
  },
  {
    "objectID": "modules/visualizing_more_distributions.html#other-aesthetics",
    "href": "modules/visualizing_more_distributions.html#other-aesthetics",
    "title": "Visualizing more distributions",
    "section": "Other Aesthetics",
    "text": "Other Aesthetics\nAs with other geom_*()s, arguments for color, fill, linetype, alpha, size (same as linewidth in geom_line()) etc. can be set or mapped.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(fill = \"gold\",\n                      color = \"black\",\n                      linetype = \"solid\",\n                      size = .4,\n                      alpha = .6,\n                      rel_min_height = 0.00001) +\n  ggtitle('fill = \"gold\"\\nlinetype = \"solid\"')\n\nWarning in geom_density_ridges2(fill = \"gold\", color = \"black\", linetype =\n\"solid\", : Ignoring unknown parameters: `size`\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges2(aes(fill = factor(Distance)),\n                      linetype = \"dashed\",\n                      size = .4,\n                      alpha = 1, \n                      scale = 1,\n                      rel_min_height = 0.00001\n                      ) +\n  #theme(legend.position = \"none\") +\n  #theme(legend.position = c(.85, .2)) +\n  colorspace::scale_fill_discrete_sequential(palette = \"Burg\") +\n  ggtitle('aes(fill = factor(Distance)) + palette = \"Burg\"\\nlinetype = \"dashed\"')\n\nWarning in geom_density_ridges2(aes(fill = factor(Distance)), linetype =\n\"dashed\", : Ignoring unknown parameters: `size`\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges_gradient(aes(fill = stat(x)),\n                               scale = 3, \n                               size = 0.3, \n                               rel_min_height = 0.01\n                               ) +\n  colorspace::scale_fill_continuous_sequential(name = \"Time\",\n                                               palette = \"Burg\") +\n  ggtitle('geom_density_ridges_gradient\\nscale_fill_continuous_sequential + palette = \"Burg\"')\n\nWarning in geom_density_ridges_gradient(aes(fill = stat(x)), scale = 3, :\nIgnoring unknown parameters: `size`\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges_gradient(aes(fill = stat(x)),\n                               scale = 1, \n                               size = 0.3, \n                               rel_min_height = 0.01\n                               ) +\n  colorspace::scale_fill_continuous_sequential(name = \"Time\",\n                                               palette = \"Rocket\",) +\n  #theme(legend.position = c(.85, .2)) +\n  ggtitle('geom_density_ridges_gradient\\nscale_fill_continuous_sequential + palette = \"Rocket\"')\n\nWarning in geom_density_ridges_gradient(aes(fill = stat(x)), scale = 1, :\nIgnoring unknown parameters: `size`\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n)\n\nWarning: `stat(x)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(x)` instead."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html",
    "href": "modules/visualizing_uncertainty.html",
    "title": "Visualizing uncertainty",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#readings",
    "href": "modules/visualizing_uncertainty.html#readings",
    "title": "Visualizing uncertainty",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing uncertainty\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Uncertainty"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#external-functions",
    "href": "modules/visualizing_uncertainty.html#external-functions",
    "title": "Visualizing uncertainty",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /src/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"src\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#custom-functions",
    "href": "modules/visualizing_uncertainty.html#custom-functions",
    "title": "Visualizing uncertainty",
    "section": "Custom Functions",
    "text": "Custom Functions\nWe will use some custom functions to handle some tasks this module."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#libraries",
    "href": "modules/visualizing_uncertainty.html#libraries",
    "title": "Visualizing uncertainty",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{ggplot2} 3.5.1: for plotting\n{ggdist} 3.3.2: for plotting distributions\n{distributional} 0.4.0: for plotting distributional information\n{tidyr} 1.3.1: for tidying up models\n{broom} 1.0.6: for cleaning up models"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#load-libraries",
    "href": "modules/visualizing_uncertainty.html#load-libraries",
    "title": "Visualizing uncertainty",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggdist)\nlibrary(broom)\nlibrary(distributional)"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#interim-summary",
    "href": "modules/visualizing_uncertainty.html#interim-summary",
    "title": "Visualizing uncertainty",
    "section": "Interim Summary",
    "text": "Interim Summary\nThere are a few details here worth noting given the comparisons here. First, the bar plot and the table take up about the same page real estate yet the table conveys much more information. A table can be used to provide a lot of detail whereas a plot may allow a lot of detailing . Yes, we can create stacked or grouped bar plots to take up the same real estate but you should always ask what your the goal is for a plot and whether the plot is the best medium for visualizing data.\nSecond, the important aspect of the data presented in the table and the bar plot is that the number of events does not vary for a given grouping. Yes, the counts change across the team groupings and likely across years but for this year, event, and teams, the height of the bars do not vary. Where data do not vary, bar plots are a good choice.\nThird, plots are visual objects that are processed by the visual system. Plot elements will affect how the visual system processes items, directs attention exogenously (bottom-up) rather than endogenously (top-down) which may have lasting influences on plot memorability."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#point-estimates",
    "href": "modules/visualizing_uncertainty.html#point-estimates",
    "title": "Visualizing uncertainty",
    "section": "Point Estimates",
    "text": "Point Estimates\nWe can filter or an event, group the data, and summarize by groups using means in order to plot those mean point estimates are bars. This is the traditional, though not personally recommended, approach to plotting data in various disciplines. This will serve as a starting point for plots.\n\nSWIM |&gt;\n  group_by(Team, Event) |&gt;\n  summarize(Mean = mean(Time)) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = Team, y = Mean)) + \n  geom_col() +\n  labs(title = \"Mean Freestyle Swim Time\", y = \"Seconds\")\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument.\n\n\n\n\n\nCompared with the count data, the means are simply point estimates of the central tendency for sample data which are often used in service of estimating unknown population parameters. This is why a mean is called a point estimate as it estimate a single value, or point, of a distribution. Plotting means does not provide information about variability in the sample data or in the uncertainty around the mean’s ability to estimate the sample’s center generally and more specifically its corresponding population parameter."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#visualizing-variability",
    "href": "modules/visualizing_uncertainty.html#visualizing-variability",
    "title": "Visualizing uncertainty",
    "section": "Visualizing Variability",
    "text": "Visualizing Variability\nWhereas point estimates provide statistical information about central tendency and are represented visually using points, bars, or boxes, interval estimates and dispersion measures like standard deviations, standard errors of the mean, confidence intervals, etc. are represented using vertical lines, crossbars, or error bars. {ggplot2} has four geoms for visualizing statistical measures of variability: geom_crossbar(), geom_errorbar(), geom_linerange(), geom_pointrange(). Note: Legends may be hidden for illustrative purposes.\n\nA descriptives() function\nIn order to create some visualizations, we will first summarize the data and then create a base plot to overlay different metrics for examples. We could use group_by(), summarize(), and ungroup() but you can always create your own functions to perform these redundant operations.\nIn order to summarize the data, we will use a custom function I wrote and named descriptives(), which serves as a “Offiziersmesser” (“officer’s knife”, aka Swiss Army Knife), type function for descriptive statistics. This function takes a vector or a data frame and returns the n, mean, trimmed mean, median, standard deviation, standard error, skewness, kurtosis, sum, minimum, maximum, range, interquartile range, median absolute deviation, and confidence interval values for a numeric vector. Both trim and conf can be adjusted as needed.\nWe will also calculate the range of years in order to facilitate the axis scale. And we will also make a simple function to cycle though some colors for making the points in the adjacent years easier to distinguish. We only need to colors for contrasting adjacent years,\nHow does descriptives() work? There are there parts.\n\ndata: the data object, which can be a vector or a data frame/tibble\ngroupby: the grouping parameter leveraging group_by()\nvar: the outcome variable vector for describing statistically\n\nYou can source the function this way:\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz24/main/src/functions/describe.R\")\n\nLet’s get the descriptives() for the SWIM data, grouped by Team and Event for Time.\n\ndescriptives(data = SWIM, \n             groupby = c(Team, Event), \n             var = Time\n             )\n\n# A tibble: 12 × 25\n   Team  Event           n  mean mean.trim   mdn smallest_mode modefreq modeprop\n   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;    &lt;dbl&gt;\n 1 Men   Backstroke      7  90.6      90.6 110.  53.95                1   0.143 \n 2 Men   Breaststro…    11  84.2      82.2  59.4 55.17                1   0.0909\n 3 Men   Butterfly      15  65.6      62.3  52.4 49.66                1   0.0667\n 4 Men   Freestyle      40  81.2      68.3  49.8 21.34                1   0.025 \n 5 Men   IM             10 131.      119.  120.  112.33               1   0.1   \n 6 Mixed Freestyle      15  94.0      93.9  93.5 88.14                1   0.0667\n 7 Mixed Medley         15 104.      104.  104.  97.74                1   0.0667\n 8 Women Backstroke      8 106.      106.  129.  62.81                1   0.125 \n 9 Women Breaststro…     8 108.      108.  109.  62.44                1   0.125 \n10 Women Butterfly      12  89.3      87.6  62.3 57.29                1   0.0833\n11 Women Freestyle      47 142.       92.9 113.  24.16                1   0.0213\n12 Women IM             13 155.      146.  133.  127.94               1   0.0769\n# ℹ 16 more variables: sd &lt;dbl&gt;, se &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;, min &lt;dbl&gt;,\n#   max &lt;dbl&gt;, range &lt;dbl&gt;, iqr &lt;dbl&gt;, q25 &lt;dbl&gt;, q75 &lt;dbl&gt;, mad &lt;dbl&gt;,\n#   sum &lt;dbl&gt;, ci.95l &lt;dbl&gt;, ci.95u &lt;dbl&gt;, ci.99l &lt;dbl&gt;, ci.99u &lt;dbl&gt;\n\n\nAll metrics are lowercase, so if passing the returned object to ggplot(), we can plot the data by mapping mapping = aes(x = Team, y = mean).\n\ndescriptives(SWIM, groupby = c(Team, Event), var = Time) |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  group_by(Team) |&gt;\n  ggplot(mapping = aes(x = Team, y = mean)\n         ) + \n  geom_col() +\n  labs(title = \"Mean Freestyle Swim Time\", y = \"Seconds\")\n\n\n\n\nLet’s assign the returned descriptive statistics to an object for future plots.\n\nSWIM_summary &lt;- descriptives(SWIM, groupby = c(Team, Event), var = Time)\n\nFor the base plot, the one thing that we will want to ensure is to map y = mean and x = Event from the summarized data frame. Keep in mind that the variables from descriptives() are lowercase. We will, however, map other variables to aesthetics as well and in later specific geom_*()s.\nmapping = aes(x = Event, \n              y = mean, \n              fill = Team,\n              col = Team,\n              shape = Team\n              )\n\nswim_base_plot &lt;- SWIM_summary %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       y = mean, \n                       fill = Team,\n                       col = Team,\n                       shape = Team\n                       )\n         )+\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\ngeom_pointrange():\nA geom_pointrange() is quite simply a combination of a geom_point() and a geom_line(). It also provides more detail than a geom_linerange(), which is just a line connecting two points. For both geoms, you will need to specify where the line along the y axis starts and where it ends by mapping variables to ymin and ymax. For these examples, the values will be obtained using descriptives() but you could use {{dplyr}} to subset and summarize the data too. If you want to map other aes()thetics, for example, shape or color, you can do that as well.\ngeom_pointrange(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  fatten = 4,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\ngeom_pointrange() with standard deviation\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  position = position_dodge2(width = 1),\n                  alpha = .8\n                  )\n\n\n\n\nOne positioning issue that you will experience with geom_point() or geom_pointrange() relates to mapping a third variable to col, fill, or shape which were all mapped to Team. You have seen points plotted with these aesthetics before and addressed overplotting before by jittering them. When using geom_pointrange(), you can immediately notice a similar challenge; the points corresponding to the same x-axis position may have overlapping error variability lines. Because the lines are so thin, adjusting opacity will not really fix the problem.\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  position = position_dodge2(width = 1),\n                  alpha = .8\n                  )\n\n\n\n\nAdjusting positioning using position = position_jitter() will move the change point position but will do so that will be inconsistent across the x variable, whether categorical or numeric creating asymmetrical positioning.\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  alpha = .8,\n                  position = position_jitter()\n                  )\n\n\n\n\nThe problem is that jitter functions apply a random jittering for each level of x here. Setting the seed for the process will ensure consistency every function call but will not ensure consistency across each level of the x variable as seen in the plot.\nWhen you really just want the points be get out of each others way, you can use position = position_dodge2() to make the points dodge side-to-side from the central positioning in a symmetrical manner. position_dodge2() relative to position_dodge() also does not require a group to be defined in the geom_*() or the global ggplot() object. However, you will likely need to set width to a value of 1 or less when your x variable is categorical in order to avoid something unappealing. Here are some examples.\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(\n  \n      swim_base_plot + \n        geom_pointrange(mapping = aes(ymin = mean - sd, \n                                      ymax = mean + sd\n                                      ),\n                        alpha = .8,\n                        position = position_dodge2(width = 2)\n                        ) +\n  labs(title = \"position_dodge2(width = 2)\",\n       tag = \"A\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                    alpha = .8,\n                    position = position_dodge2(width = 1)\n                    ) +\n    labs(title = \"position_dodge2(width = 1)\", tag = \"B\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                    alpha = .8,\n                    position = position_dodge2(width = .5)\n                    ) +\n    labs(title = \"position_dodge2(width = .5)\", tag = \"C\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                  alpha = .8,\n                  position = position_dodge2(width = .25)\n                  ) +\n    labs(title = \"position_dodge2(width = .25)\", tag = \"D\"),\n  \n  ncol = 2\n)))\n\n\n\n\nPlot A will not achieve the dodge you desire and something something too small may not lead to enough change in position. Plot Β solves the issue but is challenged by the Gestalt perceptional grouping principle of proximity. If you are curious about these principles in UX design Nielsen Norman Group also has a post on this issue. The dodging associated with width = 1 does not facilitate the grouping of Team at each level of Event because the spacing between Teams for each event is the same as the spacing of Teams across Events. Reduce the dodge so that proximity grouping facilitates plot perception and interpretation. Keep in mind that plot aspect ratios (see here) can also affect positioning and proximity in some cases.\n\n\ngeom_pointrange() with standard error\n\n\ngeom_pointrange() with confidence intervals\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = ci.99l, \n                                ymax = ci.99u\n                                ),\n                  linewidth = .7,  # make the line more prominent\n                  position = position_dodge2(width = .5)\n  ) +\n  coord_flip() +\n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent 99% confidence intervals\\ncircle = Athena\"\n       )   \n\n\n\n\n\n\n\ngeom_linerange():\nA geom_linerange() simply visualizes a line plot that starts at one value and ends at another value.\ngeom_linerange(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\ngeom_linerange() with min and max\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = min, \n                               ymax = max\n                               ),\n                 linewidth = 1  # make the line more prominent\n                 )\n\n\n\n\nSuch a visualization shows clearly where the data start and stop and allow for comparisons. You can also see when data were missing for Events. Out of the box, the bars will overlap, which will require some adjustment.\n\n\ngeom_linerange() with confidence intervals\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = ci.99l, \n                               ymax = ci.99u\n                               ),\n                 linewidth = 1,\n                 position = position_dodge2(width = .5)\n                 ) +\n  coord_flip() +\n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent standard errors of the mean\\nred = Athena\"\n       )   \n\n\n\n\nCompared with geom_pointrange(), geom_linerange() only creates a perceptual grouping based on color. Because there are no points to plot, you cannot also change the shape of the points in order to make the grouping of Team redundant with color and point shape. Redundant encoding is something we will address in another module on designing perceptually-efficient visualizations). If you wish to achieve this redundancy, you will need to vary the lintetype. You can map the aesthetic to Team, set it specifically with scale_linetype_manual(), or code the line type into the data frame and use scale_linetype_identity(). You can specify linetype by name or by number: 0 (“blank”), 1 (“solid”), 2 (“dashed”), 3, 4, 5, 6, etc. When passing values in scale_linetype_manual(), keep in mind this is a vector and vectors can be numeric or character but not both so you cannot mix numbers and strings for line types.\nFor more on line type, read here\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = ci.99l, \n                               ymax = ci.99u,\n                               linetype = Team\n                               ),\n                 linewidth = 1,\n                 position = position_dodge2(width = .5)\n                 ) +\n  scale_linetype_manual(values = c(Men = \"dotted\", Women = \"longdash\", Mixed = \"solid\")) +\n  coord_flip() +\n  \n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent standard errors of the mean\\nred = Athena\"\n       )   \n\n\n\n\n\n\n\ngeom_errorbar():\nError bars are likely the most familiar visual form of of uncertainty you see in data visualization. Error bars represent the measurable error associated with data cases deviating from the distribution’s mean and is most typically the standard error of the mean. Without delving too deeply into concepts of statistics, the standard error of the mean is calculated as standard deviation / square root of the sample size. Although there are libraries like {plotrix} containing functions for it, its calculation is so simple you don’t need to bother with external libraries.\nThe describe() function calculates the standard error of the mean as se.\ngeom_errorbar() will require setting the ymin and ymax values for the error bars. Because the se reflects error around the mean, we will need to add and subtract the se to and from the mean in order to determine its upper and lower limits.\n\ngeom_errorbar() with standard error\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              )\n                )\n\n\n\n\nOut of the box, the bars will overlap and they will can been quite large, thus requiring some adjustment. We will position_dodge2() the bars to prevent overlapping, change the linewidth to be more prominent.\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(),\n                linewidth = .7,\n                width = .3       # make the horizontal bars shorter\n  )\n\n\n\n\n\n\ngeom_errorbar() with confidence intervals\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = ci.99l, \n                              ymax = ci.99u\n                              ),\n                position = position_dodge2(),\n                linewidth = .7, \n                width = .3       # make the horizontal bars shorter\n  )\n\n\n\n\nBefore even adding error bars, this geom_col() represents an excellent example of a pesky problem with out-of-the-box plots containing missing data. In any given data set, you might not have perfectly tidy data frames with data for all variable x variable combinations. For example, you might have data on the number of steps you walk during the morning and the afternoon (two levels of a time factor) for every day of the week (7 measures of another time variable) and you would have 2 x 7 = 14 bars to present in a plot. But if on Saturdays you sleep in past noon, you never have any data for the morning on Saturdays and you will have only 13 bars for your plot.\nThe above plot illustrates what geom_col() does when you have this data imbalance. When both bars are missing, you will see an empty space on the plot. You see that for 2021. But when only half the data are present, a single bar usurps the space of two bars.\n\n\n*Making bars the same width**\nWhen you read the docs for position_dodge() or position_dodge2(), you see that you can set a preserve argument (e.g., “should dodging preserve the”total” width of all elements at a position, or the width of a “single” element?“). Clearly, we want to fix the width using preserve = \"single\". The way that position_dodge() and position_dodge2() handle this aesthetically differs so we can use both for comparison. You can decide what looks better for your own plots.\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(\n    swim_base_plot + \n      geom_col(position = position_dodge(preserve = \"single\")) +\n      labs(title = 'position_dodge(preserve = \"single\"))',\n           tag = \"A\"\n           ),\n    swim_base_plot +\n      geom_col(position = position_dodge2(preserve = \"single\")) +\n      labs(title = 'position_dodge2(preserve = \"single\"))',\n           tag = \"B\"\n           ),\n    ncol = 1\n  )))\n\n\n\n\nThe bars are now all the same width. For position_dodge2(), the single bar is center-aligned whereas position_dodge() aligns it to the left. position_dodge2() seems like a better option.\n\n\nAdd the error bars using geom_errorbar():\nWe now will add the error bars to the plot. Just as we did for geom_linerange(), we will map the ymin and ymax to the for the line to terminate.\n\n\nBars with Standard Errors\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\")) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              )\n                )\n\n\n\n\nOK, This is hideous! The error bars are not positioned with the bars and they are rather wide. To address the positioning, remember that we dodged the bars/columns, specifically using position_dodge2(preserve = \"single\"), so we need to similarly adjust the positioning for the error bars.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = .9,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(preserve = \"single\"),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6, \n                )\n\n\n\n\nJust remember that with multi-layered plots, the layers are added on top of existing ones. Starting with geom_errorbar() and then adding geom_col() will result in the lower portion of the error bars behind masked by the columns, especially if alpha = 1.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = 1,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(preserve = \"single\", width = 1),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6\n                ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    )\n\n\n\n\n\n\n\nConfidence Intervals\nWe will create the same plot using confidence intervals.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = .8,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  geom_errorbar(mapping = aes(ymin = ci.99l, \n                              ymax = ci.99u\n                              ),\n                position = position_dodge2(preserve = \"single\"),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6\n                ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Mixed = \"grey60\"\n                               )\n                    ) +\n  labs(title = \"Mean Time for Events in 2023\",\n       tag = \"\",\n       x = NULL, y = \"Seconds\",\n       caption = \"M = blue, F = red, Medley = grey\\nbars = 99% CI\"\n      )\n\n\n\n\nThe geom_pointrange() may likely be a better visualization of the data than the geom_errobar() paired with geom_col()."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#model-uncertainty-using-a-table",
    "href": "modules/visualizing_uncertainty.html#model-uncertainty-using-a-table",
    "title": "Visualizing uncertainty",
    "section": "Model Uncertainty Using a Table",
    "text": "Model Uncertainty Using a Table\n\nlm.beta::lm.beta(fit) |&gt;\n  broom::tidy() |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd_estimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.0290832\nNA\n1.6497412\n-0.017629\n0.9860556\n\n\nSplit50\n2.0817834\n0.9857743\n0.0659113\n31.584599\n0.0000000\n\n\n\n\n\nThe tables contain the model coefficients to quantify elements like the linear relationship between the variables, the error or uncertainty in the model fit, etc. We can see that Split50 predicts the Time for the 100 Freestyle. The association is not perfect, however. There is some error, or uncertainty, in the model as indicated by the model std.error.\nConfidence Intervals for Model Fit\n\nconfint(fit) |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-3.403183\n3.345016\n\n\nSplit50\n1.946980\n2.216587\n\n\n\n\nlm.beta::lm.beta(fit) |&gt;\n  confint() |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\nNA\nNA\n\n\nSplit50\n0.8509705\n1.120578"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#model-uncertainty-using-a-plot",
    "href": "modules/visualizing_uncertainty.html#model-uncertainty-using-a-plot",
    "title": "Visualizing uncertainty",
    "section": "Model Uncertainty Using a Plot",
    "text": "Model Uncertainty Using a Plot\nLet’s apply geom_smoth() to add a fit line.\n\nplot_lm &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\"\n              ) +\n  theme_light()\n\nplot_lm\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can see the linear model fit as a line and the shaded area around that fit line indicates uncertainty of the model parameters. Because the model is not perfect, there is uncertainty about the true fit. Looking at ?geom_smooth, you will see the argument for level = 0.95 which helps define the uncertainty to visualize. Specifically, it defines the width of the shaded bands around the linear regression line in the plot. The bands represent the range within which the true regression line should lie given some degree of confidence. Thus, with level = 0.95, the confidence interval of 95%. We can see a different version by changing the level = .99 for a 99% confidence interval.\n\nplot_lm99 &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\",\n              level = .99\n              ) +\n  theme_light()\n\nplot_lm99\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe bands are wider now because they are more likely to capture the true population parameter predicted by the model. The bands can vary in width based on the number of data points contributing to the prediction of y at any given x value but the bands will be most narrow at the model centroid (the point corresponding to the mean of x and the mean of y). Mapping aesthetics to a new point will illustrate this. The model needs to pass through this point.\naes(x = mean(FREE_100$Split50), \n    y = mean(FREE_100$Time)\n    )\n\nplot_lm &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\"\n              ) +\n  theme_light() +\n  geom_point(aes(x = mean(FREE_100$Split50), \n                 y = mean(FREE_100$Time)\n             ),\n             size = 10, \n             shape = \"*\",\n             col = \"blue\"\n  )\n\nplot_lm\n\nWarning in geom_point(aes(x = mean(FREE_100$Split50), y = mean(FREE_100$Time)), : All aesthetics have length 1, but the data has 31 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can remove the model error from the plot using se = FALSE but but doing so is not very honest communication.\n\nFREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              se = FALSE,\n              col = \"firebrick\"\n              ) +\n  theme_light()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nBut even if a linear model did fit the data perfectly, the set of coefficients obtained were from a single model and that single model is based on the athletes who participated in events. What would the model look like if it did not include just those athletes but instead includes athletes who were sick and sat the sidelines or those who could have been disqualified for some reason?"
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#bootstrap-models",
    "href": "modules/visualizing_uncertainty.html#bootstrap-models",
    "title": "Visualizing uncertainty",
    "section": "Bootstrap Models",
    "text": "Bootstrap Models\nrsample::bootstraps() will allow us to take samples from the full data set and run multiple models using various subsets of that full data set. Doing so will provide models that do not include best athletes, do not include worst athletes, include various mixtures, etc. The goal is not to teach bootstrapping methods but to help you understand how models are fit and how they differ, thus illuminating uncertainty in a different way than with geom_smooth(). The code is not provided as this just illustrates a plot of bootstrapped models.\nYou can see some bootstrapped mode coefficients here.\n\n\n# A tibble: 6 × 8\n  splits          id           model term  estimate std.error statistic  p.value\n  &lt;list&gt;          &lt;chr&gt;        &lt;lis&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 &lt;split [31/10]&gt; Bootstrap00… &lt;lm&gt;  (Int…    0.282    0.929      0.304 7.63e- 1\n2 &lt;split [31/10]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.06     0.0374    55.0   6.97e-31\n3 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  (Int…   -0.644    1.32      -0.487 6.30e- 1\n4 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.10     0.0521    40.3   5.10e-27\n5 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  (Int…   -0.142    1.33      -0.107 9.16e- 1\n6 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.08     0.0543    38.3   2.14e-26\n\n\nBecause there are more than one model, we can visualize distributions of the coefficients as a histogram.\n\n\n\n\n\nThe mean and the standard deviation of the bootstrapped models:\n\n\n\n\n\nterm\nestimate_mean\nestimate_sd\n\n\n\n\n(Intercept)\n-0.11\n1.39\n\n\nSplit50\n2.08\n0.06\n\n\n\n\n\nCompare the mean with the coefficient from the single model:\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.03\n1.65\n-0.02\n0.99\n\n\nSplit50\n2.08\n0.07\n31.58\n0.00\n\n\n\n\n\n\nPlotting Bootstrapped Model Fits (Variants)\n\n\n\n\n\nEach model fit is plotted as a very this light red line in the plot. In fact, there are 1000 different models fit through the points. Because each model includes a difference subset of athletes, the mean of the variables will differ based on the data used for each model. Thus, each model has its own centroid so there is no single point through which all models must pass. Nevertheless, you can see the most narrow part and darkest coloring (indicating more lines overlapping) of the band is located near the location of the original centroid. Also, upper right part of the plot is lighter than the lower left because there are fewer points in the upper right and thus there is corresponding uncertainty to visualize."
  },
  {
    "objectID": "modules/visualizing_uncertainty.html#plotting-model-error-bars",
    "href": "modules/visualizing_uncertainty.html#plotting-model-error-bars",
    "title": "Visualizing uncertainty",
    "section": "Plotting Model Error Bars",
    "text": "Plotting Model Error Bars\nUsing {tidyr} we can create nested subsets of data using tidyr::nest() and then we can run models an each subset. We can group using .by and pass a vector of variable names for grouping. Make sure that you don’t have NAs in your data frames.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance))\n\nThe first instance is in data.\n\nnested$data[[1]]\n\n# A tibble: 14 × 8\n    Year School                    Team  Relay Name    Age  Time Split50\n   &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA  97.7    26.4\n 2  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 101.     24.4\n 3  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 102.     24.1\n 4  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 102.     25.0\n 5  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 103.     24.4\n 6  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 103.     27.5\n 7  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 104.     28.5\n 8  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 104.     26.8\n 9  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 104.     25.8\n10  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 104.     24.8\n11  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 105.     25.4\n12  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 106.     29.9\n13  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 107.     30.4\n14  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 113.     30.9\n\n\nYou see we have a tibble that contains nested subsets of data. There are not much data for some events but the goal is only to show how to visualize model error. We will now us Base R lapply() to apply a function to a list. For each nested data frame, the data will be .x. The model fit is returned and\n\nSWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                )\n                )\n\n# A tibble: 9 × 4\n  Event        Distance data              models\n  &lt;chr&gt;           &lt;dbl&gt; &lt;list&gt;            &lt;list&gt;\n1 Medley            200 &lt;tibble [14 × 8]&gt; &lt;lm&gt;  \n2 Butterfly         100 &lt;tibble [19 × 8]&gt; &lt;lm&gt;  \n3 Freestyle         200 &lt;tibble [49 × 8]&gt; &lt;lm&gt;  \n4 Breaststroke      100 &lt;tibble [11 × 8]&gt; &lt;lm&gt;  \n5 Backstroke        100 &lt;tibble [6 × 8]&gt;  &lt;lm&gt;  \n6 Backstroke        200 &lt;tibble [9 × 8]&gt;  &lt;lm&gt;  \n7 Freestyle         100 &lt;tibble [31 × 8]&gt; &lt;lm&gt;  \n8 Breaststroke      200 &lt;tibble [8 × 8]&gt;  &lt;lm&gt;  \n9 Butterfly         200 &lt;tibble [8 × 8]&gt;  &lt;lm&gt;  \n\n\nGreat! We have a tibble of linear models for each Event and Distance pair. Using the {broom} library, perform some model cleaning using broom::tidy() to return a cleaned model and assign it as a column in the tibble. Using lapply, apply the broom::tidy() function on each model in the list. Finally, because the models are nested, tidyr::unest() them.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                ),\n                tidy_mods = lapply(X = models, FUN = broom::tidy)\n                ) |&gt;\n  tidyr::unnest(cols = tidy_mods)\n\nThe tibble is messy, so let’s clean it up a bit by removing the intercept term. Also, we don’t need columns like models or data.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                ),\n                tidy_mods = map(models, broom::tidy)\n                ) |&gt;\n  tidyr::unnest(cols = tidy_mods) |&gt;\n  filter(term != \"(Intercept)\") |&gt;\n  select(-c(models, data))\n  \n\nnested  \n\n# A tibble: 9 × 7\n  Event        Distance term    estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Medley            200 Split50     1.03    0.298       3.45 4.80e- 3\n2 Butterfly         100 Split50     1.98    0.0624     31.7  1.46e-16\n3 Freestyle         200 Split50     4.15    0.319      13.0  3.67e-17\n4 Breaststroke      100 Split50     2.15    0.0868     24.7  1.38e- 9\n5 Backstroke        100 Split50     1.69    0.0740     22.8  2.18e- 5\n6 Backstroke        200 Split50     4.27    0.348      12.3  5.43e- 6\n7 Freestyle         100 Split50     2.08    0.0659     31.6  5.16e-24\n8 Breaststroke      200 Split50     3.76    0.427       8.80 1.20e- 4\n9 Butterfly         200 Split50     3.94    0.960       4.10 6.35e- 3\n\n\nSo we now have a tibble with nested model coefficients. We can visualize some of the models and their errors. In the tibble, estimate is the estimate and std.error is the error. We can create a 95% confidence interval with lower and upper bounds by subtracting and adding 1.96*std.error (use 1.645 for 90% CI or 2.576 for a 99% CI). Map the color to the Distance column.\n\nnested |&gt;\n  mutate(Distance = as.character(Distance)) |&gt;\n  ggplot(mapping = aes(\n    x = Event, y = estimate,\n    ymin = estimate - 1.96*std.error,\n    ymax = estimate + 1.96*std.error,\n    col = Distance\n  )) +\n  geom_pointrange(position = position_dodge2(width = .5)\n  ) +\n  scale_y_continuous(n.breaks = 20) + \n  theme(legend.position = \"top\")\n\n\n\n\nUsing the {ggdist} and {distributional} libraries, we can plot the distributions of errors as well.\n\nnested |&gt;\n  mutate(Distance = as.character(Distance)) |&gt;\n  ggplot(mapping = aes(x = estimate, y = Event, col = Distance)) +\n  ggdist::stat_dist_halfeye(\n    mapping = aes(dist = distributional::dist_normal(\n      mu = estimate, \n      sigma = std.error)\n  ),\n  point_size = 3\n  )"
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_git.html",
    "href": "modules_setup/Installation & Setup/installing_git.html",
    "title": "Installing Git",
    "section": "",
    "text": "The goal is to install Git on your system, if necessary. We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\nComplete by the start of the first day of class.\n\nDownload Git (if not already installed)\nInstall Git on your computer (if not already installed)\nMake note of where you installed it. If RStudio does not recognize Git.exe on its own, you will need to supply the directory path.\n\nFollow steps below to complete."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_git.html#overview",
    "href": "modules_setup/Installation & Setup/installing_git.html#overview",
    "title": "Installing Git",
    "section": "",
    "text": "The goal is to install Git on your system, if necessary. We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\nComplete by the start of the first day of class.\n\nDownload Git (if not already installed)\nInstall Git on your computer (if not already installed)\nMake note of where you installed it. If RStudio does not recognize Git.exe on its own, you will need to supply the directory path.\n\nFollow steps below to complete."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_git.html#installing-git",
    "href": "modules_setup/Installation & Setup/installing_git.html#installing-git",
    "title": "Installing Git",
    "section": "Installing Git",
    "text": "Installing Git\n\nDo I need to install Git?\n\nMac OS Users can check whether Git is already installed by typing git --version at the Mac Terminal. If a version number is returned, then Git is installed.\nWindows Users can press the Windows key (or click the Start button) and type Git in the search bar. If you see Git or Git Bash listed, then Git is installed. At the R console, you can also type system(\"git --version\") and if it is installed, the function should return the version number.\n\nDownload and Install Git (if necessary)\n\nMac OS Users can open their Terminal and type xcode-select --install. If you do not know how to open a terminal, see this link. If that approach does not work, you can visit the Git download site and follow instructions. If you try the Homebrew approach and experience problems, you may need to set a PATH variable. Students have reported to me that you do not need to do that. Instead, you can follow instructions to download the binary version referenced on the Git page.\nWindows Users can download the latest version of Git here. Download and install Git, making a note of where on your computer you are install it as you may need to locate the path for RStudio, especially if you use a portable version of Git."
  },
  {
    "objectID": "modules_setup/Installation & Setup/installing_git.html#git-what-is-git-why-go-through-the-trouble",
    "href": "modules_setup/Installation & Setup/installing_git.html#git-what-is-git-why-go-through-the-trouble",
    "title": "Installing Git",
    "section": "Git: What is Git? Why Go Through the Trouble?",
    "text": "Git: What is Git? Why Go Through the Trouble?\nProjects are rarely done without collaborators. Teams collaborate, leveraging team members’ work and accomplishments. Using R in conjunction with the a distributed version control system, like Git, will facilitate that collaboration process. Writing flexible R code that does not hard-code objects will allow your research project to be reproducible, for example, when variables and data change (e.g., new data added, a new year added, etc.). Git long with GitHub will allow you to track your edits (the version control) and share your code with your collaborators or interested scholars.\nSome benefits of using version control:\n\nMakes reverting back to previous states easy. You can easily revert back to a previous version of your code in the event you discover errors or you delete critical details accidentally.\nServes as a memory for edits when memory fails. All changes across different versions of your code or written content is available.\n\nFacilitates project sharing\nFacilitates collaboration. Others can also report errors or suggest features to your project.\n\nRStudio integrates support for Git but this interface is a little clunky. You can use it but RStudio also allows for communication via the command line Terminal, which will be the preferred method shared here.\nAll of the aforementioned benefits of Git will not experienced in this course. For your team project, the code lead will manage the repository on their own using the work contributed by the team. Although we will not cover much branching in this course, having some practice interacting with a remote repository is important for data science students and students pursuing graduate study that involves working with data. As such, you will manage your own repository for your personal class exercises."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html",
    "href": "modules_setup/R Basics/functions_and_scripts.html",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "A good friend of mine was once tried using R to summarize data. He couldn’t figure out why he could not use a function called mean() to calculate the mean of variables in his data set. Yes, mean() does compute a mean but he did not understand the object for which he was trying to compute a mean. When I explained the issue to him, he told me that he would often try to ‘brute force’ his way into obtaining results. He did not understand how the function worked and was not very concerned with learning. Without knowing how functions work, you limit yourself to troubleshoot answers and you spend a lot of time troubleshooting errors. You cannot just brute force yourself into data science or running models without getting yourself into trouble.\nAlthough the R language differs from other languages like Python, JavaScript, or HTML, the concepts covered is this section may be redundant for student who have taken a computer-science class. For beginners, the concepts may initially be challenging or confusing. You may even question why we cannot just jump into data manipulation and why all of this matters. In order to code in R so that you can be comfortable using it and with communicating with other users, a very basic understanding of programming concepts is important. This way, when someone asks you about an object, function, or assignment, you will know what they are taking about. And, well, you cannot communicate with R without knowing how functions work at a basic level.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\nR Workflow Basics\nHuber: Functions\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence.\n\n\n\n\n\n{here} 1.0.1: for file path management\n\n\n\n\nview_html(): for viewing data frames in html format\nYou can access remotely using this code, though you do not need to do so now.\nsource(https://raw.githubusercontent.com/slicesofdata/dataviz24/main/modules/src/functions/view_html.R)"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#readings-and-preparation",
    "href": "modules_setup/R Basics/functions_and_scripts.html#readings-and-preparation",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#supplementary-readings",
    "href": "modules_setup/R Basics/functions_and_scripts.html#supplementary-readings",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "R Workflow Basics\nHuber: Functions\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#libraries",
    "href": "modules_setup/R Basics/functions_and_scripts.html#libraries",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "{here} 1.0.1: for file path management"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#external-functions",
    "href": "modules_setup/R Basics/functions_and_scripts.html#external-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "view_html(): for viewing data frames in html format\nYou can access remotely using this code, though you do not need to do so now.\nsource(https://raw.githubusercontent.com/slicesofdata/dataviz24/main/modules/src/functions/view_html.R)"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#examples-of-objects",
    "href": "modules_setup/R Basics/functions_and_scripts.html#examples-of-objects",
    "title": "Functions, Arguments, and R scripts",
    "section": "Examples of objects",
    "text": "Examples of objects\nYou can also think of an object as a sort of container that holds something. Containers of different types hold different things and so is true in computer programming. A container for holding water may look different from a container for holding books. In computer speak, one type of container can hold numbers, another can hold characters, another can hold a data frame, etc. The container object is holding whatever you have assigned it to hold.\nWe will deal with different types of objects in data science. Without providing too complicated or technical of descriptions, some are described below.\n\nnumeric objects: representing numeric information (e.g., one’s age)\ncharacter objects: representing character information (e.g., one’s name or race)\nvector objects: representing more than one numeric object (e.g., ages of participants)\ndata frame objects: containing vectors of data (e.g., column variables and row instances of data)\nfunction objects: that accept one object and return an other object (e.g., the mean of numeric vector)\n\nThere are other type of objects that you will learn about and encounter but for now, those are the most relevant."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#a-character-example",
    "href": "modules_setup/R Basics/functions_and_scripts.html#a-character-example",
    "title": "Functions, Arguments, and R scripts",
    "section": "A character example",
    "text": "A character example\nLet’s start with an example of an object called name, which we would like to assign a set of characters, like Jim Bob.\nIn order to create such an object, we would need to place the characters within quotation marks (e.g., single or double, does not matter). The quotes let R know the contents of name are characters (aka strings).\n\"Jim Bob\"\nWhen dealing with data, you will encounter many character objects as they often represent factor variables (e.g., race, ethnicity, favorite game, etc.) but you will also see lots of objects that are numeric in some form (e.g., age, rating, cognitive performance, etc.)."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#assignment-provides-meaning-or-definition",
    "href": "modules_setup/R Basics/functions_and_scripts.html#assignment-provides-meaning-or-definition",
    "title": "Functions, Arguments, and R scripts",
    "section": "Assignment provides meaning or definition",
    "text": "Assignment provides meaning or definition\nAssignment is akin to creating a new word and assigning a meaning to it. You could also think of an assignment statement as a way to tell R to “create this thing and set it equal to something” so that the computer understand what association represents."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#a-character-object-a-silly-example",
    "href": "modules_setup/R Basics/functions_and_scripts.html#a-character-object-a-silly-example",
    "title": "Functions, Arguments, and R scripts",
    "section": "A character object: A silly example",
    "text": "A character object: A silly example\nIf objects are like containers holding things, we can use name of the object (e.g., container) and then assign \"things\" to it using &lt;-. In order to create a character object, we would need to place the characters within quotation marks (e.g., single or double, does not matter). The quotes let R know the contents of container are characters (aka strings).\n\"things\"\nWhen dealing with data, you will encounter many character objects as they often represent factor variables (e.g., race, ethnicity, favorite game, etc.) but you will also see lots of objects that are numeric in some form (e.g., age, rating, cognitive performance, etc.).\nSilly Example:\n\n\"something\" assigned to container\ncontainer &lt;- \"something\"\n\n\ncontainer &lt;- \"things\"\n\nAnd to see its contents, use print() to return the objects content:\n\nprint(container)\n\n[1] \"things\"\n\n\nOr just type the name of the object and you will see the returned object is \"things\".\n\ncontainer\n\n[1] \"things\"\n\n\nFor another example, we could also create an object called name, which we could assign a set of characters, like Jim Bob, making the object a character object.\n\nname &lt;- \"Jim Bob\"\n\nTo see what is returned:\n\nname\n\n[1] \"Jim Bob\"\n\n\nWhether you name is or is not Jim Bob, you can see that name contains the characters that represent the name of someone named “Jim Bob”. Although we assigned \"Jim Bob\" to name, we could have assigned it a given name. The assignment process simply stores the assigned information as an object using of whatever name you decided to call it (e.g., name, Name, NAME, xyz, etc.). We will discuss more on these letter casing differences later.\nYou could also assign the character to the object this way.\n\n\"things\" -&gt; container\n\nHowever, we won’t use much of this approach for different reasons. One reason is that doing so does not follow the R Style Guide. The style guide defines a set of guidelines for coding in R. Rather than memorize all of the styling, pay careful attention to the way code appears in the examples provided and try your best to model your code after the examples. For example, don’t do something this container&lt;-\"things\" just so you save space as doing so makes the code more difficult for you and others to read and understand.\nOK, back to Jim Bob. Of course, there are different people other than Jim Bob who exist in the world but when coding, they do not exist unless you create them. So, let’s create an object that holds the name of \"Jim Bob\".\nname &lt;- \"Jim Bob\"\n\nname &lt;- \"Jim Bob\"     # assign string to object named name\n\n\nName &lt;- \"Jim Bob\"     # we could have assigned it a different name, say Name\n\n\nNAME &lt;- \"Jim Bob\"     # or assigned it in all caps\n\nWhenever you reference the object name (or Name), R will return the contents of the object to you, which in this case will be a character or string object containing a single person’s name because that’s how we assigned it.\n\nname               # call object to return contents of \"name\"\n\n[1] \"Jim Bob\"\n\n\nAnd again, we can use print() to do the same thing:\n\nprint(name)\n\n[1] \"Jim Bob\"\n\n\n\nBeing mindful of case sensitivity\nA word of warning is needed here. Although name, Name, and NAME all contain the same four characters, n a m and e all arranged it he same order, the objects are all different. They just happen to hold the same content. The reason for there being three different object is because R is a case-sensitive language, which means that the letter case matters. In some programming languages, the case is ignored.\nTo illustrate, consider an example for which you assign different names to the object.\nname &lt;- \"Jim Bob\"     # create the object\n\n\nName &lt;- \"Bob\"         # then change it\n\n\nNAME &lt;- \"Jim\"         # then change it again\nIn those languages, if you asked what the name object contained, the program would return \"Jim\" because these characters were assigned last, even though they were assigned to an uppercase version, NAME. With R, you will need to be mindful of the letter case. This is by design, perhaps an advantage rather than a disadvantage."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#a-numeric-object",
    "href": "modules_setup/R Basics/functions_and_scripts.html#a-numeric-object",
    "title": "Functions, Arguments, and R scripts",
    "section": "A numeric object",
    "text": "A numeric object\nWhat about numeric information? We can create an object called year and assign the current year to it; let’s have this object contain the current year in numeric form, not as a string. Remember to use &lt;- for assignment.\n\nyear &lt;- 2024    # assign a number to year ; notice no quotes\n\nIn order to know whether this year object now contains the year, we can check by typing the name of the object or use print() to print the returned value.\n\nyear\n\n[1] 2024\n\nprint(year)\n\n[1] 2024"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#inspecting-vectors-with-some-functions",
    "href": "modules_setup/R Basics/functions_and_scripts.html#inspecting-vectors-with-some-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "Inspecting vectors with some functions",
    "text": "Inspecting vectors with some functions\nname and year are very simple objects. name is a simple character/string object we created, which contains only the name of 1 person and year only holds the current year. There is something else important about how R treats them that you cannot see on the surface. Both of these objects are also vectors. Vectors are one-dimensional arrays containing n pieces of information. You might also think of a vector so a variable (e.g., IQs of people). Both the name and year vectors contain only one piece of information, however. If you don’t believe me, we can use some functions that will answer this for us.\n\nis.vector() is a function that returns a logical (T or F) about whether the object is a vector\nlength() is a function that returns a non-negative numeric integer representing the number of elements contained\ntypeof() is a function that returns the object’s type\n\nLet’s try them by passing the object name inside the function.\n\nis.vector(name)   # is it a vector?\n\n[1] TRUE\n\n#?length\nlength(name)      # how many elements?\n\n[1] 1\n\ntypeof(name)      # what is it's type?\n\n[1] \"character\"\n\n\nIf name contained more than one object, it would still be a vector having a different length. But in order to create such vectors, each element of the vector needs to be separated by a comma and each elements needs to be wrapped by quotes.\nIf you do not separate strings by a comma…\n\nname &lt;- \"Jim Bob Kendra\"\n\n\nname                                # return object; also print(name)\n\n[1] \"Jim Bob Kendra\"\n\nis.character(name)                  # is it a character?\n\n[1] TRUE\n\nlength(name)                        # what is its length?\n\n[1] 1\n\n\nIf you do use quotes for each element and separate each by a comma, you need to use a function to combine them, which is c().\n\nname &lt;- c(\"Jim Bob\", \"Kendra\")  # two names, combine with c()\n\n\n\nis.character(name)        \n\n[1] TRUE\n\nlength(name)                   # vector with length 2\n\n[1] 2\n\n\nThe more you work with character vector, the more you way want to avoid some annoyances of creating them.\nThe {Hmisc} library has a function called Cs() that obviates the inclusion of the quotes.\n\nHmisc::Cs(Jim, Kendra, Bill, Sandy)\n\n[1] \"Jim\"    \"Kendra\" \"Bill\"   \"Sandy\" \n\n\nBeware of vectors containing elements with space like this:\nHmisc::Cs(Jim Bob, Kendra)\nR will throw an error to inform you that something is wrong. For example: Error: unexpected symbol in \"Hmisc::Cs(Jim Bob\"."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#elements-of-vectors",
    "href": "modules_setup/R Basics/functions_and_scripts.html#elements-of-vectors",
    "title": "Functions, Arguments, and R scripts",
    "section": "Elements of vectors",
    "text": "Elements of vectors\nAs a side note, the pieces/values of a vector are referred to as elements. You can reference elements by number representing their position in the vector.\n\nname[1]   # first element\n\n[1] \"Jim Bob\"\n\nname[2]   # second element\n\n[1] \"Kendra\"\n\nname[3]   # a third element? No. It only has length 2\n\n[1] NA\n\n\nObjects in R, however, can take on many forms other than strings or numbers just illustrated. Objects can be strings/characters, numeric values, character strings, functions, data frames, vectors, lists, matrices, plots, etc. If you use typeof() on a data frame object, the function will return \"list\" because a data frame is also a list. More on this later."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#creating-a-.r-script-file-to-source",
    "href": "modules_setup/R Basics/functions_and_scripts.html#creating-a-.r-script-file-to-source",
    "title": "Functions, Arguments, and R scripts",
    "section": "Creating a .R script file to source()",
    "text": "Creating a .R script file to source()\nThere are a few ways to create files for your R project. You can do so easily from RStudio or you can do so more quickly using Git.\n\nCreating a .R script using RStudio\nYou can easily create an .R script file from RStudio. You are most likely familiar with this file creation process.\nFirst, go to File &gt; New File &gt; R Script\nSecond, File &gt; Save As, browse to the projects /r directory, name it my_first_script.R and click save.\nIn it, type message(\"My first script file.\") and save it as my_first_script (the .R should be automatic) in your \"/src\" directory.\nYour file will be written to the /src directory and will be opened in RStudio.\nBecause the .Rmd file you are working with is already saved in \"/src\" (if you saved it there correctly), you can source the file by name.\n\n\nCreating a .R script file using the Terminal\nFirst, go to your Terminal in RStudio. This is located by the Console tab and is the same place you type your Git commands.\nSecond, you can use the touch function to create the file. You will want to specify the directory to write the file and the name of the file to write.\nThird, to create a file named my_first_script.R, type:\ntouch src/my_first_script.R and your file will be written to the r/ directory.\nTo open the file in RStudio, the easiest way to go to the Files pane in RStudio, locate it and click it so that it appears as an open tab.\nIf you want to add it to Git, type:\ngit add src/my_first_script.R and it will be staged.\nIf you misspelled the file name and want to delete it, or just need to delete it for some reason, you can type:\nrm src/my_first_script.R\nTo delete it and remove from Git, type:\ngit rm src/my_first_script.R"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#adding-code-to-the-script-file",
    "href": "modules_setup/R Basics/functions_and_scripts.html#adding-code-to-the-script-file",
    "title": "Functions, Arguments, and R scripts",
    "section": "Adding code to the script file",
    "text": "Adding code to the script file\nWe will now add code to the file. To demonstrate how this works, let’s just add a message to the file using message() which is a simple stand-in for a bunch of lines of code.\nIn the script file, type:\nmessage(\"My first script file.\")\nNote: Make sure you save the file."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#sourcing-the-script-file",
    "href": "modules_setup/R Basics/functions_and_scripts.html#sourcing-the-script-file",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing the script file`",
    "text": "Sourcing the script file`\nNow, to run the code saved in my_first_script.R, we will source() the file by specifying the path to it using {here}.\nsource(file = here::here(\"src\", \"my_first_script.R\"))\nBut you can omit using file because you are only passing one argument and it’s file.\n\nsource(here::here(\"src\", \"my_first_script.R\"))\n\nMy first script file."
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#sourcing-multiple-script-files",
    "href": "modules_setup/R Basics/functions_and_scripts.html#sourcing-multiple-script-files",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing multiple script files",
    "text": "Sourcing multiple script files\nWhen you have multiple files to source(), you can source them individually, making sure that they are ordered in the order you wish to run them. They will execute line by line.\nsource(here::here(\"src\", \"read_data.R\"))\nsource(here::here(\"src\", \"clean_data.R\"))\nsource(here::here(\"src\", \"create_plots.R\"))\nYou can also create a new .R script file that contains the above three lines of source code and add them to another file, named appropriately like read_clean_plot_data.R. and then source that file like this:\nsource(here::here(\"src\", \"read_clean_plot_data.R\"))"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#sourcing-all-files-in-a-directory",
    "href": "modules_setup/R Basics/functions_and_scripts.html#sourcing-all-files-in-a-directory",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing all files in a directory",
    "text": "Sourcing all files in a directory\nIf all those files to source are in a directory, you can use a special source function from {R.utils} R.utils::sourceDirectory(). For example, if you have all of personal or project-related functions nicely organized in a directory like src/funcions/, you can easily source it like this. The benefit here is that you don’t have to specify all of the files individually.\n\nR.utils::sourceDirectory(here::here(\"src\", \"functions\"))"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#an-alternative-to-view",
    "href": "modules_setup/R Basics/functions_and_scripts.html#an-alternative-to-view",
    "title": "Functions, Arguments, and R scripts",
    "section": "An alternative to View()",
    "text": "An alternative to View()\nAs an alternative to View(), a function that I wrote using the {DT} library to display the data in an HTML table that allows you to sort the data.\n\nview_html() (lowercase v): returns an filterable html table of the data frame; my alternative to View()\n\nIf you want to use this function, you can source() the raw code from the course site using the code below. Because I use this function often, you might wish to add it to your /src/functions/ directory and simply source all of the files in that directory as describe above.\nsource(https://raw.githubusercontent.com/slicesofdata/dataviz24/main/modules/src/functions/view_html.R)"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#getting-the-head-of-a-data-frame",
    "href": "modules_setup/R Basics/functions_and_scripts.html#getting-the-head-of-a-data-frame",
    "title": "Functions, Arguments, and R scripts",
    "section": "Getting the head() of a data frame`",
    "text": "Getting the head() of a data frame`\nIf you query the function in the console by typing using ?head or help(head), you will see in there are two main parameters.\nParameters/Arguments:\n\nx: a vector or data frame object\nn: a value of the indices to be selected (e.g., elements of vector, rows in data frame)\n\nhead() needs an object x in order to do anything. We can pass the USArrests data frame as the argument and if all goes well, we will only see the top or head of this data frame.\n\nhead(x = USArrests)   # 6 rows by default\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nAnd if you pass arguments to parameters in function according to their order (e.g., position), you do not need to reference the parameters by name when passing arguments. For example, we can remove the reference to x.\n\nhead(USArrests)   # 6 rows by default\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nThe second parameter for head() is n, the number of rows for the function to return. The default number was 6. We can change the default operation by passing 3 as the argument to it.\nBut as long as we pass the arguments to x and then to n, then we do not need to reference either by name. Instead, we can just pass the arguments.\nBut if you change order, you will need to reference the arguments. You cannot call head(3, USArrests) for example but you can call head(n = 3, x = USArrests). You normally would not wish to change the order of arguments for head() but for more complicated functions, you might wish to for different reasons.\nUsing the viewing options:\n\n#View(USArrests)                            # the standard viewer\n\n#view_html(USArrests, rows = T, show = 5)   # but same as \n\n#view_html(head(USArrests), rows = T)"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#checking-whether-an-object-is-a-data-frame-using-is.data.frame",
    "href": "modules_setup/R Basics/functions_and_scripts.html#checking-whether-an-object-is-a-data-frame-using-is.data.frame",
    "title": "Functions, Arguments, and R scripts",
    "section": "Checking whether an object is a data frame using is.data.frame()",
    "text": "Checking whether an object is a data frame using is.data.frame()\nYou can also check whether the USArrests data file is a data frame using is.data.frame(), which will return TRUE indicating that it is indeed a data frame.\n\nis.data.frame() returns logical ( T or F) about data frame as two-dimensional array"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#checking-the-structure-of-a-data-frame-using-str",
    "href": "modules_setup/R Basics/functions_and_scripts.html#checking-the-structure-of-a-data-frame-using-str",
    "title": "Functions, Arguments, and R scripts",
    "section": "Checking the structure of a data frame using str()",
    "text": "Checking the structure of a data frame using str()\nThat seems tedious, however. You can learn a lot more about the data frame by examining its structure using str(). The USArrests object is a data frame, contains 50 observations (e.g., rows) and 4 variables (columns). All column variables appear to contains numbers, with two of them being numeric, abbreviated num and two are integers, abbreviated int.\n\nstr() returns the structure of a data frame"
  },
  {
    "objectID": "modules_setup/R Basics/functions_and_scripts.html#using-other-functions",
    "href": "modules_setup/R Basics/functions_and_scripts.html#using-other-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "Using other functions`",
    "text": "Using other functions`\nAnd you can check the names of the columns using names(). What is actually returned to you is a character vector, or a vector whose elements are of character type. You can test whether the column names is a vector by wrapping names() with the is.vector() function. Similarly, wrapping names() in typeof() will tell you the type is character.\n\nnames(): returns names of data frame\nis.vector(): returns logical if/if not a vector (see other is. functions)\ntypeof(): returns the type of the object\n\n\nnames(USArrests)           # get the names of the columns?\n\n[1] \"Murder\"   \"Assault\"  \"UrbanPop\" \"Rape\"    \n\nis.vector(names(USArrests))\n\n[1] TRUE\n\ntypeof(names(USArrests))   # get the type of structure are the names\n\n[1] \"character\""
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#readings-and-preparation",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#readings-and-preparation",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#supplementary-readings",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#supplementary-readings",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Supplementary Readings",
    "text": "Supplementary Readings"
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#libraries",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#libraries",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management\n{rmarkdown} 2.27: for creating markdown files"
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-is-an-interpreted-language",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-is-an-interpreted-language",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "R is an Interpreted Language",
    "text": "R is an Interpreted Language\nR is an interpreted language. This means that code or programs you write may be executed by the R interpreter in real time. The code you write does not need to be compiled prior to being executed. Rather, the R interpreter translates your code in real time if it understands your code. If the R interpreter doesn’t understand your code, it will be unable to translate and you will receive some error."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#functions",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#functions",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Functions",
    "text": "Functions\nThe code you write for the interpreter will involve referencing functions. You have used a function already when installing libraries (e.g., install.packages(). A function is nothing more than a set of statements organized together to perform some desired operation. In R, a function is an object. This means the R interpreter passes control to the function, along with any arguments that are necessary for the function to perform that operation and return the result of that operation."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#a-function-example",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#a-function-example",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "A Function Example",
    "text": "A Function Example\nFor example, reading a file into R involves using a function that performs that operation. For these functions to read a file containing data, you will need to specify the required and/or optional arguments for given parameters of the function. Given prerequisite courses, functions and coding basics will not be covered extensively in this course. If a refresher is needed, one is here. Nevertheless, one such function is read.table() which is used to read tabular data files. Another function is read.csv(), which is a special case of read.table(). For this function to read a file, you would need to specify the file argument (and file path if the file is not in your working directory) argument at very least so that R knows what file to read. Another function you may use is data.frame() which is used to create data frames. Using R depends on using functions that are designed to handle various tasks. Unlike some languages, we will not have to create many of our own functions but instead will leverage the work of R developers."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#internal-help",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#internal-help",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Internal Help",
    "text": "Internal Help\nYou will certainly run into problems coding. When you don’t speak the language perfectly, R will let you know there are errors. So, how do you find help in R?\nTo ask R about what a function does, you can use ? paired with the function. In the Help window, you will see information about the package the function is from, how it is used, how to use it by specifying arguments (more on this later), and usually some examples of how it is used.\n?install.packages\n?install.packages\nAlternatively, you can use the help() function:\n\nhelp(\"install.packages\")\nhelp(\"install.packages\", package = \"utils\")\n\nThese methods are all equivalent ways of getting help:\nhelp(\"summarize\")\n\n?summarize\n\n?summarize::summarize\nYou can also simply type a query into the search bar in the RStudio Help menu tab (likely to the right)."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#external-help",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#external-help",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "External Help",
    "text": "External Help\nSometimes you need to find help outside of the R environment. In this case, just use Google. Type in your query by including the letter R to narrow the search results and you will see a lot that pops up. https://stackoverflow.com will likely be returned in your search results with questions that people have posted to the website for help from others. This is a community of coders helping coders. You can create an account if you wish, but reading questions and answers to those questions is free. Perhaps in years from now, you can answer questions for others.\nFor example, if you know you are using the {dplyr} library and you are using a function called starts_with(), you can search Google for “dplyr starts_with r” and this is what you will see"
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-code-execution",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-code-execution",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "R Markdown: Code Execution",
    "text": "R Markdown: Code Execution\nThis exercise is created with R Markdown code. R Markdown is a version of Markdown, which is a markup language for creating formatted text output using a plain-text. You are likely familiar with the most famous markup language, HTML (Hypertext Markup Language), which makes websites readable for us all.\nWithin this R Markdown file, the code is written between particular tick marks ``` and curly braces and {r}. These special character combinations simply allow RStudio to know what is R code (e.g., the lowercase r) and what is written text.\nIn RStudio, you can modify the code block/chunk by clicking the gear to make changes. You can specify whether the code shows the output only, shows the code and the output, whether the code is executed but not shown, or whether the code is not run at all. You can also toggle one and off options to display warnings, message, and other details. You can also review other options if you wish. You’ll notice that warnings and messages will make your output ugly so hiding them is often ideal.\nThis exercise serves as a tutorial with the goal of familiarizing you with using R and R Markdown. The output will be a nice HTML file containing your results. Within the code blocks, to execute code you would put your cursor on the line and press the RUN button (see top right) or press CONTROL+ENTER for PC or COMMAND+ENTER for Mac."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-cheat-sheet",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-cheat-sheet",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "R Markdown: Cheat Sheet",
    "text": "R Markdown: Cheat Sheet\nThere are many ways to customize an R Markdown file. You will need to insert R code, write text descriptions, create plots and tables, etc. In some instances you would want to include your R code or hide it from the output in their certain ways for doing that in the R Markdown language. Some of these ways are created automatically for you in RStudio when you initiate new R Markdown file. Others can be be found in this R Markdown cheat sheet. RStudio also has various cheat sheets which you can find here.\nOn the course site, there are additional cheat sheet files located on the Cheat sheet tab."
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-the-definitive-guide",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-the-definitive-guide",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "R Markdown: The Definitive Guide",
    "text": "R Markdown: The Definitive Guide\nXie, Allaire, and Grolemund have an advanced guide for all the things you can do with R Markdown. It’s called R Markdown: The Definitive Guide"
  },
  {
    "objectID": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#some-things-you-can-do-with-rmarkdown",
    "href": "modules_setup/R Basics/introduction_to_r_rstudio_and_rmarkdown.html#some-things-you-can-do-with-rmarkdown",
    "title": "Introduction to RStudio, R Markdown, & Functions",
    "section": "Some things you can do with RMarkdown",
    "text": "Some things you can do with RMarkdown\nWrap text in * to make text italics\nItalicize this\nWrap text in ** to make text bold\nBold this\nEmbed R code inside text using r\nFor example, the average mpg for cars in the mtcars data set is 20.090625 thought that should be rounded 20.1 to be more clear.\nEmbed R code blocks using ```{r}\nAutomatically enumerate text sections flagged using #\nExample:\n# Main Section\n## 2nd Level\n### 3rd Level"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html",
    "title": "Vectors and data frame basics",
    "section": "",
    "text": "In this module, we will address some basic building blocks of data frames in R. Having a basic understanding of objects, we can extend that to experience to some of the most important objects to understand when working with data, vectors and data frames. We will cover different examples of vector objects, their elements, and how they are organized into larger objects like data frames. Many functions we will use to clean and wrangle data will involve understanding and recognizing these two different object types so that you can apply a function correctly. For example, if a function accepts a vector in order to modify it, you cannot pass a data frame to it. You cannot try to brute force this approach and if you do, you will forever be frustrated. So, let’s jump deeper into some basic concepts.\nNote: By design, concepts in modules will often be redundant with concepts in other modules. If you understand the concepts, just read along or skip through the content. The redundancy, however, is built in purposefully to provide additional scaffolding to those who need it and because droves or literature on cognition and memory support the importance of repetition.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\n{here} 1.0.1: for file path management\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#readings-and-preparation",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#readings-and-preparation",
    "title": "Vectors and data frame basics",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#libraries",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#libraries",
    "title": "Vectors and data frame basics",
    "section": "",
    "text": "{here} 1.0.1: for file path management\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#combining-elements-into-vectors-using-c",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#combining-elements-into-vectors-using-c",
    "title": "Vectors and data frame basics",
    "section": "Combining elements into vectors using c()",
    "text": "Combining elements into vectors using c()\nOne way to create vectors is by using the combine function, c(). You can combine numeric and character elements into a vector. Let’s create some examples and assign names to them.\n\nNumeric vector:\n\nnumeric_vector &lt;- c(23, 22, 35)\n\nCall the object:\n\nnumeric_vector\n\n[1] 23 22 35\n\n\nNotice that the 3 returned elements of the vector are numbers.\n\n\nCharacter vector:\n\ncharacter_vector &lt;- c(\"Salle\", \"Jane\", \"Beavis\")\n\ncharacter_vector\n\n[1] \"Salle\"  \"Jane\"   \"Beavis\"\n\n\nNow, the 3 returned elements are enclosed by quotation marks, \". The quotes help you understand that the vector is character type.\n\n\nNumeric values as a character:\n\nquote_num_vector &lt;- c(\"23\", \"22\", \"35\")\n\nquote_num_vector\n\n[1] \"23\" \"22\" \"35\"\n\n\nAlthough the elements are numbers, they are in quotes, which indicates that the vector is character type.\n\n\nNumbers and characters:\n\nnum_char_vector &lt;- c(23, \"22\", \"35\")\n\nnum_char_vector\n\n[1] \"23\" \"22\" \"35\"\n\n\nAlthough one of the elements of the vector is numeric, the entire vector is returned as character. This is an important characteristic of vectors in R. They can be numeric or character but not both. If there is even one number enclosed by quotes, the vector is character as seen here.\n\nc(23, 22, 35, \"30\")\n\n[1] \"23\" \"22\" \"35\" \"30\""
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#creating-vectors-using-rnorm",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#creating-vectors-using-rnorm",
    "title": "Vectors and data frame basics",
    "section": "Creating vectors using rnorm()",
    "text": "Creating vectors using rnorm()\nLet’s use rnorm() to create a numeric vector object that will represent sampling from a random normal distribution. The distribution will have a certain number of observations, n, a mean, mean, and a standard deviation, sd. We will need to pass arguments to create the data.\nParameters/Arguments:\n\nn: the number of elements in the vector\nmean: the mean of the elements\nsd: the standard deviation of the elements\n\nLet’s create a random normal distribution with a length of 1000 values. The mean should be 100 and standard deviation 15 (e.g., IQ distribution).\n\niq &lt;- rnorm(n = 1000, mean = 100, sd = 15)  \n\nRemember, as long as the order is correct, you do not have to specify the parameter names. You only need to specify the arguments for the parameters.\n\niq &lt;- rnorm(1000, 100, 15)      \n\nLook at the object’s head using head() in order to inspect the first 6 elements:\n\nhead(iq)                        \n\n[1] 110.22894 109.83263 114.79909  83.75904  92.19158  96.23692\n\n\nOr inspect the first 10 elements by setting n = 10.\n\nhead(iq, n = 10)\n\n [1] 110.22894 109.83263 114.79909  83.75904  92.19158  96.23692 130.32179\n [8] 102.59679 139.71121 106.92473"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#creating-number-sequences-using-seq",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#creating-number-sequences-using-seq",
    "title": "Vectors and data frame basics",
    "section": "Creating number sequences using seq()",
    "text": "Creating number sequences using seq()\nYou can dig a little more deeply into the functionality of seq() by looking at the help documentation, help(seq) or ?seq.\nParameters/Arguments:\n\nfrom, to: the starting and (maximal) end values of the sequence. Of length 1 unless just from is supplied as an unnamed argument.\nby: number: increment of the sequence.\nlength.out: desired length of the sequence. A non-negative number, which for seq and seq.int will be rounded up if fractional.\nalong.with: take the length from the length of this argument.\n\n\nSequences from one value to another\nUse seq() to create a sequence FROM 1 TO 10:\n\nseq(from = 1, to = 10)       \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe help documentation will inform you that the from and to parameters are in the first and second position, respectively. We can specify their arguments without using the parameter explicitly.\nReference only to:\n\nseq(1, to = 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nOr, remove both:\n\nseq(1, 10) \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe returned result will be the same.\n\n\nSequences with increments using the by argument\nWe can also modify the from and to step through using the by function such that the numbers will increment by the value of by.\n\nseq(2, 10, by = 2)           # FROM 2 TO 10 BY 2s, dropping from and to arguments\n\n[1]  2  4  6  8 10\n\n\nUsing another example, create a sequence from 1 to 1000 and assign that to an object named id.\n\nid &lt;- seq(1, 1000)            # assign a sequence of 1 to 1000 to a vector named id\n\nInspecting the head:\n\nhead(id)\n\n[1] 1 2 3 4 5 6\n\n\n\n\nObtaining the number of elements using length()\nIf the number of elements in a vector variable changes, hard coding can be troublesome. We can return the length() of the sex vector and pass that as the sequence value. This approach is useful for objects that get modified. This approach would be more flexible.\n\nlength(sex)                # length will return the length of the vector, including NAs\n\n[1] 1000\n\n\nGreat, we get 1000!\n\n\nCreating a sequence using other functions\nThe argument for a function can also be another function. If we have the number of elements in a vector, we could also create a sequence from a starting number to the ending number as defined the another function.\nAssign a sequence of 1 to the length() of the sex object and assign that to an object named id. To make the code more easy to read, we will place the parameters on separate lines.\n\nid &lt;- seq(from = 1, \n          to = length(sex)\n          )  \n\nAnd look at the head:\n\nhead(id)\n\n[1] 1 2 3 4 5 6"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-numeric-or-characters-containing-numbers-to-integer",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-numeric-or-characters-containing-numbers-to-integer",
    "title": "Vectors and data frame basics",
    "section": "Converting numeric or characters containing numbers to integer",
    "text": "Converting numeric or characters containing numbers to integer\nConvert to integer:\n\niq &lt;- as.integer(iq)\n\nNow they are integers:\n\nhead(iq)\n\n[1] 110 109 114  83  92  96"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-numeric-vectors-to-character",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-numeric-vectors-to-character",
    "title": "Vectors and data frame basics",
    "section": "Converting numeric vectors to character",
    "text": "Converting numeric vectors to character\nIf the characters are numbers, pass an existing vector into as.character() to convert\n\niq &lt;- as.character(iq)                # make is a character vector  \n\nNow the numbers are in quotes representing strings.\n\nhead(iq)               \n\n[1] \"110\" \"109\" \"114\" \"83\"  \"92\"  \"96\""
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-character-vectors-to-numeric",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#converting-character-vectors-to-numeric",
    "title": "Vectors and data frame basics",
    "section": "Converting character vectors to numeric",
    "text": "Converting character vectors to numeric\nIf the elements are characters, pass an existing vector into as.integer() to convert.\n\niq &lt;- as.integer(iq)  \n\nNow elements are integers, not floats.\n\nhead(iq)\n\n[1] 110 109 114  83  92  96\n\n\nYou can also wrap a function in another function when the initial object is created. Here, as.integer() converts the vector returned by rnorm() into an integer.\n\niq &lt;- as.integer(rnorm(1000, 100, 15))                 # create initially by wrapping as.integer() around rnorm()"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#using-piping-operators-and",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#using-piping-operators-and",
    "title": "Vectors and data frame basics",
    "section": "Using piping operators |> and %>%",
    "text": "Using piping operators |&gt; and %&gt;%\nAlternatively, if nesting functions and reading them from the inside out confuses you, you can instead use piping operators to pass objects from function to function. Piping also improves code readability.\nBase R now includes it’s own piping operator, |&gt;. In the past, piping was accomplish using {magrittr} piping operators and sometimes those operators work better than the base R pipe. The main piping operator from {magrittr} is %&gt;%. To use it, we will need to load the library first using library(), though you should loads all libraries at the top of your file. We will use both piping operators to illustrate differences in functionality. I may use them interchangeably in materials.\nLoad the library:\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nCreate the iq vector:\n\niq &lt;- rnorm(1000, 100, 15)        # create the random normal dist\n\nCheck whether the vector is an integer:\n\nis.integer(iq)\n\n[1] FALSE\n\n\nis.integer() is a logical test, so it will return either TRUE or FALSE. You see that the vector is not an integer as FALSE was returned. Because IQ scores are integers, let’s use the process to make it an integer.\n\niq &lt;- rnorm(1000, 100, 15) %&gt;%    # create the random normal dist\n    as.integer()                  # pipe to make integer\n\nUsing base R’s piping operator:\n\niq &lt;- rnorm(1000, 100, 15) |&gt;     # create the random normal dist\n    as.integer()                  # pipe to make integer"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#examine-the-head-of-the-object",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#examine-the-head-of-the-object",
    "title": "Vectors and data frame basics",
    "section": "Examine the head() of the object",
    "text": "Examine the head() of the object\nHowever you create the vector, we can examine the head of the vector using head():\n\nhead(iq)\n\n[1] 113  96  86 103 102  69\n\n\nA note about pipes: If you did not pipe the object from one function to another, you would need to wrap the functions as layers. The the function in the inner layer would be executed first and the function of the outer layer would be executed last.\nas.integer(rnorm(1000, 100, 15))\nAlthough there is nothing incorrect with this code, readability is compromised because you have to read the functions from the inside out. Piping objects to functions allows for reading functions from top to bottom."
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#plotting-the-vector-using-hist",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#plotting-the-vector-using-hist",
    "title": "Vectors and data frame basics",
    "section": "Plotting the vector using hist()",
    "text": "Plotting the vector using hist()\nAnd to see a plot, use hist(iq):\n\nhist(iq)\n\n\n\n\nOr pass the object using a pipe (e.g., |&gt; or %&gt;%) and pipe the vector to the histogram function in base R:\n\niq %&gt;% hist()\n\n\n\n\n\niq |&gt; hist()\n\n\n\n\nNotice that this approach changes the title. When piping objects with {magrittr}’s pipe, the object is referenced using . so this because the name of the object."
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#adding-a-title-to-the-plot",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#adding-a-title-to-the-plot",
    "title": "Vectors and data frame basics",
    "section": "Adding a title to the plot",
    "text": "Adding a title to the plot\nTO add a title, pass a string argument to main:\n\niq |&gt; hist(main = \"IQ Distribution\")"
  },
  {
    "objectID": "modules_setup/R Basics/vectors_and_data_frame_basics.html#recoding-vectors",
    "href": "modules_setup/R Basics/vectors_and_data_frame_basics.html#recoding-vectors",
    "title": "Vectors and data frame basics",
    "section": "Recoding vectors",
    "text": "Recoding vectors\nSometimes elements of vectors are messy and need to be fixed. In general, this process is referred to as recoding. There are various ways to recode in R and there are special libraries dedicated to recoding. Now, we will perform some simple recoding.\nYou can use ifelse() or dplyr::case_when() to test whether the elements of a vector match some condition and if yes (do one thing), otherwise no (do something else). In order to understand how these functions and many others work we need to understand a logical test.\n\nifelse()\ndplyr::case_when()\n\n\nPerforming a logical test\nWe can perform a logical test on all types of objects but this example will focus on vectors, for which all elements will be examined. The logical test will return TRUE or FALSE for each vector element depending on whether the case matches a test condition.\nRather than illustrate this the 1000 element sex vector, we will create a vector of length 5 called temp_sex. In this example, you will also see what happens when you need to clean up and recode the sloppy data. You can see are composed of both upper and lower case letters presumably corresponding to biological sex. Because R is a case-sensitive language, \"M\" and \"m\" represent different objects even though the intent is for them to be the same.\n\ntemp_sex &lt;- c(\"M\", \"m\", \"F\", \"f\", NA)\n\nYou can see that some character elements in the vector are upper- and lowercase m’s and f’s. Let’s see what happens when we perform a logical test of the vector. Remember that by itself = will be assignment (like &lt;-). In order to determine whether an object or elements of an object is equal to something, we use ==.\nFor example, temp_sex == \"M\":\n\ntemp_sex == \"M\"\n\n[1]  TRUE FALSE FALSE FALSE    NA\n\n\nThe returned vector is of the same length as the vector tested. Each element of the vector was tested and those elements that matched the character \"M\" returns TRUE. The other elements are FALSE, except of the NA, or missing value. Importantly, the logical test does not return FALSE for NAs.\n\n\nRecoding using ifelse()\nLet’s perform the logical test inside ifelse(). The function will test each element and IF it is TRUE (matches the condition) will assign 0, else/otherwise assign 1 in order to recode the letters into numbers. Of course, you may often wish to recode letters into other letters.\n\nifelse(temp_sex == \"M\", 0, 1)\n\n[1]  0  1  1  1 NA\n\n\nWe can see that all of the TRUEs are 0 and all else except for NA are 0. You can see that only the \"M\" was recoded to 0 and all other elements that were not NA were recoded as 1. Clearly, this is not correct. We can use multiple ifelse() functions but the solution won’t be offered here because it’s just really messy. Instead of focusing on bad code, let’s just focus on offering better solutions.\nPerforming the same test on sex but piping the vector to head() will allow for inspection of the first few elements.\n\nifelse(sex == \"M\", 0, 1) |&gt;\n  head()\n\n[1] 1 1 1 1 1 1\n\n\nThe ifelse() approach is fine for two groups. When there are more than two groups, however, re-coding can be confusing with ifelse() because you’ll need to nest an ifelse() inside an ifelse(). The popular {dplyr} library also has a couple functions similar to ifelse(), for example, if_else() and case_when().\n\n\nRecoding using dplyr::case_when()\nThe case_when() function will also perform logical tests but you can easily specify more than one. The help documentation tells us that “This function allows you to vectorise multiple if_else() statements. Each case is evaluated sequentially and the first match for each element determines the corresponding value in the output vector. If no cases match, the .default is used as a final”else” statement.” And later “If none of the cases match and no .default is supplied, NA is used.\nWith case_when(), we will perform a logical test of the elements against the character string \"M\" first. The elements that match \"M\" will evaluate as TRUE and will be recoded as 0. Then the elements of the new recoded vector will be tested again against \"F\". Those that are TRUE will be recoded as 1. Anything else will be assigned NA for missing because they matched neither \"M\" nor \"F\".\nWe wee that only the first element returns TRUE. Other elements are FALSE or NA.\n\ndplyr::case_when(\n  temp_sex == \"M\" ~ 0,\n  temp_sex == \"F\" ~ 1\n  ) \n\n[1]  0 NA  1 NA NA\n\n\nBut note that if the character case is inconsistent, NA’s will replace elements that are \"m\" and \"f\". An easy fix for casing is to convert the vector (without assignment) by passing it to tolower() or toupper() and then perform the logical conversion on the case change elements.\n\ndplyr::case_when(\n  toupper(temp_sex) == \"M\" ~ 0,\n  toupper(temp_sex) == \"F\" ~ 1\n  ) \n\n[1]  0  0  1  1 NA\n\n\nYou can now see that all elements will evaluate to TRUE and are recoded except for the NA in the vector. Keep in mind that strings may be very messy and require careful inspection and cleaning. Sometimes simple case recoding solves your problems.\nNote: There is a much powerful library called {stringr} for wrangling strings. We will use this library to perform other tasks. If you wanted to familiarize yourself with making strings upper or lowercase using that library, use stringr::str_to_lower() and stringr::str_to_upper().\nTo illustrate:\n\nlibrary(stringr)            # load the library first\n\ndplyr::case_when(\n  str_to_upper(temp_sex) == \"M\" ~ 0,\n  str_to_upper(temp_sex) == \"F\" ~ 1\n  ) \n\n[1]  0  0  1  1 NA\n\n\nWhen you have more logical tests to perform, you can specify them on a new line. Using the existing vector, we can illustrate with a silly example.\n\ndplyr::case_when(\n  temp_sex == \"m\" ~ \"Young Men\",\n  temp_sex == \"M\" ~ \"Old Men\",\n  temp_sex == \"f\" ~ \"Young Women\",\n  temp_sex == \"F\" ~ \"Old Women\",\n  ) \n\n[1] \"Old Men\"     \"Young Men\"   \"Old Women\"   \"Young Women\" NA           \n\n\nWe have not recoded the vector to have clear names for 4 groups, plus and NAs. Of course, you have not changed temp_sex unless you assign the returned vector to a name.\n\ntemp_sex\n\n[1] \"M\" \"m\" \"F\" \"f\" NA \n\n\nAssign to temp_sex to overwrite:\n\ntemp_sex &lt;- dplyr::case_when(\n  temp_sex == \"m\" ~ \"Young Men\",\n  temp_sex == \"M\" ~ \"Old Men\",\n  temp_sex == \"f\" ~ \"Young Women\",\n  temp_sex == \"F\" ~ \"Old Women\",\n  ) \n\n\ntemp_sex\n\n[1] \"Old Men\"     \"Young Men\"   \"Old Women\"   \"Young Women\" NA"
  },
  {
    "objectID": "project/01_project_team_roles.html",
    "href": "project/01_project_team_roles.html",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating the team meeting time and location to me;\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data story line;\nFormatting, text, images, inline code (R code embedded in text if relevant), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (making sure teammates are pushing work to remote repo);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/01_project_team_roles.html#team-roles",
    "href": "project/01_project_team_roles.html#team-roles",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating the team meeting time and location to me;\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data story line;\nFormatting, text, images, inline code (R code embedded in text if relevant), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (making sure teammates are pushing work to remote repo);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/03_project_final.html",
    "href": "project/03_project_final.html",
    "title": "Final Presentation",
    "section": "",
    "text": "Overview\nThe in-class final presentation will be a clear and concise 20-minute presentation version of the final written deliverable. The presentation to your liaison and/or organization may be of greater duration, though I do no not recommend longer than approximately 30 minutes. You should focus on presenting a description of the problem, your approach taken to address the problem, and your visualizations use to tell a story about your findings. Each team member should present and discuss at least one of their visualizations.\nThe final written report for the project will be delivered to me and to your liaison. This report will represent a more careful unpacking of the problem, including a discussion about the data, data cleaning steps, and associated file deliverables. I can print a color-printed copy for you to distribute to the liaison. If the liaison is remote, a color version of the pdf is appropriate.\n\n\nElements to Focus On\nFor the final presentation, you should focus on presenting a description of the problem, data summaries, and visualization used to help tell a story about your findings. You should make sure to address the key elements outlined in the project proposal and discussed with your liaison.\n\n\nPresentation Medium\nYou can use any slide-presentation tool you wish. You will just need to ensure:\n\na printed version of the slide deck for class time;\nan electronic pdf of the slide deck before or after the presentation;\nthat visualizations contain Alt text (alternative text) for screen readers; What is alt text?; see Make your document, presentation and sheets more accessible and How to add alternative text to an object in google slides\n\n\n\nStakeholders\nIdentify the stakeholders for your project. For example, include you liaison, liaison’s institution, course professor, your college, etc. for whom the final work will be submitted.\n\n\nEvaluation and Generalized Rubric\nMore detail will be added here similar to the Midterm Presentation.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, models, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaisons will also participate in evaluating teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\n\nPresentation Tips\nSee tips for Midterm Presentation."
  },
  {
    "objectID": "project/05_project_tasks.html",
    "href": "project/05_project_tasks.html",
    "title": "Project Tasks",
    "section": "",
    "text": "Important\n\n\n\nDo not proceed. I need to edit this for PSYC167. If you see this message, feel free to remind me that the edits are not on the website.\n\n\n\n\nOverview\nIn order to complete the project, there are different components that can be easily broken up and delegated among team members. During weekly team meetings, team members can discuss accomplishments and progress, and check off tasks. Provided many of you have never taken on such tasks and thought about how to break tasks into smaller bite-sized pieces, a general framework maybe be helpful for you.\n\n\nLarge-Scale Tasks\nSome tasks have to be performed in a sequential order but others can be integrated throughout other tasks. For example, describing the motivation of the project, explaining the data and variables used, describing how you prepared the data, presenting findings, etc. are all part of the Report Drafting process. Components can be, and should be, worked on in piecemeal so that they are all not delayed until the end.\n\nReview the project proposal details shared with you in the project /docs\nReview any project documents in /docs to understand the structure of the data and identify relevant variables\nSchedule to meet with liaison to discuss project in order to formulate a game plan; ask about variables of interest\nOutline the project plan and develop a timeline (consider how timeline maps onto course topics)\nRead data, clean and prepare data for summaries, visualizations, and models\nMerge data parts from team members\nIntegrate team member sub-goal code files\nFinalize report\n\nReport drafting. This tasks can get integrated within the other tasks. For example, delegating tasks, setting deadlines for rough drafts, etc.). Relevant references in /refs can be disseminated, read, and used to prepare the theoretical and conceptual motivation for the project."
  },
  {
    "objectID": "resources/tools.html#websites",
    "href": "resources/tools.html#websites",
    "title": "Tools for Foundations of Data Science",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/"
  },
  {
    "objectID": "resources/tools.html#books",
    "href": "resources/tools.html#books",
    "title": "Tools for Foundations of Data Science",
    "section": "Books",
    "text": "Books\n\nLots of alternative books https://www.bigbookofr.com/data-visualization.html"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-is-an-interpreted-language",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-is-an-interpreted-language",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R is an Interpreted Language",
    "text": "R is an Interpreted Language\n\n\ncode or programs you write execute in real time\nby he R interpreter that translates your code\ncode does not need to be compiled prior to being executed"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-involves-functional-programming",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-involves-functional-programming",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R involves functional programming",
    "text": "R involves functional programming\n\n\nhttps://en.wikipedia.org/wiki/Functional_programming\nprograms are constructed by applying and composing functions\nfunctions:\n\nmean()\ndplyr::summarize()"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics",
    "text": "Some basics\n\n\nnumeric objects (e.g., 2024, 21.2)\nstrings/character objects:\n\ncomposed of letters\nenclosed by quotes (e.g., \"Sam\", \"Male\", \"21\")\n\nvector objects:\n\ncollections of objects (e.g., c(\"18\", \"23\", \"20\"))\n\ndata frames:\n\ncollections of vectors"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics (cont.)",
    "text": "Some basics (cont.)\n\n\nwe assign objects to names/names to objects\n\nages &lt;- c(\"18\", \"23\", \"20\")\n\nwe perform functions on objects:\n\nas.numeric(ages)\noften by assigning or reassigning:\n\nages &lt;- as.numeric(ages)"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.-1",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.-1",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics (cont.)",
    "text": "Some basics (cont.)\n\n\nwe inspect object contents\n\nages\nand get something returned: [1] 18 23 20\n\nwe perform more functions on objects:\n\nmean(ageas.numeric(ages))\n[1] 20.33333\n\nwe model data frames"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#open-rstudio",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#open-rstudio",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Open RStudio",
    "text": "Open RStudio\n\n\nfind the Console\nfind the Terminal\nfind ‘environment’ in pane\nfind ‘history’ in pane\nfind ‘help’ in pane\nfind ‘files’ in pane\nfind ‘plots’ in pane"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-code-in-the-r-console",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-code-in-the-r-console",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write some code in the R console",
    "text": "Write some code in the R console\n\n\n\nyear &lt;- 2024\n\n\n\n\ncode\nyear &lt;- 2024\n\n\n\nassign objects to names using &lt;-, not ="
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-more-code-in-the-r-console",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-more-code-in-the-r-console",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write more code in the R console",
    "text": "Write more code in the R console\n\n\n\nages &lt;- c(18, 22, 24)\n\n\n\n\ncode\nages &lt;- c(18, 22, 24)\n\n\n\n[1] 18 22 24"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#rstudio",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#rstudio",
    "title": "R, RStudio, & Rmarkdown",
    "section": "RStudio",
    "text": "RStudio\n\nIDE for using R\nmake for a better coding experience\nlots of extras\n\nbetter UI, markdown, Terminal, Git, code snippets"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-markdown",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-markdown",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R Markdown",
    "text": "R Markdown\n\n\nMarkdown is a lightweight markup language used for adding formatting elements to plain text text\nR Markdown is a markdown language create for R and RStudio\nAllows you to dress up text, embed and render code, reference hyperlinks, etc. within a written document\nLibraries like {rmarkdown} and {knitr} help you build HTML, pdf, and Word documents that update automatically with new data"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-an-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-an-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create an R Markdown File",
    "text": "Create an R Markdown File\n\n\nCreate directory/folder named: fods24\nFile &gt; New File &gt; R Markdown\nName it: my_first_markdown.Rmd\nSave in: /fods24\nNOTE: Directories will be addressed for next week!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-text-in-the-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-text-in-the-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write some text in the R Markdown File",
    "text": "Write some text in the R Markdown File\n\nMy name is X and the year I start learning R is Y."
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#dressing-up-text",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#dressing-up-text",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Dressing up Text",
    "text": "Dressing up Text\n\n\nItalics: wrap text in *\n\n*italics*\n\nBold: wrap text in **\n\n**bold**\n\nBold Italics: wrap text in ***\n\n***bold italics***"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-and-embed-code-block",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-and-embed-code-block",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Insert and Embed Code Block",
    "text": "Insert and Embed Code Block\n\n\n```{r}\n\n```\n\n\n\n\nWindows: CLTR+ALT+I\nMac: COMMAND+ALT+I"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-code-in-block-assign-value-to-year",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-code-in-block-assign-value-to-year",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create Code in Block: Assign value to year ",
    "text": "Create Code in Block: Assign value to year \n\n\n```{r}\nyear &lt;- 2024\n```\n\n\n\n\ncode\nyear &lt;- 2024"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#code-block-settings",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#code-block-settings",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Code block settings",
    "text": "Code block settings"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-a-code-block-write-some-code",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-a-code-block-write-some-code",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create a code block + write some code",
    "text": "Create a code block + write some code\n\n\n```{r}\nband &lt;- \"your favorite band\"\nstate &lt;- \"the state in which you grew up\"\nname &lt;- \"your name\"\n```"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-1",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-1",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text\n\n\n\nThe year is `r year`!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-2",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-2",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text\n\n\n\nThe year is `r year`!\n\n\nThe year is 2024!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#modify-your-text-in-the-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#modify-your-text-in-the-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Modify your text in the R Markdown File",
    "text": "Modify your text in the R Markdown File\n\n\nmake the year change by using inline code\nmake sure your inline code is after you assign the object"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#add-header-sections-and-subsections-using",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#add-header-sections-and-subsections-using",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Add header sections and subsections using #",
    "text": "Add header sections and subsections using #\n# About me\n## My favorite band\n### My favorite band from the 1990s"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-hyperlinks",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-hyperlinks",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Insert hyperlinks",
    "text": "Insert hyperlinks\n\n\n[message](url)\n[cheatsheet](https://gabrielcook.xyz/fods24/cheatsheets/rmarkdown-2.0.pdf)\ncheatsheet"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#knitting-r-markdown-files",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#knitting-r-markdown-files",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Knitting R Markdown Files",
    "text": "Knitting R Markdown Files\n\n\nAs HTML\nAs pdf\nAs Word"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#locate-the-html-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#locate-the-html-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Locate the HTML file ",
    "text": "Locate the HTML file \n\nmy_first_markdown.html"
  },
  {
    "objectID": "slides/02_git.html#version-control",
    "href": "slides/02_git.html#version-control",
    "title": "Git and GitHub",
    "section": "Version Control",
    "text": "Version Control\n\n\nWhat is version control?\n\nProject backup\nSee specific changes inside files\nUndo changes (time machine)\n\nVersion Control Summary Video"
  },
  {
    "objectID": "slides/02_git.html#version-control-git-workflow-basics",
    "href": "slides/02_git.html#version-control-git-workflow-basics",
    "title": "Git and GitHub",
    "section": "Version Control: Git Workflow Basics",
    "text": "Version Control: Git Workflow Basics\nThere are three main parts to Git Workflow:\n\n\nVersion control for files (not empty directories)\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)\nVersion Control Workflow Basics\nOther Parts\n\nPush for sending commits to GitHub\nMerge for merging branches (i.e., to incorporate your edits into main)"
  },
  {
    "objectID": "slides/02_git.html#git-image-version",
    "href": "slides/02_git.html#git-image-version",
    "title": "Git and GitHub",
    "section": "Git: Image Version",
    "text": "Git: Image Version\nunderstanding git through images"
  },
  {
    "objectID": "slides/02_git.html#connecting-git-to-github-the-rstudio-terminal",
    "href": "slides/02_git.html#connecting-git-to-github-the-rstudio-terminal",
    "title": "Git and GitHub",
    "section": "Connecting Git to GitHub: The RStudio Terminal",
    "text": "Connecting Git to GitHub: The RStudio Terminal\n\n\nConfigure Git and GitHub in RStudio Terminal\nCreate token\nSet token\nCan use the RStudio Gui (clunky though)"
  },
  {
    "objectID": "slides/02_git.html#configuring-git-and-github-with-usethis",
    "href": "slides/02_git.html#configuring-git-and-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Configuring Git and GitHub with {usethis}",
    "text": "Configuring Git and GitHub with {usethis}\n\nusethis::use_git_config(user.name = \"janegit\", \n                        user.email = \"jane_git@gitrdone.com\"\n                        )"
  },
  {
    "objectID": "slides/02_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "href": "slides/02_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Creating a Personal Access Token (PAT) for GitHub with {usethis}",
    "text": "Creating a Personal Access Token (PAT) for GitHub with {usethis}\n\n\nusethis::create_github_token()\nCreate token and copy to your clipboard"
  },
  {
    "objectID": "slides/02_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "href": "slides/02_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "title": "Git and GitHub",
    "section": "Setting your Git Credentials (using PAT) with {gitcreds}",
    "text": "Setting your Git Credentials (using PAT) with {gitcreds}\n\n\ngitcreds::gitcreds_set()\nChoose option to either set or replace\nAt ? Enter new password or token, paste PAT to set\ngh::gh_whoami() to check if set"
  },
  {
    "objectID": "slides/02_git.html#some-basic-commands",
    "href": "slides/02_git.html#some-basic-commands",
    "title": "Git and GitHub",
    "section": "Some Basic Commands",
    "text": "Some Basic Commands\n\nFork: to make a copy of a repo in your own GitHub account\nClone: make a copy of the your GitHub repo on your local computer. * copies a remote repo to create a local repo with a remote called origin automatically set up."
  },
  {
    "objectID": "slides/02_git.html#some-basic-commands-cont.",
    "href": "slides/02_git.html#some-basic-commands-cont.",
    "title": "Git and GitHub",
    "section": "Some Basic Commands (Cont.)",
    "text": "Some Basic Commands (Cont.)\n\nPull: incorporates changes into your repo from remote\nAdd: adds snapshots of your changes to the “Staging” area.\nCommit: takes the files as they are in your staging area and stores a snap shot of your files (changes) permanently in your Git directory\nPush: uploads your files (changes) to the remote repo\nStatus: checks the status of a repo changes, etc.\nMerge: incorporates changes into the branch you are on.\nPull Request: By “issuing a pull request” to the owner of the upstream repo, you are requesting that your changes be pulled into their repo (accept your changes/work)."
  },
  {
    "objectID": "slides/02_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "slides/02_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Git and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\n\nMake a change to a file, save to local computer\nCheck status of project for changes\nAdd/Stage change\nCommit change(s)\nPush changes\nPull pulls changes down from repo (downloads and merges changes)\nFetch downloads new data (does not change your working copy)"
  },
  {
    "objectID": "slides/02_git.html#checking-the-status-of-local-file-changes",
    "href": "slides/02_git.html#checking-the-status-of-local-file-changes",
    "title": "Git and GitHub",
    "section": "Checking the Status of Local File Changes",
    "text": "Checking the Status of Local File Changes\nAt the Terminal in RStudio\n\n$ git status"
  },
  {
    "objectID": "slides/02_git.html#shared-repository-workflow",
    "href": "slides/02_git.html#shared-repository-workflow",
    "title": "Git and GitHub",
    "section": "Shared Repository Workflow",
    "text": "Shared Repository Workflow\n\n\nPull recent changes from main: git pull\nMake changes to files\nStage your changes: git add\nCommit changes locally: git commit -m \"description of changes\"\nUpload your new the changes to GitHub: git push"
  },
  {
    "objectID": "slides/02_git.html#staging-changes-adding-changes",
    "href": "slides/02_git.html#staging-changes-adding-changes",
    "title": "Git and GitHub",
    "section": "Staging Changes (Adding Changes)",
    "text": "Staging Changes (Adding Changes)\n\n\nStaging and Committing\n\nUntracked vs. tracked files\nTo have tracked by Git, you need to add"
  },
  {
    "objectID": "slides/02_git.html#staging-a-specific-change",
    "href": "slides/02_git.html#staging-a-specific-change",
    "title": "Git and GitHub",
    "section": "Staging a Specific Change",
    "text": "Staging a Specific Change\n\n\n$ git add &lt;file&gt;... such that &lt;file&gt; refers to the file name\nfile might be in a directory, e.g., r/\n$ git add r/yourname.R\nTab to auto-complete, e.g., git add r/you{TAB}"
  },
  {
    "objectID": "slides/02_git.html#staging-all-changes",
    "href": "slides/02_git.html#staging-all-changes",
    "title": "Git and GitHub",
    "section": "Staging All Changes",
    "text": "Staging All Changes\n\n$ git add ."
  },
  {
    "objectID": "slides/02_git.html#committing-the-changes",
    "href": "slides/02_git.html#committing-the-changes",
    "title": "Git and GitHub",
    "section": "Committing the Change(s)",
    "text": "Committing the Change(s)\n\n\ngit commit is used to commit the changes\nadd -m to tell git you want a message (e.g., \"my message here\")\n\n$ git commit -m \"added my first .R file\""
  },
  {
    "objectID": "slides/02_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "href": "slides/02_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Push (publish) the change(s) from your branch to the remote repository",
    "text": "Push (publish) the change(s) from your branch to the remote repository\n\n\n$ git push\nPushing changes"
  },
  {
    "objectID": "slides/02_git.html#pulls-changes-from-the-remote-repository",
    "href": "slides/02_git.html#pulls-changes-from-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Pulls change(s) from the remote repository",
    "text": "Pulls change(s) from the remote repository\n\n\n$ git pull\nIf you make changes that other will need, let them know to pull"
  },
  {
    "objectID": "slides/02_git.html#git-client-video-tutorials",
    "href": "slides/02_git.html#git-client-video-tutorials",
    "title": "Git and GitHub",
    "section": "Git Client Video Tutorials",
    "text": "Git Client Video Tutorials\n\n\nGitKraken Git Client examples\nfor more, see: this video"
  },
  {
    "objectID": "slides/02_git.html#videos-of-many-things-you-can-do",
    "href": "slides/02_git.html#videos-of-many-things-you-can-do",
    "title": "Git and GitHub",
    "section": "Videos of many things you can do",
    "text": "Videos of many things you can do\nIf interested, see gittower YouTube"
  },
  {
    "objectID": "slides/03_functions_slides.html#some-object-types",
    "href": "slides/03_functions_slides.html#some-object-types",
    "title": "Functions, Parameters, and Arguments",
    "section": "Some Object Types",
    "text": "Some Object Types\n\n\nnumeric objects: representing numeric information (e.g., one’s age)\ncharacter objects: representing character information (e.g., one’s name or race)\nvector objects: representing more than one numeric object (e.g., ages of participants)\ndata frame objects: containing vectors of data (e.g., column variables and row instances of data)\nfunction objects: that accept one object and return an other object (e.g., the mean of numeric vector)"
  },
  {
    "objectID": "slides/03_functions_slides.html#object-assignment",
    "href": "slides/03_functions_slides.html#object-assignment",
    "title": "Functions, Parameters, and Arguments",
    "section": "Object Assignment",
    "text": "Object Assignment\n\n\nObjects need names\nObtained through assignment\n\nname is assigned an object; or\nobject is set to name\n\nAssignment operator &lt;-\n\nex: age &lt;- 22\nex: age &lt;- as.numeric(c(\"22\", \"25\", \"19\"))"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-objects",
    "href": "slides/03_functions_slides.html#function-objects",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Objects",
    "text": "Function Objects\n\nFunctions are special objects which contain statements for carrying out operations\n\nc() or Hmisc::Cs(): to combine elements into a vector\nmean(): to compute the mean of a numeric vector\nsource(): for reading/executing R code\ndplyr::mutate(): for creating variables in data frames\nrio::import() or readr::read_csv(): for reading data files\nreadRDS(): for reading compressed data files"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-characteristics",
    "href": "slides/03_functions_slides.html#function-characteristics",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Characteristics",
    "text": "Function Characteristics\n5 terms concepts to know:\n\n\nname (created by assignment operator &lt;-)\ndefinition (code statements or instructions for its usage)\narguments (optional variables that specify the function’s operation)\nfunction call (e.g., execution of a function)\nreturned object (value returned from the executed function)"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-statements-without-parameterargument",
    "href": "slides/03_functions_slides.html#function-statements-without-parameterargument",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Statements without Parameter/Argument",
    "text": "Function Statements without Parameter/Argument\n\n\nmy_function &lt;- function() {\n\n    statements/instructions to do something\n\n    \n    return(result of instructions)\n\n}"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-example-with-parameterargument",
    "href": "slides/03_functions_slides.html#function-example-with-parameterargument",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Example with Parameter/Argument",
    "text": "Function Example with Parameter/Argument\n\n\n\nget_years_since_birth &lt;- function(dob) {\n  if (!hasArg(dob)) {\n      message(\"Error: dob missing/no argument provided\")\n    } \n  else {\n    # make string a data\n    dob = lubridate::as_date(dob) \n    # obtain the difference in time in days\n    diff = difftime(time1 = Sys.Date(), time2 = dob, units = \"days\")\n    # create age based on days in year\n    age = as.numeric(diff / 365.25)\n    # return the age in years, truncated \n    return(trunc(age))\n  }\n}"
  },
  {
    "objectID": "slides/03_functions_slides.html#functions-in-libraries",
    "href": "slides/03_functions_slides.html#functions-in-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Functions in Libraries",
    "text": "Functions in Libraries\n\n\n{dplyr}: for wrangling data frames\n{ggplot2}: for plotting data\n{tidyverse}: for loading all libraries in the tidyverse ecosystem\n{easystats}: for loading all libraries in the easystats ecosystem"
  },
  {
    "objectID": "slides/03_functions_slides.html#loadingimporting-functions-from-libraries",
    "href": "slides/03_functions_slides.html#loadingimporting-functions-from-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Loading/Importing Functions from Libraries",
    "text": "Loading/Importing Functions from Libraries\n\n\nLoading all functions:\n\nlibrary(dplyr)\n\nLoading order matters: Function of the same name will overwrite others"
  },
  {
    "objectID": "slides/03_functions_slides.html#calling-functions-from-libraries",
    "href": "slides/03_functions_slides.html#calling-functions-from-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Calling Functions from Libraries",
    "text": "Calling Functions from Libraries\n\n\nIf loaded:\n\nmutate() (from {dplyr})\n\nIf not loaded:\n\neeptools::age_calc(): for calculating age based on a date\n:: calls ensures choice (duplicate function names in different libraries)"
  },
  {
    "objectID": "modules/designing_perceptually_efficient_visualizations.html#extended-reading-resources",
    "href": "modules/designing_perceptually_efficient_visualizations.html#extended-reading-resources",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Extended Reading Resources",
    "text": "Extended Reading Resources\nAnother great but very lengthy reading is Franceroni et al. (2012). The Science of Visual Data Communication: What Works."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#the-ggplot-function",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#the-ggplot-function",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "The ggplot() Function",
    "text": "The ggplot() Function\nWhat is a ?ggplot object? Review the docs first. Let’s apply the base layer using ggplot().\nParameters/Arguments:\n\ndata: a data frame\nmapping: for mapping data or values to aesthetic properties of a geom_*\n\nThis function takes a data set and simply initializes the plot object so that you can build other components on top of it. By default, data = NULL so, you will need to pass some data argument. The mapping parameter is essential for mapping the aesthetics of the plot, by default, mapping = aes()."
  },
  {
    "objectID": "modules/ggplot_and_the_grammar_of_graphics.html#ggplot2-plot-composition",
    "href": "modules/ggplot_and_the_grammar_of_graphics.html#ggplot2-plot-composition",
    "title": "{ggplot2}: The Grammar of Graphics",
    "section": "{ggplot2} Plot Composition",
    "text": "{ggplot2} Plot Composition\nThere are five mapping components:\n\nLayer containing geometric elements and statistical transformations:\n\n\nData a tidy data frame, most typically in long/narrow format\nMapping defining how vector variables are visualized (e.g., aesthetics like shape, color, position, hue, etc.)\nStatistical Transformation (stat) representing some summarizing of data (e.g., sums, fitted curves, etc.)\nGeometric object (geom) controlling the type of visualization\nPosition Adjustment (position) controlling where visual elements are positioned\n\n\nScales that map values in the data space to values in aesthetic space\nA Coordinate System for mapping coordinates to the plane of a graphic\nA Facet for arranging the data into a grid; plotting subsets of data\nA Theme controlling the niceties of the plot, like font, background, grids, axes, typeface etc.\n\nThe grammar does not:\n\nMake suggestions about what graphics to use\nDescribe interactivity with a graphic; {ggplot2} graphics are static images, though they can be animated"
  }
]
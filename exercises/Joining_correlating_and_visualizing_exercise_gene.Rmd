---
title: "Exercise: Joining, Correlating, and Visualizing"
#author: "yourname"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    number_sections: yes
    code_folding: show #hide
  word_document:
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
eval_answers    <- TRUE
include_answers <- TRUE
```

```{r, include=FALSE}
R.utils::sourceDirectory(here::here("r", "functions"))
```

# **Class Practice**

Your project involves joining, summarizing, modeling, and visualizing data. You will need to join components created by team members in order to create data summaries and visualizations. The exercise provides practice doing just that and moving your toward those goals.


# **Loading Libraries**

```{r eval=eval_answers, message=FALSE, warning=FALSE, include=include_answers}
library(easystats)
library(tidyverse)
#library(ggplot2)
library(gt)
library(gtsummary)
library(GGally)
```


```{r, eval=eval_answers, include=include_answers}
#source(here::here("r", "merge", "merge_all.R"))

JOINED_LONG <- readRDS(here::here("data", "merged", "champ_demog_span_long_merged.Rds"))
JOINED_Wide <- readRDS(here::here("data", "merged", "champ_demog_span_wide_merged.Rds"))

names(JOINED_Wide)

library(heatmaply)

drug_freg_wmc <-
  JOINED_Wide |>
  select(c(contains("_freq"), WMC_1, WMCe_1)) |> 
  select(!contains("_30_")) |>
  select(!contains("poly")) |>
  filter(!is.na(WMC_1)) |>
  rename_with(~(gsub("_freq", "", .x, fixed = T))) |>
  #rename_with(.fn = function(x) stringr::str_replace_all(x, "_freq", ""))
  na.omit()


drug_freg_wmc |> 
  view_html()

heat_norm <- as.matrix(heatmaply::normalize(drug_freg_wmc, method = "standardize"))
heatmap(heat_norm)

heatmap(cor(normalize(na.omit(drug_freg_wmc))))

cor(drug_freg_wmc)
corrplot::corrplot(corr = cor(drug_freg_wmc), 
         method = "number",
         #number.font = 1,
         number.cex = 0.75,
         tl.col = 'black'
         #col.col = "blue"
         )

library(corrplot)
corrplot(corr = cor(drug_freg_wmc),
         type = 'lower', 
         order = 'hclust',
#         method = 'square', 
#         order = 'AOE', 
         addCoef.col = 'black', 
         tl.col = 'black',
 #        tl.pos = 'd',
  #       cl.pos = 'n', 
         col = COL2('BrBG'), diag = FALSE
         )

# https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html
corrplot(corr = cor(drug_freg_wmc, 
                    #use = "pairwise.complete.obs"
                    ),
         #order = 'AOE', 
         order = 'hclust',
         tl.col = 'black',      # change label font color
         addCoef.col = 'black', # add the corr coefficient to cells
         diag = FALSE,          # drop out the diagonal 
         number.cex = 0.8,     # the coeff font size
#         variable names to diagonal
#         tl.pos = 'd', # drop out the names
         cl.pos = 'n',    # drop the scale
         col = COL2('RdYlBu') # the color palette
         )


We can get p-value matrix and confidence intervals matrix by cor.mtest() which returns a list containing:

p is the p-values matrix.
lowCI is the lower bound of confidence interval matrix.
uppCI is the lower bound of confidence interval matrix.
testRes = cor.mtest(mtcars, conf.level = 0.95)

## specialized the insignificant value according to the significant level
corrplot(corr = cor(drug_freg_wmc), 
         p.mat = cor.mtest(drug_freg_wmc, conf.level = 0.95)$p,
         sig.level = 0.10, 
         order = 'hclust', 
         addrect = 2,
         tl.col = 'black',      # change label font color
         )



JOINED_Wide$poly_drug_use
JOINED_Wide <-
  JOINED_Wide |>
  #select(contains("_freq")) |> #view_html()
  mutate(poly_drug_use_fact = 
           factor(
             case_when(
               poly_drug_use == 0 ~ "None",
               poly_drug_use == 1 ~ "1",
               poly_drug_use > 1  ~ ">1",
               is.na(poly_drug_use) ~ "NA",
    #           TRUE ~ ""
               ), 
     #        labels = c("None", "1", ">1"),
             ordered = TRUE
           )
  )




JOINED_Wide |>
  select(id_subject, poly_drug_use_fact) |>
  view_html()

    mutate(poly_drug_use_30_fact = factor(case_when(
      poly_drug_use_30 == 0 ~ "None",
      poly_drug_use_30 == 1 ~ "1",
      poly_drug_use_30 > 1  ~ ">1",
      TRUE ~ ""
    ),
    labels = c("None", "1", ">1"),
    ordered = TRUE
    ))
#JOINED_LONG |> view_html()

JOINED_LONG |> select(id_subject, poly_drug_use) |> view_html()
```




# **Summarizing a Variable (or Variables) by Group**

1. Using wave 1 data, create a data summary using `summarize()` to present the means, standard errors, upper and lower limit 95% confidence-interval thresholds, and sample size associate with a measurement/outcome variable of your choice. To assist with the standard error, confidence intervals, *n*, use the list provided below. Include a grouping variable in your summary. 

```{.r}
summarize_across_list <- list(
  mean = ~mean(na.omit(.x)),
  se   = ~sd(na.omit(.x)) / sqrt(length(na.omit(.x))),
  ci.95l = ~ifelse(length(na.omit(.x)) > 1, 
                   t.test(na.omit(.x), conf.level = .95)$conf.int[1], NA),
  ci.95u = ~ifelse(length(na.omit(.x)), 
                   t.test(na.omit(.x), conf.level = .95)$conf.int[2], NA),
  n    = ~length(na.omit(.x))
  )
```

```{r, eval=eval_answers, include=include_answers}
summarize_across_list <- list(
  mean = ~mean(na.omit(.x)),
  se   = ~sd(na.omit(.x)) / sqrt(length(na.omit(.x))),
  ci.95l = ~ifelse(length(na.omit(.x)) > 1, 
                   t.test(na.omit(.x), conf.level = .95)$conf.int[1], NA),
  ci.95u = ~ifelse(length(na.omit(.x)), 
                   t.test(na.omit(.x), conf.level = .95)$conf.int[2], NA),
  n    = ~length(na.omit(.x))
  )


JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  group_by(ethnicity, wave) |>
  filter(as.numeric(wave) == 1) |>
  summarize(across(.cols = c(contains("sspan")),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |> 
  arrange(wave, desc(sspan_mean)) |>
  rename_with(~tolower(gsub("sspan_", "", .x, fixed = T))) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute Span Score by Ethnicity")


JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  filter(as.numeric(wave) == 1) |>
  group_by(ethnicity) |>
  summarize(across(.cols = c(contains("sspan")),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |> 
  arrange(ethnicity, desc(sspan_mean)) |>
  rename_with(~tolower(gsub("sspan_", "", .x, fixed = T))) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute Span Score by Ethnicity")

JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  group_by(ethnicity) |>
  filter(as.numeric(wave) == 1) |>
  summarize(across(.cols = contains("WMC"),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |>
  arrange(ethnicity, desc(WMC_mean)) |>
  mutate(across(where(is.numeric), round, digits = 2)) |>
  rename_with(~tolower(gsub("WMC_", "", .x, fixed = T))) |>
  gt() |>
  tab_header(title = "Wave 1: WMC by Ethnicity")

JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  group_by(ethnicity) |>
  filter(as.numeric(wave) == 1) |>
  summarize(across(.cols = contains("WMCe"),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |>
  arrange(ethnicity, desc(WMCe_mean)) |>
  mutate(across(where(is.numeric), round, digits = 2)) |>
  rename_with(~tolower(gsub("WMCe_", "", .x, fixed = T))) |>
  gt() |>
  tab_header(title = "Wave 1: WMC Errors by Ethnicity")
```



# **Correlate**


Vector of variables to correlate by.

```{r}
corr_filter <- function(
    correlation,
    filter_param1,
    descending = FALSE
                        
    ) {
  if (is.data.frame(correlation)) {
  correlation = 
    correlation |>
    filter(Parameter1 == {{filter_param1}}) |>
    arrange(p)
  
  if (descending) {
    correlation = 
      correlation |> arrange(desc(p))
  }

  return(correlation)
  
  } else {
    message("Object passed to correlation is not a data frame.")
  }
}

vars_corr <- JOINED_Wide |> select(c("wave", "WMC_1":"WMC_3", "WMCe_1", "WMC_3",
                                     "cigarette":"ritalin", "poly_drug_use")
                                   ) |> names()

CORR <- JOINED_Wide |>
  select(all_of(vars_corr)) |>
  filter(!is.na(WMC_1)) |>
  #group_by(group) |>
  correlation::correlation()
  
corr_filter(CORR, filter_param1 = "WMC_1")
  

vars_corr <- JOINED_Wide |> select(c("wave", "WMC_1":"WMC_3", "WMCe_1", "WMC_3",
                                     "cigarette_freq":"ritalin_freq", "poly_drug_use")
                                   ) |> names()

CORR <- JOINED_Wide |>
  select(all_of(vars_corr)) |>
  filter(!is.na(WMC_1)) |>
  #group_by(group) |>
  correlation::correlation()


corr_filter(CORR, filter_param1 = "WMC_1")


JOINED_Wide |> view_html() #poly_drug_use

vars_corr <- JOINED_Wide |> select(c("wave", "WMC_1":"WMC_3", "WMCe_1", "WMC_3",
                                     "cigarette_30_freq":"ritalin_30_freq", "poly_drug_use_30")
                                   ) |> names()

CORR <- JOINED_Wide |>
  select(all_of(vars_corr)) |>
  filter(!is.na(WMC_1)) |>
  #group_by(group) |>
  correlation::correlation()

corr_filter(CORR, filter_param1 = "WMC_1")



# JOINED_Wide |>  select(all_of(vars_corr)) |> ggpairs()

```

# **Random Forest**

3 Random forest with ranger
Packages used in this section: ranger for random forests and vip for variable importance (can be used for many model types, see https://koalaverse.github.io/vip/articles/vip.html).

The mtry optional argument gives the number of variables randomly sampled as candidates at each split. By default for ranger this is ⌊p–√⌋
 where p
 is the number of predictors, here 5
, so ⌊p–√⌋=2
. We want to try all the variables at each split for more accurate splitting. We increase this to 3 to get better trees but still include weak predictors; this is matched for randomForest (above).


3.1 Build the forest
First build the forest, using the ranger function. Ask for the permutation measure of variabile importance, to match randomForest.

The variable importance measures are of several types:

“impurity”: variance of the responses for regression (as here)
“impurity_corrected”: “The ‘impurity_corrected’ importance measure is unbiased in terms of the number of categories and category frequencies” – not relevant for regression forests
“permutation”. For this one can specify scale.permutation.importance = TRUE, this should match the randomForest concept.
Compute two ways, for the two kinds of importance. Use the same random seed, the forests will then be identical.

importance = 'permutation'
importance = 'impurity' 


3.2 Goodness-of-fit:
Predict with fitted model, at all observations;for this we need to specify a data= argument.

p.ra <- predict(m.lzn.ra, data = meuse)
str(p.ra)

summary(r.rap <- meuse$logZn - p.ra$predictions)

(rmse.ra <- sqrt(sum(r.rap^2)/length(r.rap)))


3.3 Out-of-bag cross-validation
The default model already has the OOB predictions stored in it. Compare to RandomForest results.

summary(m.lzn.ra$predictions)


summary(p.rf.oob)


summary(m.lzn.ra$predictions - p.rf.oob)  # difference

par(mfrow=c(1,2))
plot(meuse$logZn ~ m.lzn.ra$predictions, asp=1, pch=20,
     ylab="actual", xlab="OOB X-validation estimates",
    xlim=c(2,3.3), ylim=c(2,3.3),
    main="ranger")
abline(0,1); grid()
plot(meuse$logZn ~ p.rf.oob, asp=1, pch=20,
     xlab="OOB X-validation estimates",
     ylab="actual", xlim=c(2,3.3), ylim=c(2,3.3),
     main="RandomForest")
grid(); abline(0,1); par(mfrow=c(1,1))


3.4 Variable importance:
First, for permutation:

cbind(ranger = ranger::importance(m.lzn.ra),
      rF = randomForest::importance(m.lzn.rf)[,1])
      
Second, for impurity:

cbind(ranger =ranger::importance(m.lzn.ra.i),
      rF = randomForest::importance(m.lzn.rf)[,2])
      
library(vip)

v1 <- vip::vip(m.lzn.ra, title = "Ranger")
v2 <- vip::vip(m.lzn.rf, title = "randomForest")
grid.arrange(v1, v2, ncol = 2)


      



https://uc-r.github.io/random_forests

```{r}
library(ranger)   # a c++ implementation of random forest 
library(h2o)      # a java-based implementation of random forest
library(vip)
library(broom)
library(ggplot2)
library(tidyverse)
```

1.  Given a training data set
2.  Select number of trees to build (n_trees)
3.  for i = 1 to n_trees do
4.  |  Generate a bootstrap sample of the original data
5.  |  Grow a regression/classification tree to the bootstrapped data
6.  |  for each split do
7.  |  | Select m_try variables at random from all p variables
8.  |  | Pick the best variable/split-point among the m_try
9.  |  | Split the node into two child nodes
10. |  end
11. | Use typical tree model stopping criteria to determine when a 
    | tree is complete (but do not prune)
12. end
13. Output ensemble of trees 


```{r}
JOINED_LONG |> view_html()

omit_vars <- c("id_subject", "id_school", "id", "id_wave", #"wave", 
               "totalerrors", "totalcorrectsquares", "totalrecalledsets", "sspan"
               )
omit_predictors <- c("WMC", "WMCe", "wave", "id_wave")



wmc_30_freq <- JOINED_LONG |> 
  filter(as.numeric(wave) == 1) |>
  filter(!is.na(WMC)) |>
  #select(c(WMC, contains("_30_freq"))) |>
  select(-any_of(omit_vars)) |>
  select(-contains("bmq")) |>
  select(-contains("bnq")) |>
  mutate(across(.cols = where(is.numeric), 
                .fns = ~if_else(is.na(.), 0, .)
                )
         ) |>
  select(where(is.numeric))

wmc_30_freq |> view_html()

n_features <- length(setdiff(names(wmc_30_freq), c("WMC", "WMCe")))

wmc_30_freq_forest <- ranger::ranger(
  formula = WMC ~ ., 
  data = wmc_30_freq |> select(-WMCe),
  importance = 'permutation',
  scale.permutation.importance = TRUE,
  mtry = floor(n_features / 3),
  seed = 123
)
wmc_30_freq_forest
#ranger::importance(wmc_30_freq_forest)

vip::vip(object = wmc_30_freq_forest, 
         #num_features = 10,
         #geom = "boxplot", # c("col", "point", "boxplot", "violin"),
         ) + 
  labs(title = "Variables Ordered by Importantance (WMC~)")




mod <- ranger::ranger(
  formula = WMCe ~ ., 
  data = wmc_30_freq |> select(-WMC),
  importance = 'permutation',
  scale.permutation.importance = TRUE,
  mtry = floor(n_features / 3),
  seed = 123
)

summary(mod)

mod |>
  vip::vip() +
         #num_features = 10,
         #geom = "boxplot", # c("col", "point", "boxplot", "violin"),
  labs(title = "Variables Ordered by Importantance (WMCe~)")

```

# **Predicting Errors**

```{r}
wmce_30_freq <- JOINED_LONG |> 
  filter(!is.na(WMCe)) |>
  select(c(WMCe, contains("_30_freq"))) |>
  na.omit()

n_features <- length(setdiff(names(wmce_30_freq), c("WMC", "WMCe")))

wmce_30_freq_forest <- ranger::ranger(
  formula = WMCe ~ ., 
  data = wmce_30_freq,
  importance = 'permutation',
  scale.permutation.importance = TRUE,
  mtry = floor(n_features / 3),
  seed = 123
)

wmce_30_freq_forest

#ranger::importance(wmc_30_freq_forest)

vip::vip(wmce_30_freq_forest) + 
  labs(title = "Variables Ordered by Importantance (WMC~)")
```


# **Predicting Errors**

```{r}
omit_vars <- c("id_subject", "id_school", "id", "id_wave", #"wave", 
               "totalerrors", "totalcorrectsquares", "totalrecalledsets", "sspan"
               )
omit_predictors <- c("WMC", "WMCe", "wave", "id_wave")

wmce_all <- JOINED_LONG |> 
  filter(!is.na(WMCe)) |>
  filter(as.numeric(wave) == 3) |>
  select(-contains("bmq")) |>
  select(-contains("bnq")) |>
  select(-any_of(omit_vars)) |>
  #select(c(WMCe, contains("_freq"), -contains("30"))) |>
  na.omit()

#wmce_all |> view_html()

n_features <- length(setdiff(names(wmce_all), omit_predictors))
n_features
#setdiff(names(wmce_all), omit_predictors)


wmce_all_forest <- ranger::ranger(
  formula = WMCe ~ ., 
  data = wmce_all |> select(-WMC),
  importance = 'permutation',
  scale.permutation.importance = TRUE,
  mtry = floor(n_features / 3),
  seed = 123
)

summary(wmce_all_forest)

#ranger::importance(wmc_30_freq_forest)
vip::vip(wmce_all_forest) + 
  labs(title = "Variables Ordered by Importantance (WMCe~)")
```


#wmc_forest <- ranger::ranger(
#  formula = WMC ~ ., 
#  data = DAT,
#  mtry = floor(n_features / 3),
#  respect.unordered.factors = "order",
#  seed = 123
#)



# get OOB RMSE
(default_rmse <- sqrt(wmc_30_freq_forest$prediction.error))


### ngaya
# # Deforest function trims trees, producing a slimmer model without sacrificing much accuracy
#deforest_wmc <- ranger::deforest(wmc_forest, which.trees = c(1, 3, 5))
###

plot(wmc_30_freq$WMC ~ wmc_30_freq_forest$predictions, 
     asp = 1, pch = 20, 
     xlab = "fitted", 
     ylab = "actual", 
     #xlim = c(2,3.3), 
     #ylim=c(2,3.3), 
     main = "WMC, Ranger"
     )
abline(0, 1)
```

3.2 Goodness-of-fit:
Predict with fitted model, at all observations;for this we need to specify a data= argument.

```{r}
predict_wmc <- predict(wmc_30_freq_forest, data = wmc_30_freq)
str(predict_wmc)

summary(predict_wmc <- wmc_30_freq$WMC - predict_wmc$predictions)

(rmse_wmc <- sqrt(sum(predict_wmc^2)/length(predict_wmc)))

```

3.3 Out-of-bag cross-validation
The default model already has the OOB predictions stored in it. Compare to RandomForest results.

```{r}
summary(predict_wmc$predictions)

#summary(wmc_30_freq_forest$predictions - p.rf.oob)  # difference

plot(DAT$WMC ~ wmc_forest$predictions, 
     asp = 1, 
     pch = 20,
     ylab = "actual", 
     xlab = "OOB X-validation estimates",
#     xlim = c(2,3.3), ylim = c(2,3.3),
     main = "ranger"
     )

```


3.4 

```{r}
ranger::importance(wmc_30_freq_forest)

vip::vip(wmc_30_freq_forest, title = "Ranger")
#rF = randomForest::importance(m.lzn.rf)[,1])
```



ames <- AmesHousing::make_ames()

# Stratified sampling with the rsample package
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7, strata = "Sale_Price")
ames_train  <- rsample::training(split)
ames_test   <- rsample::testing(split)

feature_names <- sort(setdiff(names(ames_train), "Sale_Price"))

n_features <- length(setdiff(names(ames_train), "Sale_Price"))

# train a default random forest model
ames_rf1 <- ranger::ranger(
  formula = Sale_Price ~ ., 
  data = ames_train,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  seed = 123
)

ames_rf1

# get OOB RMSE
(default_rmse <- sqrt(ames_rf1$prediction.error))
## [1] 24859.27
```

```{r Using the Ranger Package to Run a Random Forest Model}
# Allows us to use the entire data set for training, and use more trees
# Importance = 'Permutation' allows the model to calculate the importance of each variable for a plot

rangerspinmodel <- ranger::ranger(
  formula = linear_weight ~ exit_speed + exit_vertical_angle + exit_spin_rate + exit_horizontal_angle + exit_spin_axis, 
  data = train, 
  importance = "permutation"
  )
rangerspinmodel

# Deforest function trims trees, producing a slimmer model without sacrificing much accuracy
dfspin <- ranger::deforest(rangerspinmodel, which.trees = c(1, 3, 5))
```






```{r Spin Random Forest Model}
#Calculating Predictions for both Models
preds.rfspin <- predict(rangerspinmodel, data = test, predict.all = TRUE)$predictions

preds.dfspin <- predict(dfspin, data = test, predict.all = TRUE)$predictions

#Making Sure the Deforested Model has the Same Predictions
identical(preds.rfspin[, -c(1, 3, 5)], y = preds.dfspin)
```


```{r Spin Random Forest Model}

#Calculating RMS
rmse(batted_ball$linear_weight, preds.rfspin)
rmse(batted_ball$linear_weight, preds.dfspin)
```

```{r Spin Random Forest}

# Looking at the importance of each variable
importance(rangerspinmodel)
```

```{r Spin Random Forest Model}
# Building a leaderboard for players based on Quality of Contact

predbatter_batty <- batted_ball %>% 
  # Adding another variable that is Quality of Contact
  mutate(PredQC = predict(rangerspinmodel, data = batted_ball, predict.all = TRUE)$predictions) %>% 
  
  # Grouped by Batter_id, and summarized to show the avg QC, LW, and RMSE
  group_by(name_use, name_last) %>% 
  summarize(Avg_QC = mean(PredQC),
            Avg_LW = mean(linear_weight),
            Error = rmse(Avg_LW, Avg_QC),
            n = n()) %>%
  arrange(desc(Avg_QC)) %>%
  
  # Only Looking at Batters with At Least 300 Batted Balls
  filter(n > 300)

predbatter_batty
batted_ball %>% arrange(desc(linear_weight))
```









2. After you are sure that your summary table looks correct, pipe the data frame to `gt()` from the **{gt}** library  (used in modules) to present the summary in a simple table. 

3. To add a title to the table, pipe your data frame to `tab_header()` from the **{gt}** library.

- Example: `tab_header(title = "My Clear Title")`

4. In preparation for your liaison meeting, you can repeat the process for another variable that you would want to present. 



# **Correlating Variables**

1. Create a Pearson's *r* correlation table of numeric variables that are also grouped by some grouping variable. Use the `gt()` function from module to present the correlations in a simple table. 

2. Extend the correlation table by adding a grouping variable that is relevant to the liaison's proposal. Use the `gt()` function from module to present the correlations in a simple table.

```{r, eval=eval_answers, include=include_answers}
JOINED_WIDE |>
#  filter(wave == 1 | wave == "1") |>
  #select(where(fn = is.numeric)) |>
  select(c(self_eth, contains("WMC"), contains("WMCe"))) |>
  correlation() |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  #cor(use = "pairwise.complete.obs") |>
  select(-Method) |>
  gt::gt() |>
  tab_header(title = "Wave 1: WMC Correlations")

#JOINED_WIDE |>  gtsummary::tbl_summary(poly_drug_use_30)

JOINED_WIDE |>
  select(c(poly_drug_use, contains("WMC"), contains("WMCe"))) |>
  filter(!is.na(WMC_1)) |>
  #group_by(poly_drug_use_30) |>
  correlation() |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  #cor(use = "pairwise.complete.obs") |>
  select(-Method) |>
  gt::gt() |>
  tab_header(title = "Wave 1: WMC Correlations by Poly Drug Use (Year)")

JOINED_WIDE |>
  select(c(poly_drug_use_30, contains("WMC"), contains("WMCe"))) |>
  filter(!is.na(WMC_1)) |>
  #group_by(poly_drug_use_30) |>
  correlation() |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  #cor(use = "pairwise.complete.obs") |>
  select(-Method) |>
  gt::gt() |>
  tab_header(title = "Wave 1: WMC Correlations by Poly Drug Use (30 Days)")

JOINED_WIDE |>
#  filter(wave == 1 | wave == "1") |>
  #select(where(fn = is.numeric)) |>
  select(c(self_eth, contains("WMC_1"), contains("WMCe_1"), age)) |>
  group_by(self_eth) |>
  correlation() |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  #cor(use = "pairwise.complete.obs") |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute and Partial Span Score Correlations by Ethnicity")


JOINED_WIDE |>
  filter(sex != "N/A") |>
  filter(wave == 1 |  wave == "1") |>
  #select(where(fn = is.numeric)) |>
  select(c(sex, self_eth, contains("span_1"), contains("squares_1"), age)) |>
  group_by(sex) |>
  correlation() |>
  #cor(use = "pairwise.complete.obs") |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute and Partial Span Score Correlations by Sex")
```


```{r, eval=eval_answers, include=include_answers}
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  select(ethnicity) |>
  table() |>  
  as.data.frame() |>
  pivot_wider(
      names_from = ethnicity,
      values_from = Freq
    ) |>
  relocate("NA", .after = last_col()) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Ethnicity (n)")
  
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  select(sex, ethnicity) |>
  table() |> 
  as.data.frame() |>
  pivot_wider(
      names_from = ethnicity,
      values_from = Freq
    ) |> 
  relocate("NA", .after = last_col()) |>
  gt() |>
  tab_header(title = "Wave 1: Sex and Ethnicity (n)")
```



# **Exploring Variables**

1. Create a generalized pairs plot to explore the data and bivariate relationships among a set of numeric variables. Consider variable relationships that would be relevant for your liaison's proposal. 

```{r, eval=eval_answers, include=include_answers}
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(!is.na(sspan_1)) |>
  select(c(contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs()
```

2. Extend the generalized pairs plot by adding a grouping variable that is relevant to the liaison's proposal. 

```{r eval=eval_answers, include=include_answers, message=FALSE, warning=FALSE}
suppressMessages(
suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(self_eth, contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs()
))
```

```{r eval=eval_answers, message=FALSE, warning=FALSE, include=include_answers}
suppressMessages(
suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(ethnicity, contains("span_1"), contains("squares_1"), age)) |>
  GGally::ggpairs(mapping = aes(col = ethnicity, alpha = .3),
                  lower = list(continuous = wrap("smooth", se = FALSE))
                  )
)
)

new_colors <- c("cornflowerblue", "firebrick") 

suppressMessages(
suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(sex, contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs(mapping = aes(col = sex, alpha = .3),
                  lower = list(continuous = wrap("smooth", se = FALSE))
                  ) +
  scale_color_manual(values = new_colors) +
  scale_fill_manual(values = new_colors)
))
```



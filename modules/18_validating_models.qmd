---
title: "**Validating Models**"
author: "Gabriel I. Cook"
#date: "`r Sys.Date()`"
date: "`r format(Sys.time(), '%d %B, %Y')`"

execute:
  #enabled: false
  freeze: auto
---

```{r message=FALSE, warning=FALSE, include=FALSE}
# secret functions
# source(here::here("r", "src", "color_format_text.R"))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# huber text
huber_pdf <- "https://www.markhuberdatascience.org/_files/ugd/c2b9b6_543ea42a1ea64e32b4440b34ffd71635.pdf"
front_matter <- 10
huber_intro_ch <- glue::glue(huber_pdf,"#page=",front_matter + 3)
huber_rmarkdown_ch <- glue::glue(huber_pdf,"#page=",front_matter + 10)
huber_graphing_ch <- glue::glue(huber_pdf,"#page=",front_matter + 17)
huber_transformation_ch <- glue::glue(huber_pdf,"#page=",front_matter + 59) # 5
huber_summaries_ch <- glue::glue(huber_pdf,"#page=",front_matter + 71)
huber_eda_var_ch <- glue::glue(huber_pdf,"#page=",front_matter + 81)
huber_eda_covar_ch <- glue::glue(huber_pdf,"#page=",front_matter + 93)
huber_import_ch <- glue::glue(huber_pdf,"#page=",front_matter + 103)
huber_tidy_data_ch <- glue::glue(huber_pdf,"#page=",front_matter + 123)
huber_relational_ch <- glue::glue(huber_pdf,"#page=",front_matter + 141)
huber_filtering_joins_ch <- glue::glue(huber_pdf,"#page=",front_matter + 150)
huber_strings_ch <- glue::glue(huber_pdf,"#page=",front_matter + 155)
huber_regex_ch <- glue::glue(huber_pdf,"#page=",front_matter + 162)
huber_using_regex_ch <- glue::glue(huber_pdf,"#page=",front_matter + 170)
huber_func_patterns_ch <- glue::glue(huber_pdf,"#page=",front_matter + 182)
huber_factors_ch <- glue::glue(huber_pdf,"#page=",front_matter + 186)
huber_sql_ch <- glue::glue(huber_pdf,"#page=",front_matter + 199)
huber_writing_functions_ch <- glue::glue(huber_pdf,"#page=",front_matter + 232)
huber_modeling_ch <- glue::glue(huber_pdf,"#page=",front_matter + 241)
```

```{r}
#| label: load-packages
#| include: false

R.utils::sourceDirectory(here::here("r", "functions"))
```

# **Overview**

In this optional module, you will be introduced to validating models. 


## **Readings and Preparation**

*Before Class*: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence. 

*Class*: In class, some functions and concepts will be introduced and we will practice implementing code through exercises. 


```{r eval=FALSE, warning=FALSE, include=FALSE}
# **To Do**
#- [R Workflow Basics](https://r4ds.hadley.nz/data-transform)
```

## **Supplementary Readings**


## **Libraries** 

- **{here}** `r packageVersion("here")`: for file path management
- **{dplyr}** `r packageVersion("dplyr")`: for manipulating data frames
- **{ggplot2}** `r packageVersion("ggplot2")`: for data visualization
- **{GGally}** `r packageVersion("GGally")`: for generalized pairs plots
- or **{tidyverse}** `r packageVersion("tidyverse")`: the full **{tidyverse}** ecosystem
- **{parameters}** `r packageVersion("parameters")`: for details on model parameters
- **{performance}** `r packageVersion("performance")`: for evaluating model fit
- or **{easystats}** `r packageVersion("easystats")`: the full **{easystats}** ecosystem

Others:

- **{gt}** `r packageVersion("gt")`: for model tables
- **{gtsummary}** `r packageVersion("gtsummary")`: for model tables

# **Libraries**

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(parameters)
library(performance)
library(GGally)
library(gt)
library(gtsummary)
#library(ggstatsplot)
```

# **Data**

We will work with the `mtcars` data set built into R. Examine the variables for variable types. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
head(mtcars) |> gt::gt() |> gt::tab_header("Data: mtcars")
```

Using `GGally::ggpairs`, explore the variable distributions and relationships. Let's reduce this data frame down to some variables that are numeric and convert those that represent categories (e.g., am = automatic vs. manual; vs = v vs. straight line). So as not to get distracted by mathematical measures of linear association, remove the correlations in the upper quadrants by setting them to be black using `upper = list(continuous = wrap("blank")))`. This plot is provided for exploring the data and thinking about the relationships before running any models.

```{r message=FALSE, warning=FALSE}
mtcars |>
  mutate(vs = factor(vs), 
         am = factor(am)
         ) |>
  relocate(c(vs, am), .after = last_col()) |>        # relocate to group at end in plot
  select(-c(cyl, gear)) |>                           # remove some variables
  ggpairs(upper = list(continuous = wrap("blank")))  # make correlations blank
```

By simple visual inspection, some variable relationships appear as they could be linear and some do not. Examine some variables more closely and also replace the empty squares with scatter plots with smoothed lines that will highlight the relationship. Note that the scatter plots above and below the diagonal will **not** be identical because they invert what variable is plotted along the axes. 

```{r message=FALSE, warning=FALSE}
mtcars |>
  mutate(vs = factor(vs), 
         am = factor(am)
         ) |>
  relocate(c(vs, am), .after = last_col()) |>        # relocate to group at end in plot
  select(-c(cyl, gear, qsec, am, vs)) |>             # remove some variables
  ggpairs(upper = list(continuous = wrap("smooth",   # add a loess fit
                                         method = "loess", 
                                         se = FALSE, 
                                         col = "cornflowerblue" 
                                         )
                       )
          ) 
```

Let's pull out some variables of interest to predict `mpg`, for example `disp` (displacement), `hp` (horsepower), and `wt` (weight) mpg.

```{r message=FALSE, warning=FALSE}
mtcars |>
  select(mpg, disp, hp, wt) |>                           
  ggpairs(upper = list(continuous = wrap("smooth", 
                                         method = "loess", 
                                         se = FALSE, 
                                         col = "cornflowerblue"
                                         )
                       )
  )
```

You could try to fit a simple linear model to the data by predicting `mpg` from `disp`, `hp`, or `wt` individually. But before doing so, let's look at whether the transforming data will visually improve a linear fit. These steps will help you understand what the model is doing as well as understand how `lm()` if used to fit the data. 


# **Model Accuracy Using k-fold Cross-Validation (kFCV)**

Using `caret::train()`, we can train the model using k-fold cross-validation. The function will return a cross-validated RMSE for both model accuracy and for comparing with the RMSE associated with other models. The data will essentially be split into *k* different samples (aka "folds") and the model will be run on each sample. The *k*-models will be averaged and combined for comparisons. 

Instead of refitting the model *n* different times, the model is refit *k* times (once for each fold). The first time, the first fold (the “test” fold) is withheld from the model (hold-out sample), the model is fit/trained with the other *k*−1 folds, and the test fold is used to make predictions with the mean square error (MSE) using all data from that fold. The process is repeated for each remaining fold as a "test" fold. After completing all folds, an estimate of the MSE is computed. 

# **Model Accuracy Using Leave-One-Out Cross Validation (LOOCV)**

Another validation approach is called *leave-one-out cross validation* () for which *n*-1 *cases* in the data set are dropped out and the model is run *n*-1 times. With *k*FCV, we trade off the model estimate's bias (which is more biased with kFCV) for less variance (which will be higher in LOOCV). With LOOCV, the model is run *n*-1 times rather than *k* times with *k*FCV so there is a time trade-off as well. With very large samples, *n*-1 models will take quite a bit of time. For example, if there are 100 cases of data, with LOOCV, there will be 99 models run. Splitting the data into 4 equal folds of 25 cases for *4*-fold cross validation would result in 4 models run.  

We will use k-fold cross validation for both the simple model and the more complex one. In order to replicate the outcome, let's first set a random seed so the results will be the same.

```{r message=FALSE, warning=FALSE}
set.seed(166)
mod_hp_log_cv_4 <- caret::train(
  mpg ~ log(hp),
  data = mtcars,
  method = "lm",
  trControl = caret::trainControl(method = "cv", number = 4)
  )

mod_hp_log_cv_10 <- caret::train(
  mpg ~ log(hp),
  data = mtcars,
  method = "lm",
  trControl = caret::trainControl(method = "cv", number = 4)
  )



mod_hp_log_wt_log_cv <- caret::train(
  mpg ~ log(hp) + log(wt),
  data = mtcars,
  method = "lm",
  trControl = caret::trainControl(method = "cv", number = 4)
  )

```

## *Extract the Model*

Using `caret::resamples()`, we can specify a `list()` object holding the models. We will assign each model a name too just to make output easier to read.

```{r message=FALSE, warning=FALSE}
mod_resamples <- caret::resamples(
  list(
    trial = lm_trial_cv,
    trial_e = lm_trial_error_cv,
    trial_e_ixn = lm_trial_error_ixn_cv
  )
)

```

## *Compare RMSE and R2*

We will now take a look at the cross-validated unadjusted `R2` and `RMSE`'s (root mean square error) for all three models. AIC and BIC weights are not included. MAE is mean absolute error.

```{r message=FALSE, warning=FALSE}
# new estimates using k-fold cross-validation
summary(mod_resamples)
```

Based on the random seed, the mean R2 is (at this writing) higher for the `trialtype` only model after sampling, perhaps able to explain a little more variance in rt. The mean RMSE is, however, slightly lower for the simple model. Which model is best may come down to weighing R2 against RMSE. 






# **Summary**


# **Session Information**

```{r}
sessioninfo::session_info()
```

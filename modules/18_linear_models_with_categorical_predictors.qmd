---
title: "**Linear Models (Categorical Predictors**"
author: "Gabriel I. Cook"
#date: "`r Sys.Date()`"
#date: "`r format(Sys.time(), '%d %B, %Y')`"

execute:
  #enabled: false
  freeze: auto
---

```{r message=FALSE, warning=FALSE, include=FALSE}
# secret functions
# source(here::here("r", "src", "color_format_text.R"))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# huber text
huber_pdf <- "https://www.markhuberdatascience.org/_files/ugd/c2b9b6_543ea42a1ea64e32b4440b34ffd71635.pdf"
front_matter <- 10
huber_intro_ch <- glue::glue(huber_pdf,"#page=",front_matter + 3)
huber_rmarkdown_ch <- glue::glue(huber_pdf,"#page=",front_matter + 10)
huber_graphing_ch <- glue::glue(huber_pdf,"#page=",front_matter + 17)
huber_transformation_ch <- glue::glue(huber_pdf,"#page=",front_matter + 59) # 5
huber_summaries_ch <- glue::glue(huber_pdf,"#page=",front_matter + 71)
huber_eda_var_ch <- glue::glue(huber_pdf,"#page=",front_matter + 81)
huber_eda_covar_ch <- glue::glue(huber_pdf,"#page=",front_matter + 93)
huber_import_ch <- glue::glue(huber_pdf,"#page=",front_matter + 103)
huber_tidy_data_ch <- glue::glue(huber_pdf,"#page=",front_matter + 123)
huber_relational_ch <- glue::glue(huber_pdf,"#page=",front_matter + 141)
huber_filtering_joins_ch <- glue::glue(huber_pdf,"#page=",front_matter + 150)
huber_strings_ch <- glue::glue(huber_pdf,"#page=",front_matter + 155)
huber_regex_ch <- glue::glue(huber_pdf,"#page=",front_matter + 162)
huber_using_regex_ch <- glue::glue(huber_pdf,"#page=",front_matter + 170)
huber_func_patterns_ch <- glue::glue(huber_pdf,"#page=",front_matter + 182)
huber_factors_ch <- glue::glue(huber_pdf,"#page=",front_matter + 186)
huber_sql_ch <- glue::glue(huber_pdf,"#page=",front_matter + 199)
huber_writing_functions_ch <- glue::glue(huber_pdf,"#page=",front_matter + 232)
huber_modeling_ch <- glue::glue(huber_pdf,"#page=",front_matter + 241)
```

```{r}
#| label: load-packages
#| include: false

R.utils::sourceDirectory(here::here("r", "functions"))
```

# **Overview**

In this optional module, you will be introduced to validating models. 


## **Readings and Preparation**

*Before Class*: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence. 

*Class*: In class, some functions and concepts will be introduced and we will practice implementing code through exercises. 


```{r eval=FALSE, warning=FALSE, include=FALSE}
# **To Do**
#- [R Workflow Basics](https://r4ds.hadley.nz/data-transform)
```

## **Supplementary Readings**


## **Libraries** 

- **{here}** `r packageVersion("here")`: for file path management
- **{dplyr}** `r packageVersion("dplyr")`: for manipulating data frames
- **{ggplot2}** `r packageVersion("ggplot2")`: for data visualization
- **{GGally}** `r packageVersion("GGally")`: for generalized pairs plots
- or **{tidyverse}** `r packageVersion("tidyverse")`: the full **{tidyverse}** ecosystem
- **{parameters}** `r packageVersion("parameters")`: for details on model parameters
- **{performance}** `r packageVersion("performance")`: for evaluating model fit
- or **{easystats}** `r packageVersion("easystats")`: the full **{easystats}** ecosystem

Others:

- **{gt}** `r packageVersion("gt")`: for model tables
- **{gtsummary}** `r packageVersion("gtsummary")`: for model tables

# **Libraries**

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(parameters)
library(performance)
library(GGally)
library(gt)
library(gtsummary)
#library(ggstatsplot)
```


## **Linear Model Equation**

The linear model equation with a single predictor: 
$$
Y = \beta_0 + \beta_1 X + \epsilon
$$

- *beta_0*: is the intercept (the value of Y when X = 0) 
- *beta_1*: is the slope (the change in Y for each one-unit change in X)
- *epsilon*: model error (the difference between the observed value of Y and value predicted by the model)


# **Data**

We will work with the `mtcars` data set built into R. Examine the variables for variable types. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
head(mtcars) |> gt::gt() |> gt::tab_header("Data: mtcars")
```

Using `GGally::ggpairs`, explore the variable distributions and relationships. Let's reduce this data frame down to some variables that are numeric and convert those that represent categories (e.g., am = automatic vs. manual; vs = v vs. straight line). So as not to get distracted by mathematical measures of linear association, remove the correlations in the upper quadrants by setting them to be black using `upper = list(continuous = wrap("blank")))`. This plot is provided for exploring the data and thinking about the relationships before running any models.

```{r message=FALSE, warning=FALSE}
dat <-
  mtcars |>
  mutate(vs_fact = factor(vs), 
         am_fact = factor(am, 
                          levels = c(0, 1), 
                          labels = c("Automatic", "Manual")
                          )
         ) |>
  relocate(c(vs, am), .after = last_col()) |>
  select(-c(cyl, gear))
```

We see that `vs` is a factor but the labels are numeric whereas `am` is a factor with levels that are either "Automatic" or "Manual".

```{r}
glimpse(dat)
```

## **Inspecting Categorical/Factor Variables**

If `am` was truly numeric, we could create a scatter plot and fine a linear model to the data visually. Of course, `am` does not provide to numeric information about the vehicles but instead provided categorical information about their transmission.

```{r}
ggplot(data = dat, 
       mapping = aes(x = am, y = mpg)
       ) +
  geom_point(position = position_jitter(width = .1), color = "yellow") +
  geom_smooth(method = "lm") +
  theme_dark_mode()

```

Inspecting the factor variables, we see the box plots reveal different distributions of `mpg` across the levels of both `am_fact` and `vs_fact`. The distributions of `hp` also look different but in the opposite direction. 

```{r message=FALSE, warning=FALSE}
dat |>
  select(mpg, hp, vs_fact, am_fact) |>
  ggpairs(upper = list(continuous = wrap("blank")))  # make correlations blank 
```

Inspecting the descriptive statistics, the manual-transmission vehicles are getting better gas mileage on average. Make note of this numeric difference. 

```{r}
dat |>
  group_by(am_fact) |>
  summarize(mpg = mean(mpg, na.rm = TRUE)) |> 
  pivot_wider(names_from = am_fact, 
              values_from = mpg 
              ) |>
  mutate(diff = Manual - Automatic)
```

## **Applying Statistical Models**

We see that there are numeric differences in the outcome variable across levels of the predictor. In order to determine whether those differences are random or systematic involves some additional analyses. An important of understanding relationships between variables is not just understanding in a binary sense whether variables are related but rather understanding the strength of a relationship if one exists. In other words, a goal is often to determine whether variability in an outcome variables can be *explained by*, or *accounted for*, by predictor variables. One way to understand this strength is R-squared. Another way is to understand the RMSE (root mean square error) associated with the model.

### **Comparing Factor Levels using `t.test()`**

In a binary sense, a familiar approach is to examine the data is by *t*-test. In order to compare the independent factor levels, use `paired = FALSE`. We see the models for both `vs` and `am`. The means are presented for both factor levels, which match the data summary.

```{r}
t.test(mpg ~ am_fact, paired = FALSE, data = dat) 
```

If you want to clean up the model, pass it to `broom::tidy()` and `mutate()` `across()` variables to `round()` them.

```{r}
t.test(mpg ~ am_fact, paired = FALSE, data = dat) |> 
  broom::tidy() |> 
  mutate(across(.cols = where(is.numeric), 
                .fns = ~round(.x, 4)
                )
         ) |>
  gt()
```

The `estimate` represents the difference between the means for the levels of the predictor whereas the additional `estimate`s represent their individual means. The  *t*-value, or `statistic` value, and the associated `p.value` provide information about whether the outcome variables differs across the levels of the factor predictor.

The same in formation can be extracted from the `vs_fact` predictor.

```{r}
t.test(mpg ~ vs_fact, paired = FALSE, data = dat) 
```

Another approach would be to use a linear model. In fact, the *t*-test can be thought of as a linear model predicting `mpg` by a numeric value of `am`. Vehicles with automatic transmissions are `am = 0` and those with a manual transmission are `am = 1`.


# **The Linear Model Approach**

One could build a linear model with the numeric variables of `am` and `vs` but these variable are not truly numeric. Their levels represent qualitatively/categorically different mechanical systems; they are not more or less of the same system. 

To help gain some insight into a linear model, however, we can examine relationships across these numeric variables. We see that there are positive Pearson *r* values associated with `mpg` and the numeric versions of the categorical variables (e.g., `am` no `am_fact`).

```{r}
correlation::correlation(data = dat |> select(mpg, am, vs)) |> gt()
```

## **Building the Model**

Building the model is as easy as specifying the outcome as a function of the predictor: `lm(mpg ~ am_fact, dat = dat)`.

```{r}
mod_am <- lm(mpg ~ am_fact, dat = dat)
```


## **Understanding the Model**

In order to see how `lm()` will treat the model, we can use `modelr::model_matrix()` to build a model and examine the components. 

```{r}
modelr::model_matrix(data = dat, 
                     formula = mpg ~ am_fact
                     ) |> gt()
```

The model matrix has a column variable for which every observation has an `(Intercept)` value and a `am_factManual` value. The intercept is a constant because the intercept of the model will be the same whether the transmission is automatic or manual. Importantly, the `am_factManual` column created for the model is a combination of the factor name, `am_fact` and the levels of the factor, which are `"Automatic"` and `"Manual"`. 

For the regression model, there need to be a base or *reference* category level to which you compare the other level(s). Vehicles that are "automatic" (or not manual) are coded as `0` so this is serving as the base category for the predictor variable because of how `am_fact` was created. Vehicles that are manual are thus coded as `am_factManual = 1` (they are manual). The model provide a binary predictor variable, which can be conceived of a Manual: "Yes" or "No", which the model has created automatically as `am_factManual` 0 or 1. 

For binary factor variables that can be conceived as "yesses" or "nos", this distinction is simple to understand. If, however, your predictor is something like `location` with levels of "California" and "Texas", the distinction becomes somewhat more challenging, though you could simply recode the variable as `California`: "yes" vs. "no" where "Texas" = "no". 

## **Interpreting the Model**

In order to interpret the role of the factor predictor, we need to consider the coefficients associated with the model.

- *beta_0*: the intercept 
- *beta_1*: slope 
- *epsilon*: model error 

A model `summary()` will provide several model details. 

```{r}
summary(mod_am)
```

To extract the coefficients specifically, we can pass the model to `parameters::parameters()`.

```{r}
parameters::parameters(mod_am)
```

As before, the *y-intercept* of this `mpg ~ am_fact` model reflects the `mpg` when `x = 0`. Because `x` is `am_factManual` and `0 = "automatic"`, then the y-intercept reflects the `mpg` when vehicles have a manual transmission. 

The coefficient for the predictor represents the *slope* as with other linear models. The model clarifies that the slope is associate with the vehicles with manual transmission, by labeling the coefficient/parameter as `"am fact [Manual]"`. 

Let's unpack the slope value (`beta_1`), which is `r parameters::parameters(mod_am)[2,2]`. For each unit change in the predictor, there is a `r parameters::parameters(mod_am)[2,2]` increase in `mpg`. Because vehicles can be either automatic or manual, this unit change of `1` reflects the change from automatic (0) to manual (1). Thus, the slope should represent the difference in `mpg` between the two groups. The slope reflects the same difference observed between the means for the factor levels (e.g., `am = 0` vs. `am = 1`). This difference is positive and in favor of higher `mpg` for the *manual*-transmission vehicles rather than negative in favor of the *automatic*-transmission vehicles. 

```{r}
ggplot(data = dat, 
       mapping = aes(x = am_fact, y = mpg)
       ) +
  geom_point(color = "yellow",
             position = position_jitter(width = .1)
             ) +
  theme_dark_mode()
```


You can check the model diagnostics `performance::check_model)`. 

```{r}
performance::check_model(mod_am)
```

For feedback-related disgnostic functions, use `performance::check_residuals()` and  `performance::check_heteroskedasticity()`.

```{r}
performance::check_residuals(mod_am)

performance::check_heteroskedasticity(mod_am)
```



# **Handling Factors with > 2 Levels**

Let's create a simple data frame containing a factor and a numeric variable.

```{r}
data <- data.frame(
  Id = c(1, 2, 3, 4, 5, 6),
  Group = c("A", "B", "C", "B", "A", "C"),  # Example categorical predictor with 3 levels
  Y = c(10, 12, 15, 11, 9, 14)  # Example response variable
)
```


Make the variable a `factor()`.

```{r}
data <-
  data |>
  mutate(Group  = factor(Group,
                         labels = c("A", "B", "C")
                         )
  )

data |> gt()
```

Looking at the factor levels, there appear to be some differences.

```{r}
data |>
  group_by(Group) |>
  summarize(Y_mean = mean(Y, na.rm = T),
            Y_sd = sd(Y, na.rm = T)
            )
```


## **Dummy Coding**

Remember that linear models are designed for with numerical variables. Many data-science questions, however, involve asking about the importance of categorical/factor variables.  In order to run linear models, categorical variables need to be converted to numeric variables in some way. **Dummy coding** is one way to incorporate categorical variables into regression models.

**Why dummy code factor predictors?**

- **For Comparing Factor Levels:** Dummy coding allows for making comparisons across levels of categorical variable with respect to the outcome variable. Dummy variables, however, allow for quantifying the role of different levels of the factor of interest *relative to a reference category*. This last part is important. There needs to be a reference, or baseline, group. Typically, this reference group is the baseline or control factor level but for some variables like race, ethicity, college major, etc. a control or baseline factor level is ambiguous. Nevertheless, a reference level is needed. 

- **Facilitate Interpretation of Coefficients:** Dummy coding factors variables provides clear interpretation of regression coefficients associated with the influence of factor variables. Each coefficient of the linear model represents the *difference in the outcome variable between the respective category and the reference category**. This makes it easier to understand the impact of each category on the outcome variable.

- **Avoiding Multicollinearity:** Linear models are constrained when model predictors are correlated with each other, an issue referred to as *multicollinearity*. When models involve categorical variables with >2 levels, dummy coding helps reduce, or avoid, multicollinearity. Dummy-coding variables creates factors levels that are represented independently, thereby reducing multicollinearity. This can be evaluated using `performance::check_collinearity()`.

- **Model Flexibility:** Dummy coding allows for flexibility in modeling categorical variables with multiple levels. Using dummy coding, you can include multiple levels of factor variables. This makes the dummy-coding approach applicable to a wide range of data questions.


## **Implementing Dummy Coding**

We can create dummy coded variables in different ways. One way is to use **{modelr}**'s `model.matrix()` 

```{r}
data |> 
  model.matrix(object = ~ Group - 1) 
```

We can create the dummy variable and join to the data frame.

```{r}
dummy_vars <- 
  data |>
  model.matrix(object = ~ Group - 1)
```


Join with the data frame.

```{r}
(data <- cbind(data, dummy_vars))
```


We see that there are dummy variables for each level of the original factor variable, `Group`. The new variables are named with the factor level names appended to the factor name. This results in a variable for each level for with `0` represents **not** belonging to that factor level and `1` represents belonging to that factor level.

Fit the linear model.

```{r}
mod_categ_mult <- lm(Y ~ Group, data = data)
```

Examine the model summary.

```{r}
summary(mod_categ_mult)
```

Before examining the parameters, let's look at the group means again. Group "B" is greater than Group "A" by a value of 2 and Group "C" is greater than Group "A" by a value of 5.

```{r}
data |> 
  group_by(Group) |>
  summarize(Group = mean(na.omit(Y)))
```

Examine the model parameters.

```{r}
parameters::parameters(mod_categ_mult)
```

The coefficient for `Group [B]` is `r parameters::parameters(mod_categ_mult)[2,2]`, which reflects the difference between the reference group (e.g., "A") and Group "B". Similarly, the coefficient for `Group [C]` is `r parameters::parameters(mod_categ_mult)[3,2]`,reflects the difference between the reference group (e.g., "A") and Group "C". The corresponding *p*-values suggest that group C differs from Group "A" but Group "B" does not differ from Group "A". The only comparison that is missing is between Groups "B" and "C".


You could plot the coefficients using `ggstatsplot::ggcoefstats()` by passing the model to the function. **{ggstatsplot}** has a set of functions that help visualize model details quickly. The plots are not very customizable like what you could produce using **{ggplot2}**. 

```{r}
ggstatsplot::ggcoefstats(mod_categ_mult)
```


Fit with Analysis of Variance (ANOVA).

You could also fit a model using `aov()`, which is an ANOVA alternative to `lm()`. However, there are different statistical models that affect how variance is decomposed. These are referred to as type I ,type II, and type III sums of squares models. These are not the same, so don't apply them without investigating. A discussion of these differences are beyond the scope of this content.


```{r}
aov_cat <- aov(Y ~ Group, data = data)
```

Examine the model summary.

```{r}
summary(aov_cat)
```

```{r}
parameters::parameters(aov_cat)
```

And how to compare the separate groups? You could create your one theoretically motivated contrasts but one way is to use the `TukeyHSD()` to perform a Tukey's **H**onestly **S**ignificant **D**ifference Test. 

```{r}
TukeyHSD(aov_cat)
```

The corresponding *p*-values suggest that Groups C versus C differ and that Group V versus B.   


```{r}
ggstatsplot::ggbetweenstats(
  data  = data,
  x     = Group,
  y     = Y,
  title = ""
)
```


```{r}
ggstatsplot::ggbetweenstats(
  data  = dat,
  x     = am,
  y     = mpg,
  title = "none"
)

ggstatsplot::ggcoefstats(mod_categ_mult)
```



```{r}
ggstatsplot::ggcoefstats(mod_am)

#ggstatsplot::ggcoefstats(aov_cat)
```

